#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Detector de tecnologías web mejorado con múltiples herramientas.
Integra Wappalyzer, WhatWeb, httpx y patrones personalizados.
"""

import json
import subprocess
import time
import re
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional, Set
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import urlparse
import hashlib

# Configurar logging
log = logging.getLogger(__name__)

class TechDetectionCache:
    """Cache inteligente para evitar análisis duplicados."""
    
    def __init__(self, cache_size: int = 1000):
        self.cache = {}
        self.max_size = cache_size
        self.access_times = {}
    
    def get_cache_key(self, url: str) -> str:
        """Genera clave de cache basada en dominio."""
        parsed = urlparse(url)
        domain = parsed.netloc.lower()
        return hashlib.md5(domain.encode()).hexdigest()
    
    def get(self, url: str) -> Optional[Dict]:
        """Obtiene datos del cache si existen."""
        key = self.get_cache_key(url)
        if key in self.cache:
            self.access_times[key] = time.time()
            return self.cache[key]
        return None
    
    def set(self, url: str, data: Dict) -> None:
        """Guarda datos en el cache."""
        key = self.get_cache_key(url)
        
        # Limpiar cache si está lleno
        if len(self.cache) >= self.max_size:
            self._cleanup_cache()
        
        self.cache[key] = data
        self.access_times[key] = time.time()
    
    def _cleanup_cache(self) -> None:
        """Limpia entradas más antiguas del cache."""
        # Ordenar por tiempo de acceso y eliminar 20% más antiguas
        sorted_keys = sorted(self.access_times.keys(), 
                           key=lambda k: self.access_times[k])
        to_remove = sorted_keys[:self.max_size // 5]
        
        for key in to_remove:
            if key in self.cache:
                del self.cache[key]
            if key in self.access_times:
                del self.access_times[key]

class EnhancedTechDetector:
    """Detector de tecnologías mejorado con múltiples herramientas."""
    
    def __init__(self, use_cache: bool = True):
        self.cache = TechDetectionCache() if use_cache else None
        self.tools = {
            'wappalyzer': self._check_wappalyzer,
            'whatweb': self._check_whatweb,
            'httpx': self._check_httpx_tech,
            'custom': self._custom_detection
        }
        self.confidence_weights = {
            'wappalyzer': 1.0,
            'whatweb': 0.9,
            'httpx': 0.7,
            'custom_patterns': 0.6
        }
    
    def detect_technologies(self, url: str, timeout: int = 30) -> Dict[str, Any]:
        """Detecta tecnologías usando múltiples herramientas."""
        start_time = time.time()
        
        # Verificar cache primero
        if self.cache:
            cached_result = self.cache.get(url)
            if cached_result:
                log.debug(f"Usando resultado cacheado para {url}")
                return cached_result
        
        results = {
            'url': url,
            'technologies': [],
            'confidence_scores': {},
            'detection_methods': [],
            'detection_time': 0,
            'timestamp': int(time.time())
        }
        
        # Ejecutar detección con múltiples herramientas
        for tool_name, tool_func in self.tools.items():
            try:
                log.debug(f"Ejecutando {tool_name} para {url}")
                tech_data = tool_func(url, timeout)
                
                if tech_data and tech_data.get('technologies'):
                    results['technologies'].extend(tech_data['technologies'])
                    results['detection_methods'].append(tool_name)
                    
                    # Agregar scores de confianza
                    for tech in tech_data['technologies']:
                        tech_name = tech.get('name', '').lower().strip()
                        confidence = tech.get('confidence', 50)
                        
                        if tech_name in results['confidence_scores']:
                            # Promedio ponderado si múltiples herramientas detectan la misma tech
                            current_conf = results['confidence_scores'][tech_name]
                            weight = self.confidence_weights.get(tool_name, 0.5)
                            results['confidence_scores'][tech_name] = (
                                current_conf + (confidence * weight)
                            ) / 2
                        else:
                            weight = self.confidence_weights.get(tool_name, 0.5)
                            results['confidence_scores'][tech_name] = confidence * weight
                            
            except Exception as e:
                log.warning(f"Error con {tool_name} para {url}: {e}")
        
        # Deduplicar y filtrar por confianza
        results['technologies'] = self._deduplicate_technologies(
            results['technologies'], 
            min_confidence=30
        )
        
        # Calcular tiempo de detección
        results['detection_time'] = round(time.time() - start_time, 2)
        
        # Guardar en cache
        if self.cache:
            self.cache.set(url, results)
        
        return results
    
    def _check_wappalyzer(self, url: str, timeout: int = 30) -> Optional[Dict[str, Any]]:
        """Detección con Wappalyzer CLI."""
        try:
            cmd = ['wappalyzer', url, '--pretty']
            result = subprocess.run(
                cmd, 
                capture_output=True, 
                text=True, 
                timeout=timeout,
                creationflags=subprocess.CREATE_NO_WINDOW if hasattr(subprocess, 'CREATE_NO_WINDOW') else 0
            )
            
            if result.returncode == 0 and result.stdout.strip():
                data = json.loads(result.stdout)
                technologies = []
                
                for tech_name, tech_info in data.get('technologies', {}).items():
                    technologies.append({
                        'name': tech_name,
                        'version': tech_info.get('version', ''),
                        'confidence': tech_info.get('confidence', 100),
                        'categories': tech_info.get('categories', []),
                        'source': 'wappalyzer'
                    })
                
                return {'technologies': technologies}
                
        except (subprocess.TimeoutExpired, json.JSONDecodeError, FileNotFoundError) as e:
            log.debug(f"Wappalyzer falló para {url}: {e}")
        except Exception as e:
            log.debug(f"Error inesperado con Wappalyzer para {url}: {e}")
        
        return None
    
    def _check_whatweb(self, url: str, timeout: int = 30) -> Optional[Dict[str, Any]]:
        """Detección con WhatWeb."""
        try:
            cmd = ['whatweb', '--log-json=-', '--quiet', url]
            result = subprocess.run(
                cmd, 
                capture_output=True, 
                text=True, 
                timeout=timeout,
                creationflags=subprocess.CREATE_NO_WINDOW if hasattr(subprocess, 'CREATE_NO_WINDOW') else 0
            )
            
            if result.returncode == 0 and result.stdout.strip():
                # WhatWeb puede devolver múltiples líneas JSON
                lines = result.stdout.strip().split('\n')
                technologies = []
                
                for line in lines:
                    if line.strip():
                        try:
                            data = json.loads(line)
                            plugins = data.get('plugins', {})
                            
                            for plugin_name, plugin_data in plugins.items():
                                if isinstance(plugin_data, dict):
                                    version = ''
                                    if 'version' in plugin_data:
                                        versions = plugin_data['version']
                                        if isinstance(versions, list) and versions:
                                            version = versions[0]
                                        elif isinstance(versions, str):
                                            version = versions
                                    
                                    technologies.append({
                                        'name': plugin_name,
                                        'version': version,
                                        'confidence': 80,  # WhatWeb no proporciona confidence
                                        'details': plugin_data.get('string', []),
                                        'source': 'whatweb'
                                    })
                        except json.JSONDecodeError:
                            continue
                
                return {'technologies': technologies}
                
        except (subprocess.TimeoutExpired, FileNotFoundError) as e:
            log.debug(f"WhatWeb falló para {url}: {e}")
        except Exception as e:
            log.debug(f"Error inesperado con WhatWeb para {url}: {e}")
        
        return None
    
    def _check_httpx_tech(self, url: str, timeout: int = 20) -> Optional[Dict[str, Any]]:
        """Detección con httpx tech-detect."""
        try:
            cmd = ['httpx', '-u', url, '-tech-detect', '-json', '-silent', '-timeout', str(timeout)]
            result = subprocess.run(
                cmd, 
                capture_output=True, 
                text=True, 
                timeout=timeout + 5,
                creationflags=subprocess.CREATE_NO_WINDOW if hasattr(subprocess, 'CREATE_NO_WINDOW') else 0
            )
            
            if result.returncode == 0 and result.stdout.strip():
                lines = result.stdout.strip().split('\n')
                technologies = []
                
                for line in lines:
                    if line.strip():
                        try:
                            data = json.loads(line)
                            tech_list = data.get('tech', [])
                            
                            for tech in tech_list:
                                if isinstance(tech, str):
                                    technologies.append({
                                        'name': tech,
                                        'version': '',
                                        'confidence': 70,
                                        'source': 'httpx'
                                    })
                                elif isinstance(tech, dict):
                                    technologies.append({
                                        'name': tech.get('name', ''),
                                        'version': tech.get('version', ''),
                                        'confidence': 70,
                                        'source': 'httpx'
                                    })
                        except json.JSONDecodeError:
                            continue
                
                return {'technologies': technologies}
                
        except (subprocess.TimeoutExpired, FileNotFoundError) as e:
            log.debug(f"httpx tech-detect falló para {url}: {e}")
        except Exception as e:
            log.debug(f"Error inesperado con httpx para {url}: {e}")
        
        return None
    
    def _custom_detection(self, url: str, timeout: int = 10) -> Optional[Dict[str, Any]]:
        """Detección personalizada basada en patrones."""
        try:
            import requests
            from requests.adapters import HTTPAdapter
            from urllib3.util.retry import Retry
            
            # Configurar sesión con reintentos
            session = requests.Session()
            retry_strategy = Retry(
                total=2,
                backoff_factor=1,
                status_forcelist=[429, 500, 502, 503, 504],
            )
            adapter = HTTPAdapter(max_retries=retry_strategy)
            session.mount("http://", adapter)
            session.mount("https://", adapter)
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            response = session.get(url, timeout=timeout, verify=False, headers=headers)
            technologies = []
            
            # Patrones personalizados mejorados
            patterns = {
                'WordPress': [
                    r'/wp-content/',
                    r'/wp-includes/',
                    r'<meta name="generator" content="WordPress',
                    r'wp-json',
                    r'wp-admin'
                ],
                'Drupal': [
                    r'/sites/default/',
                    r'Drupal.settings',
                    r'<meta name="Generator" content="Drupal',
                    r'/core/misc/drupal.js',
                    r'data-drupal-selector'
                ],
                'Joomla': [
                    r'/administrator/',
                    r'/components/',
                    r'<meta name="generator" content="Joomla',
                    r'Joomla.JText'
                ],
                'React': [
                    r'react',
                    r'__REACT_DEVTOOLS_GLOBAL_HOOK__',
                    r'data-reactroot',
                    r'react-dom'
                ],
                'Vue.js': [
                    r'Vue.js',
                    r'__VUE__',
                    r'v-cloak',
                    r'vue.js'
                ],
                'Angular': [
                    r'ng-app',
                    r'angular.js',
                    r'ng-controller',
                    r'ng-version'
                ],
                'jQuery': [
                    r'jquery',
                    r'jQuery',
                    r'\$\(document\).ready'
                ],
                'Bootstrap': [
                    r'bootstrap',
                    r'Bootstrap',
                    r'btn-primary',
                    r'container-fluid'
                ],
                'Laravel': [
                    r'laravel_session',
                    r'XSRF-TOKEN',
                    r'_token'
                ],
                'Django': [
                    r'csrfmiddlewaretoken',
                    r'Django',
                    r'__admin_media_prefix__'
                ],
                'PHP': [
                    r'PHPSESSID',
                    r'\.php',
                    r'X-Powered-By.*PHP'
                ]
            }
            
            content = response.text.lower()
            headers_str = ' '.join([f"{k}: {v}" for k, v in response.headers.items()]).lower()
            
            for tech_name, tech_patterns in patterns.items():
                confidence = 0
                matches = 0
                
                for pattern in tech_patterns:
                    if re.search(pattern.lower(), content) or re.search(pattern.lower(), headers_str):
                        matches += 1
                        confidence += 20  # Cada patrón encontrado suma 20 puntos
                
                if matches > 0:
                    # Ajustar confianza basada en número de patrones encontrados
                    final_confidence = min(confidence, 90)  # Máximo 90%
                    
                    technologies.append({
                        'name': tech_name,
                        'version': '',
                        'confidence': final_confidence,
                        'patterns_matched': matches,
                        'source': 'custom_patterns'
                    })
            
            return {'technologies': technologies}
            
        except Exception as e:
            log.debug(f"Detección personalizada falló para {url}: {e}")
        
        return None
    
    def _deduplicate_technologies(self, technologies: List[Dict], min_confidence: int = 30) -> List[Dict]:
        """Deduplica tecnologías y filtra por confianza."""
        seen = {}
        result = []
        
        for tech in technologies:
            name = tech.get('name', '').lower().strip()
            confidence = tech.get('confidence', 0)
            
            if not name or confidence < min_confidence:
                continue
            
            # Normalizar nombres comunes
            name = self._normalize_tech_name(name)
            
            if name in seen:
                # Mantener la detección con mayor confianza
                if confidence > seen[name]['confidence']:
                    seen[name] = tech
                    seen[name]['name'] = name.title()  # Capitalizar nombre
                elif confidence == seen[name]['confidence']:
                    # Si tienen la misma confianza, combinar información
                    if tech.get('version') and not seen[name].get('version'):
                        seen[name]['version'] = tech['version']
            else:
                tech['name'] = name.title()  # Capitalizar nombre
                seen[name] = tech
        
        return list(seen.values())
    
    def _normalize_tech_name(self, name: str) -> str:
        """Normaliza nombres de tecnologías para mejor deduplicación."""
        # Mapeo de nombres comunes
        name_mapping = {
            'jquery': 'jQuery',
            'vue': 'Vue.js',
            'vue.js': 'Vue.js',
            'vuejs': 'Vue.js',
            'react': 'React',
            'reactjs': 'React',
            'angular': 'Angular',
            'angularjs': 'AngularJS',
            'bootstrap': 'Bootstrap',
            'wordpress': 'WordPress',
            'wp': 'WordPress',
            'drupal': 'Drupal',
            'joomla': 'Joomla',
            'php': 'PHP',
            'nginx': 'Nginx',
            'apache': 'Apache',
            'mysql': 'MySQL',
            'postgresql': 'PostgreSQL',
            'redis': 'Redis'
        }
        
        normalized = name.lower().strip()
        return name_mapping.get(normalized, normalized)

def parallel_tech_analysis(urls: List[str], max_workers: int = 5, timeout: int = 30) -> List[Dict]:
    """Análisis paralelo de tecnologías con rate limiting."""
    detector = EnhancedTechDetector()
    results = []
    
    log.info(f"Iniciando análisis paralelo de {len(urls)} URLs con {max_workers} workers")
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # Enviar tareas con rate limiting
        futures = {}
        for i, url in enumerate(urls):
            # Delay escalonado para evitar sobrecarga
            delay = (i % max_workers) * 0.2
            future = executor.submit(detector.detect_technologies, url, timeout)
            futures[future] = url
            
            if delay > 0:
                time.sleep(delay)
        
        # Recoger resultados
        for future in as_completed(futures, timeout=timeout + 30):
            url = futures[future]
            try:
                result = future.result(timeout=10)
                results.append(result)
                log.debug(f"Análisis completado para {url}: {len(result.get('technologies', []))} tecnologías")
            except Exception as e:
                log.error(f"Error analizando {url}: {e}")
                # Agregar resultado vacío para mantener consistencia
                results.append({
                    'url': url,
                    'technologies': [],
                    'error': str(e),
                    'detection_time': 0
                })
    
    log.info(f"Análisis paralelo completado. {len(results)} resultados obtenidos")
    return results

if __name__ == "__main__":
    # Ejemplo de uso
    import sys
    
    if len(sys.argv) > 1:
        test_url = sys.argv[1]
        detector = EnhancedTechDetector()
        result = detector.detect_technologies(test_url)
        print(json.dumps(result, indent=2, ensure_ascii=False))
    else:
        print("Uso: python enhanced_fingerprint.py <URL>")