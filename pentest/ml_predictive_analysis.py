#!/usr/bin/env python3
"""
MÃ³dulo de IA/ML para AnÃ¡lisis Predictivo
Proporciona capacidades de machine learning para anÃ¡lisis predictivo de seguridad
"""

import json
import logging
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, asdict
from sklearn.ensemble import IsolationForest, RandomForestClassifier
from sklearn.cluster import DBSCAN
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score
import joblib
import os

# ConfiguraciÃ³n de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class SecurityEvent:
    """Representa un evento de seguridad para anÃ¡lisis"""
    timestamp: datetime
    event_type: str
    severity: str
    source_ip: str
    target_domain: str
    vulnerability_count: int
    threat_score: float
    technologies: List[str]
    ports_open: List[int]
    response_time: float
    status_code: int
    payload_size: int
    user_agent: str
    country: str
    is_malicious: bool = False

@dataclass
class PredictionResult:
    """Resultado de predicciÃ³n de ML"""
    prediction: str
    confidence: float
    risk_score: float
    anomaly_score: float
    recommendations: List[str]
    features_importance: Dict[str, float]
    timestamp: datetime

@dataclass
class ThreatPattern:
    """PatrÃ³n de amenaza identificado"""
    pattern_id: str
    pattern_type: str
    frequency: int
    severity: str
    indicators: List[str]
    first_seen: datetime
    last_seen: datetime
    confidence: float

class MLPredictiveAnalyzer:
    """Analizador predictivo basado en Machine Learning"""
    
    def __init__(self, model_path: str = "models/"):
        self.model_path = model_path
        self.anomaly_detector = None
        self.threat_classifier = None
        self.scaler = StandardScaler()
        self.feature_columns = [
            'vulnerability_count', 'threat_score', 'response_time',
            'payload_size', 'ports_count', 'tech_count', 'hour_of_day',
            'day_of_week', 'is_weekend'
        ]
        self.models_loaded = False
        self._ensure_model_directory()
    
    def _ensure_model_directory(self):
        """Asegura que el directorio de modelos existe"""
        if not os.path.exists(self.model_path):
            os.makedirs(self.model_path)
    
    def extract_features(self, event: SecurityEvent) -> np.ndarray:
        """Extrae caracterÃ­sticas numÃ©ricas de un evento de seguridad"""
        features = {
            'vulnerability_count': event.vulnerability_count,
            'threat_score': event.threat_score,
            'response_time': event.response_time,
            'payload_size': event.payload_size,
            'ports_count': len(event.ports_open),
            'tech_count': len(event.technologies),
            'hour_of_day': event.timestamp.hour,
            'day_of_week': event.timestamp.weekday(),
            'is_weekend': 1 if event.timestamp.weekday() >= 5 else 0
        }
        
        return np.array([features[col] for col in self.feature_columns]).reshape(1, -1)
    
    def train_anomaly_detector(self, events: List[SecurityEvent]):
        """Entrena el detector de anomalÃ­as"""
        logger.info(f"Entrenando detector de anomalÃ­as con {len(events)} eventos")
        
        # Extraer caracterÃ­sticas
        features = []
        for event in events:
            feature_vector = self.extract_features(event).flatten()
            features.append(feature_vector)
        
        X = np.array(features)
        
        # Normalizar caracterÃ­sticas
        X_scaled = self.scaler.fit_transform(X)
        
        # Entrenar Isolation Forest
        self.anomaly_detector = IsolationForest(
            contamination=0.1,
            random_state=42,
            n_estimators=100
        )
        self.anomaly_detector.fit(X_scaled)
        
        # Guardar modelo
        self._save_models()
        logger.info("Detector de anomalÃ­as entrenado exitosamente")
    
    def train_threat_classifier(self, events: List[SecurityEvent]):
        """Entrena el clasificador de amenazas"""
        logger.info(f"Entrenando clasificador de amenazas con {len(events)} eventos")
        
        # Extraer caracterÃ­sticas y etiquetas
        features = []
        labels = []
        
        for event in events:
            feature_vector = self.extract_features(event).flatten()
            features.append(feature_vector)
            labels.append(1 if event.is_malicious else 0)
        
        X = np.array(features)
        y = np.array(labels)
        
        # Dividir datos
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # Normalizar
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # Entrenar Random Forest
        self.threat_classifier = RandomForestClassifier(
            n_estimators=100,
            random_state=42,
            class_weight='balanced'
        )
        self.threat_classifier.fit(X_train_scaled, y_train)
        
        # Evaluar modelo
        y_pred = self.threat_classifier.predict(X_test_scaled)
        accuracy = accuracy_score(y_test, y_pred)
        
        logger.info(f"PrecisiÃ³n del clasificador: {accuracy:.3f}")
        logger.info(f"Reporte de clasificaciÃ³n:\n{classification_report(y_test, y_pred)}")
        
        # Guardar modelo
        self._save_models()
        logger.info("Clasificador de amenazas entrenado exitosamente")
    
    def _save_models(self):
        """Guarda los modelos entrenados"""
        if self.anomaly_detector:
            joblib.dump(self.anomaly_detector, f"{self.model_path}/anomaly_detector.pkl")
        if self.threat_classifier:
            joblib.dump(self.threat_classifier, f"{self.model_path}/threat_classifier.pkl")
        joblib.dump(self.scaler, f"{self.model_path}/scaler.pkl")
    
    def load_models(self):
        """Carga los modelos pre-entrenados"""
        try:
            if os.path.exists(f"{self.model_path}/anomaly_detector.pkl"):
                self.anomaly_detector = joblib.load(f"{self.model_path}/anomaly_detector.pkl")
            
            if os.path.exists(f"{self.model_path}/threat_classifier.pkl"):
                self.threat_classifier = joblib.load(f"{self.model_path}/threat_classifier.pkl")
            
            if os.path.exists(f"{self.model_path}/scaler.pkl"):
                self.scaler = joblib.load(f"{self.model_path}/scaler.pkl")
            
            self.models_loaded = True
            logger.info("Modelos cargados exitosamente")
        except Exception as e:
            logger.error(f"Error cargando modelos: {e}")
            self.models_loaded = False
    
    def predict_threat(self, event: SecurityEvent) -> PredictionResult:
        """Predice si un evento es una amenaza"""
        if not self.models_loaded:
            self.load_models()
        
        features = self.extract_features(event)
        features_scaled = self.scaler.transform(features)
        
        # DetecciÃ³n de anomalÃ­as
        anomaly_score = 0.0
        if self.anomaly_detector:
            anomaly_pred = self.anomaly_detector.predict(features_scaled)[0]
            anomaly_score = abs(self.anomaly_detector.score_samples(features_scaled)[0])
            is_anomaly = anomaly_pred == -1
        else:
            is_anomaly = False
        
        # ClasificaciÃ³n de amenazas
        threat_probability = 0.0
        prediction = "benign"
        
        if self.threat_classifier:
            threat_proba = self.threat_classifier.predict_proba(features_scaled)[0]
            threat_probability = threat_proba[1] if len(threat_proba) > 1 else 0.0
            prediction = "malicious" if threat_probability > 0.5 else "benign"
        
        # Calcular puntuaciÃ³n de riesgo
        risk_score = self._calculate_risk_score(
            event, threat_probability, anomaly_score, is_anomaly
        )
        
        # Generar recomendaciones
        recommendations = self._generate_recommendations(
            event, prediction, risk_score, is_anomaly
        )
        
        # Importancia de caracterÃ­sticas
        feature_importance = {}
        if self.threat_classifier:
            importances = self.threat_classifier.feature_importances_
            feature_importance = dict(zip(self.feature_columns, importances))
        
        return PredictionResult(
            prediction=prediction,
            confidence=max(threat_probability, 1 - threat_probability),
            risk_score=risk_score,
            anomaly_score=anomaly_score,
            recommendations=recommendations,
            features_importance=feature_importance,
            timestamp=datetime.now()
        )
    
    def _calculate_risk_score(self, event: SecurityEvent, threat_prob: float, 
                            anomaly_score: float, is_anomaly: bool) -> float:
        """Calcula la puntuaciÃ³n de riesgo basada en mÃºltiples factores"""
        base_score = threat_prob * 100
        
        # Ajustes por anomalÃ­a
        if is_anomaly:
            base_score += 20
        
        # Ajustes por vulnerabilidades
        if event.vulnerability_count > 10:
            base_score += 15
        elif event.vulnerability_count > 5:
            base_score += 10
        
        # Ajustes por puntuaciÃ³n de amenaza
        if event.threat_score > 8:
            base_score += 15
        elif event.threat_score > 6:
            base_score += 10
        
        # Ajustes por puertos abiertos
        dangerous_ports = [22, 23, 135, 139, 445, 1433, 3389]
        if any(port in dangerous_ports for port in event.ports_open):
            base_score += 10
        
        return min(base_score, 100.0)
    
    def _generate_recommendations(self, event: SecurityEvent, prediction: str, 
                                risk_score: float, is_anomaly: bool) -> List[str]:
        """Genera recomendaciones basadas en el anÃ¡lisis"""
        recommendations = []
        
        if prediction == "malicious":
            recommendations.append("ğŸš¨ Actividad maliciosa detectada - Investigar inmediatamente")
            recommendations.append("ğŸ”’ Considerar bloquear la IP de origen")
        
        if is_anomaly:
            recommendations.append("âš ï¸ Comportamiento anÃ³malo detectado - Monitorear de cerca")
        
        if risk_score > 80:
            recommendations.append("ğŸ”´ Riesgo CRÃTICO - Respuesta inmediata requerida")
        elif risk_score > 60:
            recommendations.append("ğŸŸ¡ Riesgo ALTO - InvestigaciÃ³n prioritaria")
        elif risk_score > 40:
            recommendations.append("ğŸŸ  Riesgo MEDIO - Monitoreo continuo")
        
        if event.vulnerability_count > 10:
            recommendations.append("ğŸ›¡ï¸ MÃºltiples vulnerabilidades - Aplicar parches urgentemente")
        
        if len(event.ports_open) > 20:
            recommendations.append("ğŸ” Muchos puertos abiertos - Revisar configuraciÃ³n de firewall")
        
        dangerous_ports = [22, 23, 135, 139, 445, 1433, 3389]
        if any(port in dangerous_ports for port in event.ports_open):
            recommendations.append("âš ï¸ Puertos peligrosos expuestos - Asegurar servicios")
        
        return recommendations
    
    def detect_threat_patterns(self, events: List[SecurityEvent]) -> List[ThreatPattern]:
        """Detecta patrones de amenazas en los eventos"""
        patterns = []
        
        # Convertir eventos a DataFrame para anÃ¡lisis
        df_data = []
        for event in events:
            df_data.append({
                'timestamp': event.timestamp,
                'source_ip': event.source_ip,
                'target_domain': event.target_domain,
                'vulnerability_count': event.vulnerability_count,
                'threat_score': event.threat_score,
                'is_malicious': event.is_malicious
            })
        
        df = pd.DataFrame(df_data)
        
        if len(df) == 0:
            return patterns
        
        # PatrÃ³n 1: IPs con mÃºltiples ataques
        ip_attacks = df[df['is_malicious'] == True].groupby('source_ip').size()
        frequent_attackers = ip_attacks[ip_attacks >= 3]
        
        for ip, count in frequent_attackers.items():
            patterns.append(ThreatPattern(
                pattern_id=f"frequent_attacker_{ip}",
                pattern_type="Frequent Attacker",
                frequency=count,
                severity="HIGH",
                indicators=[f"IP {ip} realizÃ³ {count} ataques"],
                first_seen=df[df['source_ip'] == ip]['timestamp'].min(),
                last_seen=df[df['source_ip'] == ip]['timestamp'].max(),
                confidence=0.9
            ))
        
        # PatrÃ³n 2: Dominios con alta concentraciÃ³n de vulnerabilidades
        domain_vulns = df.groupby('target_domain')['vulnerability_count'].sum()
        vulnerable_domains = domain_vulns[domain_vulns >= 50]
        
        for domain, vuln_count in vulnerable_domains.items():
            patterns.append(ThreatPattern(
                pattern_id=f"vulnerable_domain_{domain}",
                pattern_type="Vulnerable Target",
                frequency=len(df[df['target_domain'] == domain]),
                severity="MEDIUM",
                indicators=[f"Dominio {domain} tiene {vuln_count} vulnerabilidades"],
                first_seen=df[df['target_domain'] == domain]['timestamp'].min(),
                last_seen=df[df['target_domain'] == domain]['timestamp'].max(),
                confidence=0.8
            ))
        
        # PatrÃ³n 3: Picos de actividad temporal
        df['hour'] = df['timestamp'].dt.hour
        hourly_activity = df.groupby('hour').size()
        avg_activity = hourly_activity.mean()
        peak_hours = hourly_activity[hourly_activity > avg_activity * 2]
        
        for hour, activity in peak_hours.items():
            patterns.append(ThreatPattern(
                pattern_id=f"peak_activity_{hour}",
                pattern_type="Temporal Peak",
                frequency=activity,
                severity="LOW",
                indicators=[f"Pico de actividad a las {hour}:00 con {activity} eventos"],
                first_seen=df['timestamp'].min(),
                last_seen=df['timestamp'].max(),
                confidence=0.6
            ))
        
        logger.info(f"Detectados {len(patterns)} patrones de amenazas")
        return patterns
    
    def generate_predictive_report(self, events: List[SecurityEvent]) -> Dict[str, Any]:
        """Genera un reporte predictivo completo"""
        logger.info("Generando reporte predictivo")
        
        # AnÃ¡lisis de eventos
        predictions = []
        for event in events:
            pred = self.predict_threat(event)
            predictions.append(pred)
        
        # Detectar patrones
        patterns = self.detect_threat_patterns(events)
        
        # EstadÃ­sticas generales
        total_events = len(events)
        malicious_events = sum(1 for p in predictions if p.prediction == "malicious")
        high_risk_events = sum(1 for p in predictions if p.risk_score > 70)
        anomalies = sum(1 for p in predictions if p.anomaly_score > 0.5)
        
        # Tendencias temporales
        df = pd.DataFrame([asdict(event) for event in events])
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        daily_trends = df.groupby(df['timestamp'].dt.date).size().to_dict()
        
        # Recomendaciones estratÃ©gicas
        strategic_recommendations = self._generate_strategic_recommendations(
            predictions, patterns, total_events, malicious_events
        )
        
        report = {
            "timestamp": datetime.now().isoformat(),
            "summary": {
                "total_events": total_events,
                "malicious_events": malicious_events,
                "malicious_rate": malicious_events / total_events if total_events > 0 else 0,
                "high_risk_events": high_risk_events,
                "anomalies_detected": anomalies,
                "patterns_found": len(patterns)
            },
            "predictions": [asdict(p) for p in predictions],
            "threat_patterns": [asdict(p) for p in patterns],
            "daily_trends": {str(k): v for k, v in daily_trends.items()},
            "strategic_recommendations": strategic_recommendations,
            "model_performance": {
                "anomaly_detector_loaded": self.anomaly_detector is not None,
                "threat_classifier_loaded": self.threat_classifier is not None,
                "models_status": "operational" if self.models_loaded else "training_required"
            }
        }
        
        return report
    
    def _generate_strategic_recommendations(self, predictions: List[PredictionResult], 
                                          patterns: List[ThreatPattern], 
                                          total_events: int, malicious_events: int) -> List[str]:
        """Genera recomendaciones estratÃ©gicas basadas en el anÃ¡lisis"""
        recommendations = []
        
        malicious_rate = malicious_events / total_events if total_events > 0 else 0
        
        if malicious_rate > 0.3:
            recommendations.append("ğŸš¨ CRÃTICO: Tasa de actividad maliciosa muy alta (>30%) - Implementar medidas de seguridad inmediatas")
        elif malicious_rate > 0.1:
            recommendations.append("âš ï¸ ALTO: Tasa de actividad maliciosa elevada (>10%) - Reforzar monitoreo")
        
        high_risk_count = sum(1 for p in predictions if p.risk_score > 70)
        if high_risk_count > total_events * 0.2:
            recommendations.append("ğŸ”´ Muchos eventos de alto riesgo - Revisar configuraciones de seguridad")
        
        frequent_attackers = [p for p in patterns if p.pattern_type == "Frequent Attacker"]
        if len(frequent_attackers) > 0:
            recommendations.append(f"ğŸ›¡ï¸ {len(frequent_attackers)} atacantes frecuentes identificados - Considerar blacklisting")
        
        vulnerable_targets = [p for p in patterns if p.pattern_type == "Vulnerable Target"]
        if len(vulnerable_targets) > 0:
            recommendations.append(f"ğŸ”§ {len(vulnerable_targets)} objetivos vulnerables - Priorizar parcheo")
        
        if not self.models_loaded:
            recommendations.append("ğŸ¤– Modelos ML no entrenados - Entrenar con datos histÃ³ricos para mejorar precisiÃ³n")
        
        return recommendations

# Funciones de utilidad
def create_sample_events(count: int = 100) -> List[SecurityEvent]:
    """Crea eventos de muestra para testing"""
    import random
    from datetime import datetime, timedelta
    
    events = []
    base_time = datetime.now() - timedelta(days=30)
    
    for i in range(count):
        timestamp = base_time + timedelta(
            days=random.randint(0, 30),
            hours=random.randint(0, 23),
            minutes=random.randint(0, 59)
        )
        
        is_malicious = random.random() < 0.2  # 20% maliciosos
        
        event = SecurityEvent(
            timestamp=timestamp,
            event_type=random.choice(["scan", "probe", "attack", "reconnaissance"]),
            severity=random.choice(["LOW", "MEDIUM", "HIGH", "CRITICAL"]),
            source_ip=f"192.168.{random.randint(1, 255)}.{random.randint(1, 255)}",
            target_domain=f"target{random.randint(1, 10)}.com",
            vulnerability_count=random.randint(0, 50) if is_malicious else random.randint(0, 10),
            threat_score=random.uniform(7, 10) if is_malicious else random.uniform(1, 6),
            technologies=[f"tech{i}" for i in range(random.randint(1, 5))],
            ports_open=[random.randint(1, 65535) for _ in range(random.randint(1, 20))],
            response_time=random.uniform(0.1, 5.0),
            status_code=random.choice([200, 404, 403, 500]),
            payload_size=random.randint(100, 10000),
            user_agent="Mozilla/5.0",
            country=random.choice(["US", "CN", "RU", "BR", "IN"]),
            is_malicious=is_malicious
        )
        events.append(event)
    
    return events

def main():
    """FunciÃ³n principal para testing"""
    # Crear analizador
    analyzer = MLPredictiveAnalyzer()
    
    # Crear eventos de muestra
    events = create_sample_events(200)
    
    # Entrenar modelos
    analyzer.train_anomaly_detector(events)
    analyzer.train_threat_classifier(events)
    
    # Generar reporte
    test_events = create_sample_events(50)
    report = analyzer.generate_predictive_report(test_events)
    
    print("=== REPORTE PREDICTIVO ===")
    print(json.dumps(report["summary"], indent=2))
    print(f"\nPatrones detectados: {len(report['threat_patterns'])}")
    print(f"Recomendaciones estratÃ©gicas: {len(report['strategic_recommendations'])}")
    
    for rec in report["strategic_recommendations"]:
        print(f"- {rec}")

if __name__ == "__main__":
    main()