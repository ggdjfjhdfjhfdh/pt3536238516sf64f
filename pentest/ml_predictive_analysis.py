#!/usr/bin/env python3
"""
Módulo de IA/ML para Análisis Predictivo
Proporciona capacidades de machine learning para análisis predictivo de seguridad
"""

import json
import logging
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, asdict
from sklearn.ensemble import IsolationForest, RandomForestClassifier
from sklearn.cluster import DBSCAN
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score
import joblib
import os

# Configuración de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class SecurityEvent:
    """Representa un evento de seguridad para análisis"""
    timestamp: datetime
    event_type: str
    severity: str
    source_ip: str
    target_domain: str
    vulnerability_count: int
    threat_score: float
    technologies: List[str]
    ports_open: List[int]
    response_time: float
    status_code: int
    payload_size: int
    user_agent: str
    country: str
    is_malicious: bool = False

@dataclass
class PredictionResult:
    """Resultado de predicción de ML"""
    prediction: str
    confidence: float
    risk_score: float
    anomaly_score: float
    recommendations: List[str]
    features_importance: Dict[str, float]
    timestamp: datetime

@dataclass
class ThreatPattern:
    """Patrón de amenaza identificado"""
    pattern_id: str
    pattern_type: str
    frequency: int
    severity: str
    indicators: List[str]
    first_seen: datetime
    last_seen: datetime
    confidence: float

class MLPredictiveAnalyzer:
    """Analizador predictivo basado en Machine Learning"""
    
    def __init__(self, model_path: str = "models/"):
        self.model_path = model_path
        self.anomaly_detector = None
        self.threat_classifier = None
        self.scaler = StandardScaler()
        self.feature_columns = [
            'vulnerability_count', 'threat_score', 'response_time',
            'payload_size', 'ports_count', 'tech_count', 'hour_of_day',
            'day_of_week', 'is_weekend'
        ]
        self.models_loaded = False
        self._ensure_model_directory()
    
    def _ensure_model_directory(self):
        """Asegura que el directorio de modelos existe"""
        if not os.path.exists(self.model_path):
            os.makedirs(self.model_path)
    
    def extract_features(self, event: SecurityEvent) -> np.ndarray:
        """Extrae características numéricas de un evento de seguridad"""
        features = {
            'vulnerability_count': event.vulnerability_count,
            'threat_score': event.threat_score,
            'response_time': event.response_time,
            'payload_size': event.payload_size,
            'ports_count': len(event.ports_open),
            'tech_count': len(event.technologies),
            'hour_of_day': event.timestamp.hour,
            'day_of_week': event.timestamp.weekday(),
            'is_weekend': 1 if event.timestamp.weekday() >= 5 else 0
        }
        
        return np.array([features[col] for col in self.feature_columns]).reshape(1, -1)
    
    def train_anomaly_detector(self, events: List[SecurityEvent]):
        """Entrena el detector de anomalías"""
        logger.info(f"Entrenando detector de anomalías con {len(events)} eventos")
        
        # Extraer características
        features = []
        for event in events:
            feature_vector = self.extract_features(event).flatten()
            features.append(feature_vector)
        
        X = np.array(features)
        
        # Normalizar características
        X_scaled = self.scaler.fit_transform(X)
        
        # Entrenar Isolation Forest
        self.anomaly_detector = IsolationForest(
            contamination=0.1,
            random_state=42,
            n_estimators=100
        )
        self.anomaly_detector.fit(X_scaled)
        
        # Guardar modelo
        self._save_models()
        logger.info("Detector de anomalías entrenado exitosamente")
    
    def train_threat_classifier(self, events: List[SecurityEvent]):
        """Entrena el clasificador de amenazas"""
        logger.info(f"Entrenando clasificador de amenazas con {len(events)} eventos")
        
        # Extraer características y etiquetas
        features = []
        labels = []
        
        for event in events:
            feature_vector = self.extract_features(event).flatten()
            features.append(feature_vector)
            labels.append(1 if event.is_malicious else 0)
        
        X = np.array(features)
        y = np.array(labels)
        
        # Dividir datos
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # Normalizar
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # Entrenar Random Forest
        self.threat_classifier = RandomForestClassifier(
            n_estimators=100,
            random_state=42,
            class_weight='balanced'
        )
        self.threat_classifier.fit(X_train_scaled, y_train)
        
        # Evaluar modelo
        y_pred = self.threat_classifier.predict(X_test_scaled)
        accuracy = accuracy_score(y_test, y_pred)
        
        logger.info(f"Precisión del clasificador: {accuracy:.3f}")
        logger.info(f"Reporte de clasificación:\n{classification_report(y_test, y_pred)}")
        
        # Guardar modelo
        self._save_models()
        logger.info("Clasificador de amenazas entrenado exitosamente")
    
    def _save_models(self):
        """Guarda los modelos entrenados"""
        if self.anomaly_detector:
            joblib.dump(self.anomaly_detector, f"{self.model_path}/anomaly_detector.pkl")
        if self.threat_classifier:
            joblib.dump(self.threat_classifier, f"{self.model_path}/threat_classifier.pkl")
        joblib.dump(self.scaler, f"{self.model_path}/scaler.pkl")
    
    def load_models(self):
        """Carga los modelos pre-entrenados"""
        try:
            if os.path.exists(f"{self.model_path}/anomaly_detector.pkl"):
                self.anomaly_detector = joblib.load(f"{self.model_path}/anomaly_detector.pkl")
            
            if os.path.exists(f"{self.model_path}/threat_classifier.pkl"):
                self.threat_classifier = joblib.load(f"{self.model_path}/threat_classifier.pkl")
            
            if os.path.exists(f"{self.model_path}/scaler.pkl"):
                self.scaler = joblib.load(f"{self.model_path}/scaler.pkl")
            
            self.models_loaded = True
            logger.info("Modelos cargados exitosamente")
        except Exception as e:
            logger.error(f"Error cargando modelos: {e}")
            self.models_loaded = False
    
    def predict_threat(self, event: SecurityEvent) -> PredictionResult:
        """Predice si un evento es una amenaza"""
        if not self.models_loaded:
            self.load_models()
        
        features = self.extract_features(event)
        features_scaled = self.scaler.transform(features)
        
        # Detección de anomalías
        anomaly_score = 0.0
        if self.anomaly_detector:
            anomaly_pred = self.anomaly_detector.predict(features_scaled)[0]
            anomaly_score = abs(self.anomaly_detector.score_samples(features_scaled)[0])
            is_anomaly = anomaly_pred == -1
        else:
            is_anomaly = False
        
        # Clasificación de amenazas
        threat_probability = 0.0
        prediction = "benign"
        
        if self.threat_classifier:
            threat_proba = self.threat_classifier.predict_proba(features_scaled)[0]
            threat_probability = threat_proba[1] if len(threat_proba) > 1 else 0.0
            prediction = "malicious" if threat_probability > 0.5 else "benign"
        
        # Calcular puntuación de riesgo
        risk_score = self._calculate_risk_score(
            event, threat_probability, anomaly_score, is_anomaly
        )
        
        # Generar recomendaciones
        recommendations = self._generate_recommendations(
            event, prediction, risk_score, is_anomaly
        )
        
        # Importancia de características
        feature_importance = {}
        if self.threat_classifier:
            importances = self.threat_classifier.feature_importances_
            feature_importance = dict(zip(self.feature_columns, importances))
        
        return PredictionResult(
            prediction=prediction,
            confidence=max(threat_probability, 1 - threat_probability),
            risk_score=risk_score,
            anomaly_score=anomaly_score,
            recommendations=recommendations,
            features_importance=feature_importance,
            timestamp=datetime.now()
        )
    
    def _calculate_risk_score(self, event: SecurityEvent, threat_prob: float, 
                            anomaly_score: float, is_anomaly: bool) -> float:
        """Calcula la puntuación de riesgo basada en múltiples factores"""
        base_score = threat_prob * 100
        
        # Ajustes por anomalía
        if is_anomaly:
            base_score += 20
        
        # Ajustes por vulnerabilidades
        if event.vulnerability_count > 10:
            base_score += 15
        elif event.vulnerability_count > 5:
            base_score += 10
        
        # Ajustes por puntuación de amenaza
        if event.threat_score > 8:
            base_score += 15
        elif event.threat_score > 6:
            base_score += 10
        
        # Ajustes por puertos abiertos
        dangerous_ports = [22, 23, 135, 139, 445, 1433, 3389]
        if any(port in dangerous_ports for port in event.ports_open):
            base_score += 10
        
        return min(base_score, 100.0)
    
    def _generate_recommendations(self, event: SecurityEvent, prediction: str, 
                                risk_score: float, is_anomaly: bool) -> List[str]:
        """Genera recomendaciones basadas en el análisis"""
        recommendations = []
        
        if prediction == "malicious":
            recommendations.append("🚨 Actividad maliciosa detectada - Investigar inmediatamente")
            recommendations.append("🔒 Considerar bloquear la IP de origen")
        
        if is_anomaly:
            recommendations.append("⚠️ Comportamiento anómalo detectado - Monitorear de cerca")
        
        if risk_score > 80:
            recommendations.append("🔴 Riesgo CRÍTICO - Respuesta inmediata requerida")
        elif risk_score > 60:
            recommendations.append("🟡 Riesgo ALTO - Investigación prioritaria")
        elif risk_score > 40:
            recommendations.append("🟠 Riesgo MEDIO - Monitoreo continuo")
        
        if event.vulnerability_count > 10:
            recommendations.append("🛡️ Múltiples vulnerabilidades - Aplicar parches urgentemente")
        
        if len(event.ports_open) > 20:
            recommendations.append("🔐 Muchos puertos abiertos - Revisar configuración de firewall")
        
        dangerous_ports = [22, 23, 135, 139, 445, 1433, 3389]
        if any(port in dangerous_ports for port in event.ports_open):
            recommendations.append("⚠️ Puertos peligrosos expuestos - Asegurar servicios")
        
        return recommendations
    
    def detect_threat_patterns(self, events: List[SecurityEvent]) -> List[ThreatPattern]:
        """Detecta patrones de amenazas en los eventos"""
        patterns = []
        
        # Convertir eventos a DataFrame para análisis
        df_data = []
        for event in events:
            df_data.append({
                'timestamp': event.timestamp,
                'source_ip': event.source_ip,
                'target_domain': event.target_domain,
                'vulnerability_count': event.vulnerability_count,
                'threat_score': event.threat_score,
                'is_malicious': event.is_malicious
            })
        
        df = pd.DataFrame(df_data)
        
        if len(df) == 0:
            return patterns
        
        # Patrón 1: IPs con múltiples ataques
        ip_attacks = df[df['is_malicious'] == True].groupby('source_ip').size()
        frequent_attackers = ip_attacks[ip_attacks >= 3]
        
        for ip, count in frequent_attackers.items():
            patterns.append(ThreatPattern(
                pattern_id=f"frequent_attacker_{ip}",
                pattern_type="Frequent Attacker",
                frequency=count,
                severity="HIGH",
                indicators=[f"IP {ip} realizó {count} ataques"],
                first_seen=df[df['source_ip'] == ip]['timestamp'].min(),
                last_seen=df[df['source_ip'] == ip]['timestamp'].max(),
                confidence=0.9
            ))
        
        # Patrón 2: Dominios con alta concentración de vulnerabilidades
        domain_vulns = df.groupby('target_domain')['vulnerability_count'].sum()
        vulnerable_domains = domain_vulns[domain_vulns >= 50]
        
        for domain, vuln_count in vulnerable_domains.items():
            patterns.append(ThreatPattern(
                pattern_id=f"vulnerable_domain_{domain}",
                pattern_type="Vulnerable Target",
                frequency=len(df[df['target_domain'] == domain]),
                severity="MEDIUM",
                indicators=[f"Dominio {domain} tiene {vuln_count} vulnerabilidades"],
                first_seen=df[df['target_domain'] == domain]['timestamp'].min(),
                last_seen=df[df['target_domain'] == domain]['timestamp'].max(),
                confidence=0.8
            ))
        
        # Patrón 3: Picos de actividad temporal
        df['hour'] = df['timestamp'].dt.hour
        hourly_activity = df.groupby('hour').size()
        avg_activity = hourly_activity.mean()
        peak_hours = hourly_activity[hourly_activity > avg_activity * 2]
        
        for hour, activity in peak_hours.items():
            patterns.append(ThreatPattern(
                pattern_id=f"peak_activity_{hour}",
                pattern_type="Temporal Peak",
                frequency=activity,
                severity="LOW",
                indicators=[f"Pico de actividad a las {hour}:00 con {activity} eventos"],
                first_seen=df['timestamp'].min(),
                last_seen=df['timestamp'].max(),
                confidence=0.6
            ))
        
        logger.info(f"Detectados {len(patterns)} patrones de amenazas")
        return patterns
    
    def generate_predictive_report(self, events: List[SecurityEvent]) -> Dict[str, Any]:
        """Genera un reporte predictivo completo"""
        logger.info("Generando reporte predictivo")
        
        # Análisis de eventos
        predictions = []
        for event in events:
            pred = self.predict_threat(event)
            predictions.append(pred)
        
        # Detectar patrones
        patterns = self.detect_threat_patterns(events)
        
        # Estadísticas generales
        total_events = len(events)
        malicious_events = sum(1 for p in predictions if p.prediction == "malicious")
        high_risk_events = sum(1 for p in predictions if p.risk_score > 70)
        anomalies = sum(1 for p in predictions if p.anomaly_score > 0.5)
        
        # Tendencias temporales
        df = pd.DataFrame([asdict(event) for event in events])
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        daily_trends = df.groupby(df['timestamp'].dt.date).size().to_dict()
        
        # Recomendaciones estratégicas
        strategic_recommendations = self._generate_strategic_recommendations(
            predictions, patterns, total_events, malicious_events
        )
        
        report = {
            "timestamp": datetime.now().isoformat(),
            "summary": {
                "total_events": total_events,
                "malicious_events": malicious_events,
                "malicious_rate": malicious_events / total_events if total_events > 0 else 0,
                "high_risk_events": high_risk_events,
                "anomalies_detected": anomalies,
                "patterns_found": len(patterns)
            },
            "predictions": [asdict(p) for p in predictions],
            "threat_patterns": [asdict(p) for p in patterns],
            "daily_trends": {str(k): v for k, v in daily_trends.items()},
            "strategic_recommendations": strategic_recommendations,
            "model_performance": {
                "anomaly_detector_loaded": self.anomaly_detector is not None,
                "threat_classifier_loaded": self.threat_classifier is not None,
                "models_status": "operational" if self.models_loaded else "training_required"
            }
        }
        
        return report
    
    def _generate_strategic_recommendations(self, predictions: List[PredictionResult], 
                                          patterns: List[ThreatPattern], 
                                          total_events: int, malicious_events: int) -> List[str]:
        """Genera recomendaciones estratégicas basadas en el análisis"""
        recommendations = []
        
        malicious_rate = malicious_events / total_events if total_events > 0 else 0
        
        if malicious_rate > 0.3:
            recommendations.append("🚨 CRÍTICO: Tasa de actividad maliciosa muy alta (>30%) - Implementar medidas de seguridad inmediatas")
        elif malicious_rate > 0.1:
            recommendations.append("⚠️ ALTO: Tasa de actividad maliciosa elevada (>10%) - Reforzar monitoreo")
        
        high_risk_count = sum(1 for p in predictions if p.risk_score > 70)
        if high_risk_count > total_events * 0.2:
            recommendations.append("🔴 Muchos eventos de alto riesgo - Revisar configuraciones de seguridad")
        
        frequent_attackers = [p for p in patterns if p.pattern_type == "Frequent Attacker"]
        if len(frequent_attackers) > 0:
            recommendations.append(f"🛡️ {len(frequent_attackers)} atacantes frecuentes identificados - Considerar blacklisting")
        
        vulnerable_targets = [p for p in patterns if p.pattern_type == "Vulnerable Target"]
        if len(vulnerable_targets) > 0:
            recommendations.append(f"🔧 {len(vulnerable_targets)} objetivos vulnerables - Priorizar parcheo")
        
        if not self.models_loaded:
            recommendations.append("🤖 Modelos ML no entrenados - Entrenar con datos históricos para mejorar precisión")
        
        return recommendations

# Funciones de utilidad
def create_sample_events(count: int = 100) -> List[SecurityEvent]:
    """Crea eventos de muestra para testing"""
    import random
    from datetime import datetime, timedelta
    
    events = []
    base_time = datetime.now() - timedelta(days=30)
    
    for i in range(count):
        timestamp = base_time + timedelta(
            days=random.randint(0, 30),
            hours=random.randint(0, 23),
            minutes=random.randint(0, 59)
        )
        
        is_malicious = random.random() < 0.2  # 20% maliciosos
        
        event = SecurityEvent(
            timestamp=timestamp,
            event_type=random.choice(["scan", "probe", "attack", "reconnaissance"]),
            severity=random.choice(["LOW", "MEDIUM", "HIGH", "CRITICAL"]),
            source_ip=f"192.168.{random.randint(1, 255)}.{random.randint(1, 255)}",
            target_domain=f"target{random.randint(1, 10)}.com",
            vulnerability_count=random.randint(0, 50) if is_malicious else random.randint(0, 10),
            threat_score=random.uniform(7, 10) if is_malicious else random.uniform(1, 6),
            technologies=[f"tech{i}" for i in range(random.randint(1, 5))],
            ports_open=[random.randint(1, 65535) for _ in range(random.randint(1, 20))],
            response_time=random.uniform(0.1, 5.0),
            status_code=random.choice([200, 404, 403, 500]),
            payload_size=random.randint(100, 10000),
            user_agent="Mozilla/5.0",
            country=random.choice(["US", "CN", "RU", "BR", "IN"]),
            is_malicious=is_malicious
        )
        events.append(event)
    
    return events

def main():
    """Función principal para testing"""
    # Crear analizador
    analyzer = MLPredictiveAnalyzer()
    
    # Crear eventos de muestra
    events = create_sample_events(200)
    
    # Entrenar modelos
    analyzer.train_anomaly_detector(events)
    analyzer.train_threat_classifier(events)
    
    # Generar reporte
    test_events = create_sample_events(50)
    report = analyzer.generate_predictive_report(test_events)
    
    print("=== REPORTE PREDICTIVO ===")
    print(json.dumps(report["summary"], indent=2))
    print(f"\nPatrones detectados: {len(report['threat_patterns'])}")
    print(f"Recomendaciones estratégicas: {len(report['strategic_recommendations'])}")
    
    for rec in report["strategic_recommendations"]:
        print(f"- {rec}")

if __name__ == "__main__":
    main()