#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Motor de análisis de correlación avanzado para datos de pentest.
Identifica patrones, relaciones y dependencias entre vulnerabilidades.
"""

import logging
import re
from collections import defaultdict, Counter
from dataclasses import dataclass
from typing import Any, Dict, List, Optional, Set, Tuple
from urllib.parse import urlparse
import ipaddress

log = logging.getLogger(__name__)


@dataclass
class CorrelationResult:
    """Resultado de análisis de correlación."""
    correlation_type: str
    confidence: float
    description: str
    affected_assets: List[str]
    risk_multiplier: float
    recommendations: List[str]
    evidence: Dict[str, Any]


@dataclass
class AttackPath:
    """Ruta de ataque identificada."""
    path_id: str
    steps: List[Dict[str, Any]]
    risk_score: float
    likelihood: float
    impact: str
    mitigation_priority: int


class AdvancedCorrelationEngine:
    """Motor de correlación avanzado para análisis de seguridad."""
    
    def __init__(self):
        self.log = logging.getLogger(f"{__name__}.{self.__class__.__name__}")
        self.correlations: List[CorrelationResult] = []
        self.attack_paths: List[AttackPath] = []
        
        # Patrones de tecnologías conocidas
        self.tech_patterns = {
            'web_servers': ['apache', 'nginx', 'iis', 'tomcat', 'jetty'],
            'databases': ['mysql', 'postgresql', 'mongodb', 'redis', 'elasticsearch'],
            'cms': ['wordpress', 'drupal', 'joomla', 'magento'],
            'frameworks': ['django', 'rails', 'laravel', 'spring', 'express'],
            'languages': ['php', 'python', 'java', 'nodejs', 'asp.net']
        }
        
        # Puertos críticos y sus servicios
        self.critical_ports = {
            22: 'ssh', 23: 'telnet', 25: 'smtp', 53: 'dns',
            80: 'http', 135: 'rpc', 139: 'netbios', 443: 'https',
            445: 'smb', 993: 'imaps', 995: 'pop3s', 1433: 'mssql',
            3306: 'mysql', 3389: 'rdp', 5432: 'postgresql', 6379: 'redis',
            27017: 'mongodb'
        }
    
    def analyze_all_correlations(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Ejecuta todos los análisis de correlación disponibles."""
        self.log.info("Iniciando análisis de correlación completo")
        
        try:
            # Limpiar resultados anteriores
            self.correlations.clear()
            self.attack_paths.clear()
            
            # Ejecutar análisis específicos
            self._analyze_technology_stack_vulnerabilities(data)
            self._analyze_credential_exposure_chains(data)
            self._analyze_network_service_correlations(data)
            self._analyze_web_application_attack_surface(data)
            self._analyze_configuration_drift_patterns(data)
            self._analyze_cve_exploit_chains(data)
            self._analyze_data_exposure_patterns(data)
            self._identify_attack_paths(data)
            
            # Generar resumen de correlaciones
            summary = self._generate_correlation_summary()
            
            self.log.info(f"Análisis completado: {len(self.correlations)} correlaciones, {len(self.attack_paths)} rutas de ataque")
            
            return {
                'correlations': [self._correlation_to_dict(c) for c in self.correlations],
                'attack_paths': [self._attack_path_to_dict(p) for p in self.attack_paths],
                'summary': summary,
                'risk_assessment': self._calculate_correlation_risk()
            }
            
        except Exception as e:
            self.log.error(f"Error en análisis de correlación: {e}")
            return {'correlations': [], 'attack_paths': [], 'summary': {}, 'risk_assessment': {}}
    
    def _analyze_technology_stack_vulnerabilities(self, data: Dict[str, Any]) -> None:
        """Analiza correlaciones en el stack tecnológico."""
        nuclei_data = data.get('nuclei_data', [])
        nmap_data = data.get('nmap_data', [])
        
        # Agrupar vulnerabilidades por host y tecnología
        host_tech_vulns = defaultdict(lambda: defaultdict(list))
        
        for vuln in nuclei_data:
            host = self._extract_host(vuln.get('host', ''))
            tags = vuln.get('info', {}).get('tags', [])
            
            for tag in tags:
                for tech_category, techs in self.tech_patterns.items():
                    if any(tech in tag.lower() for tech in techs):
                        host_tech_vulns[host][tech_category].append(vuln)
        
        # Identificar hosts con múltiples vulnerabilidades en la misma tecnología
        for host, tech_vulns in host_tech_vulns.items():
            for tech_category, vulns in tech_vulns.items():
                if len(vulns) >= 2:
                    severity_counts = Counter(v.get('info', {}).get('severity', 'info') for v in vulns)
                    
                    confidence = min(0.9, len(vulns) * 0.2)
                    risk_multiplier = 1.0 + (len(vulns) * 0.3)
                    
                    correlation = CorrelationResult(
                        correlation_type="technology_stack_vulnerability",
                        confidence=confidence,
                        description=f"Múltiples vulnerabilidades en {tech_category} en {host}",
                        affected_assets=[host],
                        risk_multiplier=risk_multiplier,
                        recommendations=[
                            f"Actualizar y endurecer la configuración de {tech_category}",
                            "Implementar segmentación de red",
                            "Aplicar parches de seguridad prioritarios"
                        ],
                        evidence={
                            'vulnerability_count': len(vulns),
                            'severity_distribution': dict(severity_counts),
                            'technology_category': tech_category,
                            'vulnerabilities': [v.get('info', {}).get('name', 'Unknown') for v in vulns]
                        }
                    )
                    
                    self.correlations.append(correlation)
    
    def _analyze_credential_exposure_chains(self, data: Dict[str, Any]) -> None:
        """Analiza cadenas de exposición de credenciales."""
        leaks_data = data.get('leaks_data', [])
        dir_brute_data = data.get('dir_brute_data', [])
        nuclei_data = data.get('nuclei_data', [])
        
        if not leaks_data:
            return
        
        # Identificar archivos sensibles expuestos
        sensitive_files = []
        admin_panels = []
        
        for directory in dir_brute_data:
            url = directory.get('url', '').lower()
            status_code = directory.get('status_code', 0)
            
            if status_code == 200:
                if any(keyword in url for keyword in ['.env', 'config', 'backup', 'dump', 'sql']):
                    sensitive_files.append(directory)
                elif any(keyword in url for keyword in ['admin', 'login', 'dashboard', 'panel']):
                    admin_panels.append(directory)
        
        # Buscar vulnerabilidades de autenticación
        auth_vulns = []
        for vuln in nuclei_data:
            tags = vuln.get('info', {}).get('tags', [])
            if any(tag in ['auth-bypass', 'default-login', 'weak-auth'] for tag in tags):
                auth_vulns.append(vuln)
        
        # Calcular riesgo de exposición de credenciales
        if leaks_data and (sensitive_files or admin_panels or auth_vulns):
            risk_factors = []
            risk_multiplier = 1.0
            
            if sensitive_files:
                risk_factors.append(f"{len(sensitive_files)} archivos sensibles expuestos")
                risk_multiplier += len(sensitive_files) * 0.5
            
            if admin_panels:
                risk_factors.append(f"{len(admin_panels)} paneles administrativos accesibles")
                risk_multiplier += len(admin_panels) * 0.3
            
            if auth_vulns:
                risk_factors.append(f"{len(auth_vulns)} vulnerabilidades de autenticación")
                risk_multiplier += len(auth_vulns) * 0.4
            
            correlation = CorrelationResult(
                correlation_type="credential_exposure_chain",
                confidence=0.8,
                description="Cadena de exposición de credenciales detectada",
                affected_assets=[leak.get('domain', 'unknown') for leak in leaks_data],
                risk_multiplier=risk_multiplier,
                recommendations=[
                    "Rotación inmediata de todas las credenciales comprometidas",
                    "Implementar autenticación multifactor (MFA)",
                    "Restringir acceso a archivos y paneles administrativos",
                    "Monitoreo continuo de credenciales en la dark web"
                ],
                evidence={
                    'leaked_accounts': len(leaks_data),
                    'sensitive_files': len(sensitive_files),
                    'admin_panels': len(admin_panels),
                    'auth_vulnerabilities': len(auth_vulns),
                    'risk_factors': risk_factors
                }
            )
            
            self.correlations.append(correlation)
    
    def _analyze_network_service_correlations(self, data: Dict[str, Any]) -> None:
        """Analiza correlaciones entre servicios de red."""
        nmap_data = data.get('nmap_data', [])
        nuclei_data = data.get('nuclei_data', [])
        
        # Agrupar puertos por host
        host_services = defaultdict(list)
        
        for port_info in nmap_data:
            if port_info.get('state') == 'open':
                host = port_info.get('host', 'unknown')
                port = port_info.get('port')
                service = port_info.get('service', {}).get('name', 'unknown')
                
                host_services[host].append({
                    'port': port,
                    'service': service,
                    'version': port_info.get('service', {}).get('version', ''),
                    'is_critical': port in self.critical_ports
                })
        
        # Identificar patrones de riesgo
        for host, services in host_services.items():
            critical_services = [s for s in services if s['is_critical']]
            
            # Múltiples servicios críticos en el mismo host
            if len(critical_services) >= 3:
                correlation = CorrelationResult(
                    correlation_type="critical_services_concentration",
                    confidence=0.7,
                    description=f"Concentración de servicios críticos en {host}",
                    affected_assets=[host],
                    risk_multiplier=1.0 + (len(critical_services) * 0.2),
                    recommendations=[
                        "Implementar segmentación de red",
                        "Cerrar servicios no esenciales",
                        "Aplicar principio de menor privilegio",
                        "Monitoreo continuo de servicios críticos"
                    ],
                    evidence={
                        'critical_services_count': len(critical_services),
                        'total_services': len(services),
                        'critical_ports': [s['port'] for s in critical_services],
                        'services': critical_services
                    }
                )
                
                self.correlations.append(correlation)
            
            # Servicios con versiones desactualizadas
            outdated_services = []
            for service in services:
                version = service.get('version', '')
                if version and any(old_indicator in version.lower() for old_indicator in ['2019', '2020', '2021']):
                    outdated_services.append(service)
            
            if len(outdated_services) >= 2:
                correlation = CorrelationResult(
                    correlation_type="outdated_services_cluster",
                    confidence=0.6,
                    description=f"Cluster de servicios desactualizados en {host}",
                    affected_assets=[host],
                    risk_multiplier=1.0 + (len(outdated_services) * 0.25),
                    recommendations=[
                        "Actualizar servicios a versiones más recientes",
                        "Implementar gestión de parches automatizada",
                        "Evaluar necesidad de cada servicio"
                    ],
                    evidence={
                        'outdated_services': outdated_services,
                        'count': len(outdated_services)
                    }
                )
                
                self.correlations.append(correlation)
    
    def _analyze_web_application_attack_surface(self, data: Dict[str, Any]) -> None:
        """Analiza superficie de ataque de aplicaciones web."""
        nuclei_data = data.get('nuclei_data', [])
        dir_brute_data = data.get('dir_brute_data', [])
        httpx_data = data.get('httpx_data', [])
        
        # Agrupar por dominio/host
        host_attack_surface = defaultdict(lambda: {
            'vulnerabilities': [],
            'exposed_directories': [],
            'technologies': set(),
            'endpoints': []
        })
        
        # Procesar vulnerabilidades Nuclei
        for vuln in nuclei_data:
            host = self._extract_host(vuln.get('host', ''))
            host_attack_surface[host]['vulnerabilities'].append(vuln)
            
            # Extraer tecnologías
            tags = vuln.get('info', {}).get('tags', [])
            host_attack_surface[host]['technologies'].update(tags)
        
        # Procesar directorios expuestos
        for directory in dir_brute_data:
            host = self._extract_host(directory.get('url', ''))
            if directory.get('status_code') == 200:
                host_attack_surface[host]['exposed_directories'].append(directory)
        
        # Procesar endpoints HTTP
        for endpoint in httpx_data:
            host = self._extract_host(endpoint.get('url', ''))
            host_attack_surface[host]['endpoints'].append(endpoint)
        
        # Analizar superficie de ataque por host
        for host, surface in host_attack_surface.items():
            vuln_count = len(surface['vulnerabilities'])
            dir_count = len(surface['exposed_directories'])
            tech_count = len(surface['technologies'])
            
            # Calcular puntuación de superficie de ataque
            attack_surface_score = (vuln_count * 2) + (dir_count * 1.5) + (tech_count * 0.5)
            
            if attack_surface_score >= 10:
                # Identificar tecnologías de alto riesgo
                high_risk_techs = []
                for tech in surface['technologies']:
                    if any(risky in tech.lower() for risky in ['php', 'wordpress', 'joomla', 'drupal']):
                        high_risk_techs.append(tech)
                
                correlation = CorrelationResult(
                    correlation_type="expanded_attack_surface",
                    confidence=min(0.9, attack_surface_score / 20),
                    description=f"Superficie de ataque expandida en {host}",
                    affected_assets=[host],
                    risk_multiplier=1.0 + (attack_surface_score / 20),
                    recommendations=[
                        "Reducir superficie de ataque cerrando servicios innecesarios",
                        "Implementar WAF (Web Application Firewall)",
                        "Aplicar principio de menor exposición",
                        "Monitoreo continuo de nuevos endpoints"
                    ],
                    evidence={
                        'attack_surface_score': attack_surface_score,
                        'vulnerability_count': vuln_count,
                        'exposed_directories_count': dir_count,
                        'technology_count': tech_count,
                        'high_risk_technologies': high_risk_techs,
                        'critical_vulnerabilities': [
                            v for v in surface['vulnerabilities'] 
                            if v.get('info', {}).get('severity') in ['critical', 'high']
                        ]
                    }
                )
                
                self.correlations.append(correlation)
    
    def _analyze_configuration_drift_patterns(self, data: Dict[str, Any]) -> None:
        """Analiza patrones de deriva de configuración."""
        security_config_data = data.get('security_config_data', [])
        nuclei_data = data.get('nuclei_data', [])
        
        if not security_config_data:
            return
        
        # Agrupar problemas de configuración por categoría
        config_issues = defaultdict(list)
        
        for config in security_config_data:
            category = config.get('category', 'unknown')
            severity = config.get('severity', 'info')
            config_issues[category].append(config)
        
        # Buscar vulnerabilidades relacionadas con configuración
        config_vulns = []
        for vuln in nuclei_data:
            tags = vuln.get('info', {}).get('tags', [])
            if any(tag in ['config', 'misconfiguration', 'default'] for tag in tags):
                config_vulns.append(vuln)
        
        # Identificar patrones de deriva
        for category, issues in config_issues.items():
            if len(issues) >= 3:
                high_severity_count = sum(1 for issue in issues if issue.get('severity') in ['high', 'critical'])
                
                correlation = CorrelationResult(
                    correlation_type="configuration_drift_pattern",
                    confidence=0.7,
                    description=f"Patrón de deriva de configuración en {category}",
                    affected_assets=[issue.get('host', 'unknown') for issue in issues],
                    risk_multiplier=1.0 + (len(issues) * 0.15),
                    recommendations=[
                        "Implementar gestión de configuración automatizada",
                        "Establecer líneas base de configuración segura",
                        "Monitoreo continuo de deriva de configuración",
                        "Aplicar políticas de configuración consistentes"
                    ],
                    evidence={
                        'category': category,
                        'total_issues': len(issues),
                        'high_severity_issues': high_severity_count,
                        'related_vulnerabilities': len(config_vulns),
                        'issues': issues[:5]  # Primeros 5 para evidencia
                    }
                )
                
                self.correlations.append(correlation)
    
    def _analyze_cve_exploit_chains(self, data: Dict[str, Any]) -> None:
        """Analiza cadenas de explotación de CVEs."""
        cves_data = data.get('cves_data', [])
        cisa_kev_data = data.get('cisa_kev_data', [])
        nuclei_data = data.get('nuclei_data', [])
        
        if not cves_data:
            return
        
        # Identificar CVEs críticos y de CISA KEV
        critical_cves = []
        kev_cves = set()
        
        for cve in cves_data:
            cvss_score = float(cve.get('cvss_score', 0))
            if cvss_score >= 7.0:
                critical_cves.append(cve)
        
        for kev in cisa_kev_data:
            kev_cves.add(kev.get('cve_id', ''))
        
        # Buscar CVEs que están en CISA KEV
        kev_matches = []
        for cve in critical_cves:
            if cve.get('cve_id') in kev_cves:
                kev_matches.append(cve)
        
        # Analizar cadenas de explotación
        if len(critical_cves) >= 3 or kev_matches:
            # Agrupar por producto/vendor
            vendor_cves = defaultdict(list)
            for cve in critical_cves:
                vendor = cve.get('vendor', 'unknown')
                vendor_cves[vendor].append(cve)
            
            # Identificar vendors con múltiples CVEs
            vulnerable_vendors = {vendor: cves for vendor, cves in vendor_cves.items() if len(cves) >= 2}
            
            if vulnerable_vendors or kev_matches:
                correlation = CorrelationResult(
                    correlation_type="cve_exploit_chain",
                    confidence=0.8 if kev_matches else 0.6,
                    description="Cadena de explotación de CVEs identificada",
                    affected_assets=list(set(cve.get('host', 'unknown') for cve in critical_cves)),
                    risk_multiplier=2.0 if kev_matches else 1.5,
                    recommendations=[
                        "Aplicar parches de seguridad inmediatamente",
                        "Priorizar CVEs de CISA KEV",
                        "Implementar detección de exploits",
                        "Segmentar sistemas vulnerables"
                    ],
                    evidence={
                        'critical_cves_count': len(critical_cves),
                        'kev_matches_count': len(kev_matches),
                        'vulnerable_vendors': {vendor: len(cves) for vendor, cves in vulnerable_vendors.items()},
                        'highest_cvss': max((float(cve.get('cvss_score', 0)) for cve in critical_cves), default=0),
                        'kev_cves': [cve.get('cve_id') for cve in kev_matches]
                    }
                )
                
                self.correlations.append(correlation)
    
    def _analyze_data_exposure_patterns(self, data: Dict[str, Any]) -> None:
        """Analiza patrones de exposición de datos."""
        dir_brute_data = data.get('dir_brute_data', [])
        leaks_data = data.get('leaks_data', [])
        nuclei_data = data.get('nuclei_data', [])
        
        # Identificar tipos de exposición de datos
        data_exposures = {
            'database_files': [],
            'backup_files': [],
            'config_files': [],
            'log_files': [],
            'source_code': []
        }
        
        for directory in dir_brute_data:
            url = directory.get('url', '').lower()
            status_code = directory.get('status_code', 0)
            
            if status_code == 200:
                if any(ext in url for ext in ['.sql', '.db', '.sqlite']):
                    data_exposures['database_files'].append(directory)
                elif any(ext in url for ext in ['.bak', '.backup', '.tar', '.zip']):
                    data_exposures['backup_files'].append(directory)
                elif any(ext in url for ext in ['.env', '.config', '.ini', '.conf']):
                    data_exposures['config_files'].append(directory)
                elif any(ext in url for ext in ['.log', '.txt']):
                    data_exposures['log_files'].append(directory)
                elif any(ext in url for ext in ['.php', '.py', '.js', '.java']):
                    data_exposures['source_code'].append(directory)
        
        # Buscar vulnerabilidades de exposición de información
        info_disclosure_vulns = []
        for vuln in nuclei_data:
            tags = vuln.get('info', {}).get('tags', [])
            if any(tag in ['exposure', 'disclosure', 'leak'] for tag in tags):
                info_disclosure_vulns.append(vuln)
        
        # Calcular riesgo de exposición de datos
        total_exposures = sum(len(files) for files in data_exposures.values())
        
        if total_exposures >= 3 or leaks_data:
            risk_multiplier = 1.0
            risk_factors = []
            
            for exposure_type, files in data_exposures.items():
                if files:
                    risk_factors.append(f"{len(files)} {exposure_type.replace('_', ' ')}")
                    risk_multiplier += len(files) * 0.2
            
            if leaks_data:
                risk_factors.append(f"{len(leaks_data)} credenciales filtradas")
                risk_multiplier += len(leaks_data) * 0.3
            
            correlation = CorrelationResult(
                correlation_type="data_exposure_pattern",
                confidence=0.75,
                description="Patrón de exposición de datos sensibles",
                affected_assets=list(set(self._extract_host(d.get('url', '')) for d in dir_brute_data)),
                risk_multiplier=risk_multiplier,
                recommendations=[
                    "Restringir acceso a archivos sensibles",
                    "Implementar controles de acceso granulares",
                    "Cifrar datos sensibles en reposo",
                    "Monitorear acceso a datos críticos",
                    "Eliminar archivos innecesarios del servidor web"
                ],
                evidence={
                    'total_exposed_files': total_exposures,
                    'exposure_breakdown': {k: len(v) for k, v in data_exposures.items() if v},
                    'leaked_credentials': len(leaks_data),
                    'info_disclosure_vulns': len(info_disclosure_vulns),
                    'risk_factors': risk_factors
                }
            )
            
            self.correlations.append(correlation)
    
    def _identify_attack_paths(self, data: Dict[str, Any]) -> None:
        """Identifica posibles rutas de ataque."""
        # Ruta 1: Credenciales comprometidas -> Panel admin -> Escalación
        leaks_data = data.get('leaks_data', [])
        dir_brute_data = data.get('dir_brute_data', [])
        nuclei_data = data.get('nuclei_data', [])
        
        admin_panels = [d for d in dir_brute_data if 'admin' in d.get('url', '').lower() and d.get('status_code') == 200]
        auth_vulns = [v for v in nuclei_data if any(tag in ['auth-bypass', 'default-login'] for tag in v.get('info', {}).get('tags', []))]
        
        if leaks_data and admin_panels:
            attack_path = AttackPath(
                path_id="credential_admin_escalation",
                steps=[
                    {
                        'step': 1,
                        'action': 'Obtener credenciales comprometidas',
                        'method': 'Data breach lookup',
                        'evidence': f"{len(leaks_data)} cuentas comprometidas"
                    },
                    {
                        'step': 2,
                        'action': 'Acceder a panel administrativo',
                        'method': 'Credential stuffing',
                        'evidence': f"{len(admin_panels)} paneles accesibles"
                    },
                    {
                        'step': 3,
                        'action': 'Escalar privilegios',
                        'method': 'Admin panel exploitation',
                        'evidence': 'Acceso administrativo'
                    }
                ],
                risk_score=8.5,
                likelihood=0.7,
                impact="Alto",
                mitigation_priority=1
            )
            
            self.attack_paths.append(attack_path)
        
        # Ruta 2: Servicio vulnerable -> Explotación -> Movimiento lateral
        nmap_data = data.get('nmap_data', [])
        cves_data = data.get('cves_data', [])
        
        critical_services = [p for p in nmap_data if p.get('state') == 'open' and p.get('port') in self.critical_ports]
        critical_cves = [c for c in cves_data if float(c.get('cvss_score', 0)) >= 7.0]
        
        if critical_services and critical_cves:
            attack_path = AttackPath(
                path_id="service_exploitation_lateral",
                steps=[
                    {
                        'step': 1,
                        'action': 'Escanear servicios expuestos',
                        'method': 'Network reconnaissance',
                        'evidence': f"{len(critical_services)} servicios críticos"
                    },
                    {
                        'step': 2,
                        'action': 'Explotar vulnerabilidad conocida',
                        'method': 'CVE exploitation',
                        'evidence': f"{len(critical_cves)} CVEs críticos"
                    },
                    {
                        'step': 3,
                        'action': 'Movimiento lateral',
                        'method': 'Network traversal',
                        'evidence': 'Acceso inicial obtenido'
                    }
                ],
                risk_score=7.8,
                likelihood=0.6,
                impact="Alto",
                mitigation_priority=2
            )
            
            self.attack_paths.append(attack_path)
    
    def _extract_host(self, url_or_host: str) -> str:
        """Extrae el host de una URL o devuelve el host si ya es uno."""
        if not url_or_host:
            return 'unknown'
        
        try:
            if url_or_host.startswith(('http://', 'https://')):
                parsed = urlparse(url_or_host)
                return parsed.netloc or parsed.hostname or 'unknown'
            else:
                # Asumir que es un host/IP
                return url_or_host.split(':')[0]  # Remover puerto si existe
        except Exception:
            return 'unknown'
    
    def _generate_correlation_summary(self) -> Dict[str, Any]:
        """Genera resumen de correlaciones encontradas."""
        if not self.correlations:
            return {}
        
        correlation_types = Counter(c.correlation_type for c in self.correlations)
        avg_confidence = sum(c.confidence for c in self.correlations) / len(self.correlations)
        max_risk_multiplier = max(c.risk_multiplier for c in self.correlations)
        
        high_confidence_correlations = [c for c in self.correlations if c.confidence >= 0.7]
        critical_correlations = [c for c in self.correlations if c.risk_multiplier >= 2.0]
        
        return {
            'total_correlations': len(self.correlations),
            'correlation_types': dict(correlation_types),
            'average_confidence': round(avg_confidence, 2),
            'max_risk_multiplier': round(max_risk_multiplier, 2),
            'high_confidence_count': len(high_confidence_correlations),
            'critical_correlations_count': len(critical_correlations),
            'attack_paths_identified': len(self.attack_paths)
        }
    
    def _calculate_correlation_risk(self) -> Dict[str, Any]:
        """Calcula el riesgo global basado en correlaciones."""
        if not self.correlations:
            return {'risk_score': 0, 'risk_level': 'Low'}
        
        # Calcular puntuación de riesgo basada en correlaciones
        base_score = len(self.correlations) * 2
        confidence_bonus = sum(c.confidence * 5 for c in self.correlations)
        multiplier_bonus = sum((c.risk_multiplier - 1) * 10 for c in self.correlations)
        
        total_score = base_score + confidence_bonus + multiplier_bonus
        
        # Determinar nivel de riesgo
        if total_score >= 50:
            risk_level = "Critical"
        elif total_score >= 30:
            risk_level = "High"
        elif total_score >= 15:
            risk_level = "Medium"
        else:
            risk_level = "Low"
        
        return {
            'risk_score': round(total_score, 1),
            'risk_level': risk_level,
            'contributing_factors': {
                'correlation_count': len(self.correlations),
                'average_confidence': round(sum(c.confidence for c in self.correlations) / len(self.correlations), 2),
                'max_risk_multiplier': round(max(c.risk_multiplier for c in self.correlations), 2)
            }
        }
    
    def _correlation_to_dict(self, correlation: CorrelationResult) -> Dict[str, Any]:
        """Convierte CorrelationResult a diccionario."""
        return {
            'type': correlation.correlation_type,
            'confidence': correlation.confidence,
            'description': correlation.description,
            'affected_assets': correlation.affected_assets,
            'risk_multiplier': correlation.risk_multiplier,
            'recommendations': correlation.recommendations,
            'evidence': correlation.evidence
        }
    
    def _attack_path_to_dict(self, attack_path: AttackPath) -> Dict[str, Any]:
        """Convierte AttackPath a diccionario."""
        return {
            'path_id': attack_path.path_id,
            'steps': attack_path.steps,
            'risk_score': attack_path.risk_score,
            'likelihood': attack_path.likelihood,
            'impact': attack_path.impact,
            'mitigation_priority': attack_path.mitigation_priority
        }


# ============================================================================
# FUNCIONES DE UTILIDAD
# ============================================================================

def create_correlation_engine() -> AdvancedCorrelationEngine:
    """Factory function para crear motor de correlación."""
    return AdvancedCorrelationEngine()


def analyze_security_correlations(data: Dict[str, Any]) -> Dict[str, Any]:
    """Función de conveniencia para análisis completo de correlaciones."""
    engine = create_correlation_engine()
    return engine.analyze_all_correlations(data)