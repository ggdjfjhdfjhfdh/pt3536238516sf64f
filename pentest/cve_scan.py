import json
import logging
import time
from pathlib import Path
from typing import List, Dict, Any, Optional
import requests
from urllib.parse import quote

from pentest.exceptions import CVEScanError

log = logging.getLogger(__name__)

# Configuraci√≥n de la API de NIST NVD
NVD_API_BASE_URL = "https://services.nvd.nist.gov/rest/json/cves/2.0"
REQUEST_DELAY = 6  # Segundos entre requests (recomendado por NIST)
MAX_RESULTS_PER_PAGE = 20

def _normalize_tech_name(tech_name: str) -> str:
    """Normaliza el nombre de la tecnolog√≠a para b√∫squeda en NVD."""
    # Mapeo de nombres comunes a nombres est√°ndar en NVD
    tech_mapping = {
        "nginx": "nginx",
        "apache http server": "apache_http_server",
        "apache": "apache_http_server", 
        "mysql": "mysql",
        "postgresql": "postgresql",
        "php": "php",
        "wordpress": "wordpress",
        "drupal": "drupal",
        "joomla": "joomla",
        "tomcat": "tomcat",
        "iis": "iis",
        "node.js": "node.js",
        "nodejs": "node.js",
        "express": "express",
        "react": "react",
        "angular": "angular",
        "vue": "vue.js",
        "jquery": "jquery",
        "bootstrap": "bootstrap",
        "openssl": "openssl",
        "openssh": "openssh"
    }
    
    normalized = tech_name.lower().strip()
    return tech_mapping.get(normalized, normalized)

def _search_cves_for_technology(tech_name: str, tech_version: str = "") -> List[Dict[str, Any]]:
    """Busca CVEs para una tecnolog√≠a espec√≠fica usando la API de NIST NVD."""
    try:
        # Normalizar nombre de tecnolog√≠a
        normalized_tech = _normalize_tech_name(tech_name)
        
        # Construir query de b√∫squeda
        if tech_version:
            # Buscar por tecnolog√≠a y versi√≥n espec√≠fica
            keyword_search = f"{normalized_tech} {tech_version}"
        else:
            # Buscar solo por tecnolog√≠a
            keyword_search = normalized_tech
        
        # Par√°metros para la API
        params = {
            "keywordSearch": keyword_search,
            "resultsPerPage": MAX_RESULTS_PER_PAGE,
            "startIndex": 0
        }
        
        log.info(f"üîç Buscando CVEs para {tech_name} {tech_version} en NIST NVD...")
        
        # Realizar request a la API
        response = requests.get(NVD_API_BASE_URL, params=params, timeout=30)
        response.raise_for_status()
        
        data = response.json()
        cves = []
        
        if "vulnerabilities" in data:
            for vuln in data["vulnerabilities"]:
                cve_data = vuln.get("cve", {})
                cve_id = cve_data.get("id", "")
                
                # Extraer descripci√≥n
                descriptions = cve_data.get("descriptions", [])
                description = ""
                for desc in descriptions:
                    if desc.get("lang") == "en":
                        description = desc.get("value", "")
                        break
                
                # Extraer m√©tricas CVSS
                metrics = cve_data.get("metrics", {})
                severity = "Unknown"
                score = 0.0
                vector = ""
                
                # Priorizar CVSS v3.1, luego v3.0, luego v2.0
                if "cvssMetricV31" in metrics and metrics["cvssMetricV31"]:
                    cvss_data = metrics["cvssMetricV31"][0]["cvssData"]
                    severity = cvss_data.get("baseSeverity", "Unknown")
                    score = cvss_data.get("baseScore", 0.0)
                    vector = cvss_data.get("vectorString", "")
                elif "cvssMetricV30" in metrics and metrics["cvssMetricV30"]:
                    cvss_data = metrics["cvssMetricV30"][0]["cvssData"]
                    severity = cvss_data.get("baseSeverity", "Unknown")
                    score = cvss_data.get("baseScore", 0.0)
                    vector = cvss_data.get("vectorString", "")
                elif "cvssMetricV2" in metrics and metrics["cvssMetricV2"]:
                    cvss_data = metrics["cvssMetricV2"][0]["cvssData"]
                    severity = "Medium"  # CVSS v2 no tiene severity textual
                    score = cvss_data.get("baseScore", 0.0)
                    vector = cvss_data.get("vectorString", "")
                
                # Extraer fechas
                published = cve_data.get("published", "")
                last_modified = cve_data.get("lastModified", "")
                
                # Extraer referencias
                references = []
                for ref in cve_data.get("references", []):
                    references.append({
                        "url": ref.get("url", ""),
                        "source": ref.get("source", "")
                    })
                
                cve_info = {
                    "cve_id": cve_id,
                    "description": description[:500] + "..." if len(description) > 500 else description,
                    "severity": severity,
                    "cvss_score": score,
                    "cvss_vector": vector,
                    "affected_technology": f"{tech_name} {tech_version}".strip(),
                    "published_date": published,
                    "last_modified": last_modified,
                    "references": references[:3],  # Limitar a 3 referencias
                    "source": "NIST NVD"
                }
                
                cves.append(cve_info)
        
        log.info(f"‚úÖ Encontrados {len(cves)} CVEs para {tech_name} {tech_version}")
        
        # Delay entre requests para respetar rate limits
        time.sleep(REQUEST_DELAY)
        
        return cves
        
    except requests.exceptions.RequestException as e:
        log.error(f"‚ùå Error al consultar NIST NVD para {tech_name}: {str(e)}")
        return []
    except Exception as e:
        log.error(f"‚ùå Error inesperado al buscar CVEs para {tech_name}: {str(e)}")
        return []

def cve_scan(httpx_file: Path, tmp_dir: Path) -> Path:
    """Escanea CVEs bas√°ndose en las tecnolog√≠as identificadas usando la API de NIST NVD.
    
    Args:
        httpx_file: Path al archivo JSON con resultados de httpx (con tech-detect).
        tmp_dir: Directorio temporal para almacenar resultados.
        
    Returns:
        Path al archivo JSON con hallazgos de CVEs.
        
    Raises:
        CVEScanError: Si el escaneo de CVEs falla.
    """
    log.info("üîç Iniciando escaneo de CVEs.")
    
    output_file = tmp_dir / "cves.json"
    cve_findings: List[Dict[str, Any]] = []

    if httpx_file is None or not httpx_file.exists():
        log.warning(f"Archivo httpx no encontrado o es None: {httpx_file}. No se realizar√° escaneo de CVEs.")
        with open(output_file, "w") as f:
            json.dump([], f)
        return output_file

    try:
        with open(httpx_file, "r") as f:
            httpx_data = json.load(f)

        # Procesar cada host y sus tecnolog√≠as
        processed_techs = set()  # Para evitar b√∫squedas duplicadas
        
        for host_data in httpx_data:
            technologies = host_data.get("tech", [])
            url = host_data.get("url", "N/A")

            for tech in technologies:
                if isinstance(tech, str):
                    tech_name = tech.strip()
                    tech_version = ""
                else:
                    tech_name = tech.get("name", "").strip()
                    tech_version = tech.get("version", "").strip()
                
                # Evitar tecnolog√≠as vac√≠as o muy gen√©ricas
                if not tech_name or len(tech_name) < 2:
                    continue
                    
                # Filtrar tecnolog√≠as muy gen√©ricas que no son √∫tiles
                generic_techs = ["html", "css", "javascript", "js", "http", "https", "ssl", "tls"]
                if tech_name.lower() in generic_techs:
                    continue
                
                # Crear clave √∫nica para evitar b√∫squedas duplicadas
                tech_key = f"{tech_name.lower()}:{tech_version}"
                if tech_key in processed_techs:
                    continue
                processed_techs.add(tech_key)
                
                log.info(f"üîç Analizando tecnolog√≠a: {tech_name} {tech_version}")
                
                # Buscar CVEs para esta tecnolog√≠a
                tech_cves = _search_cves_for_technology(tech_name, tech_version)
                
                # Agregar informaci√≥n del host a cada CVE encontrado
                for cve in tech_cves:
                    cve["detected_url"] = url
                    cve_findings.append(cve)
                
                # Limitar el n√∫mero total de CVEs para evitar archivos muy grandes
                if len(cve_findings) >= 100:
                    log.warning("‚ö†Ô∏è L√≠mite de 100 CVEs alcanzado. Deteniendo b√∫squeda.")
                    break
            
            if len(cve_findings) >= 100:
                break

        # Ordenar CVEs por severidad (Critical > High > Medium > Low > Unknown)
        severity_order = {"CRITICAL": 0, "HIGH": 1, "MEDIUM": 2, "LOW": 3, "UNKNOWN": 4}
        cve_findings.sort(key=lambda x: (severity_order.get(x["severity"].upper(), 4), -x["cvss_score"]))
        
        # Agregar resumen estad√≠stico
        summary = {
            "total_cves": len(cve_findings),
            "severity_breakdown": {},
            "technologies_analyzed": len(processed_techs),
            "scan_timestamp": time.strftime("%Y-%m-%d %H:%M:%S UTC", time.gmtime()),
            "data_source": "NIST National Vulnerability Database (NVD)",
            "api_attribution": "This product uses data from the NVD API but is not endorsed or certified by the NVD."
        }
        
        # Calcular breakdown por severidad
        for cve in cve_findings:
            severity = cve["severity"].upper()
            summary["severity_breakdown"][severity] = summary["severity_breakdown"].get(severity, 0) + 1
        
        # Estructura final del archivo
        final_output = {
            "summary": summary,
            "cve_findings": cve_findings
        }
        
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(final_output, f, indent=2, ensure_ascii=False)

        log.info("‚úÖ Escaneo de CVEs completado: %d hallazgos encontrados", len(cve_findings))
        if cve_findings:
            critical_high = sum(1 for cve in cve_findings if cve["severity"].upper() in ["CRITICAL", "HIGH"])
            if critical_high > 0:
                log.warning(f"‚ö†Ô∏è Se encontraron {critical_high} CVEs de severidad CRITICAL/HIGH")
        
        return output_file

    except Exception as e:
        log.error(f"‚ùå Error durante el escaneo de CVEs: {str(e)}")
        # Crear archivo vac√≠o en caso de error
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump({"summary": {"total_cves": 0, "error": str(e)}, "cve_findings": []}, f, indent=2)
        raise CVEScanError(f"Error durante el escaneo de CVEs: {str(e)}") from e