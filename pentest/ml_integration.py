#!/usr/bin/env python3
"""
M칩dulo de Integraci칩n ML con el Pipeline Principal
Conecta el sistema de IA/ML predictivo con el esc치ner de seguridad
"""

import json
import logging
import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
import redis
import pickle

try:
    from .ml_predictive_analysis import (
        MLPredictiveAnalyzer, SecurityEvent, PredictionResult, ThreatPattern
    )
    from .config.ml_config import ML_CONFIG
    from .metrics import MetricsCollector
except ImportError as e:
    logging.warning(f"Importaci칩n ML no disponible: {e}")
    MLPredictiveAnalyzer = None
    SecurityEvent = None
    PredictionResult = None
    ThreatPattern = None
    ML_CONFIG = None
    MetricsCollector = None

# Configuraci칩n de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class MLEnhancedScanResult:
    """Resultado de escaneo enriquecido con an치lisis ML"""
    original_result: Dict[str, Any]
    ml_prediction: Optional[PredictionResult]
    threat_patterns: List[ThreatPattern]
    risk_assessment: Dict[str, Any]
    recommendations: List[str]
    confidence_score: float
    processing_time: float
    timestamp: datetime

class MLIntegrationManager:
    """Gestor de integraci칩n entre ML y el pipeline de escaneo"""
    
    def __init__(self, redis_client=None, enable_cache=True):
        self.ml_analyzer = None
        self.redis_client = redis_client
        self.enable_cache = enable_cache
        self.metrics_collector = None
        self.processing_stats = {
            'total_scans': 0,
            'ml_enhanced_scans': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'errors': 0
        }
        
        self._initialize_components()
    
    def _initialize_components(self):
        """Inicializa los componentes ML"""
        try:
            if MLPredictiveAnalyzer:
                self.ml_analyzer = MLPredictiveAnalyzer()
                self.ml_analyzer.load_models()
                logger.info("Analizador ML inicializado")
            
            if MetricsCollector:
                self.metrics_collector = MetricsCollector()
                logger.info("Collector de m칠tricas inicializado")
            
            # Configurar Redis si est치 disponible
            if not self.redis_client and self.enable_cache:
                try:
                    import redis
                    self.redis_client = redis.Redis(
                        host='localhost', port=6379, db=0, decode_responses=True
                    )
                    self.redis_client.ping()
                    logger.info("Conexi칩n Redis establecida")
                except Exception as e:
                    logger.warning(f"Redis no disponible: {e}")
                    self.enable_cache = False
        
        except Exception as e:
            logger.error(f"Error inicializando componentes ML: {e}")
    
    def is_ml_available(self) -> bool:
        """Verifica si el sistema ML est치 disponible"""
        return self.ml_analyzer is not None and self.ml_analyzer.models_loaded
    
    def convert_scan_to_security_event(self, scan_result: Dict[str, Any], 
                                     target_domain: str) -> SecurityEvent:
        """Convierte resultado de escaneo a SecurityEvent para ML"""
        try:
            # Extraer informaci칩n del resultado de escaneo
            vulnerabilities = scan_result.get('vulnerabilities', [])
            technologies = scan_result.get('technologies', [])
            ports = scan_result.get('open_ports', [])
            
            # Calcular threat score basado en vulnerabilidades
            threat_score = self._calculate_threat_score(vulnerabilities)
            
            # Extraer informaci칩n de red
            network_info = scan_result.get('network_info', {})
            response_time = network_info.get('avg_response_time', 1.0)
            
            # Crear evento de seguridad
            event = SecurityEvent(
                timestamp=datetime.now(),
                event_type="security_scan",
                severity=self._determine_severity(threat_score, len(vulnerabilities)),
                source_ip="scanner",
                target_domain=target_domain,
                vulnerability_count=len(vulnerabilities),
                threat_score=threat_score,
                technologies=[tech.get('name', '') for tech in technologies if isinstance(tech, dict)],
                ports_open=ports if isinstance(ports, list) else [],
                response_time=response_time,
                status_code=scan_result.get('status_code', 200),
                payload_size=scan_result.get('content_length', 0),
                user_agent="PentestExpress",
                country=scan_result.get('geo_location', {}).get('country', 'Unknown'),
                is_malicious=threat_score > 7.0
            )
            
            return event
        
        except Exception as e:
            logger.error(f"Error convirtiendo scan a SecurityEvent: {e}")
            # Retornar evento b치sico en caso de error
            return SecurityEvent(
                timestamp=datetime.now(),
                event_type="security_scan",
                severity="UNKNOWN",
                source_ip="scanner",
                target_domain=target_domain,
                vulnerability_count=0,
                threat_score=0.0,
                technologies=[],
                ports_open=[],
                response_time=1.0,
                status_code=200,
                payload_size=0,
                user_agent="PentestExpress",
                country="Unknown",
                is_malicious=False
            )
    
    def _calculate_threat_score(self, vulnerabilities: List[Dict]) -> float:
        """Calcula puntuaci칩n de amenaza basada en vulnerabilidades"""
        if not vulnerabilities:
            return 0.0
        
        score = 0.0
        severity_weights = {
            'CRITICAL': 10.0,
            'HIGH': 7.5,
            'MEDIUM': 5.0,
            'LOW': 2.5,
            'INFO': 1.0
        }
        
        for vuln in vulnerabilities:
            severity = vuln.get('severity', 'LOW').upper()
            weight = severity_weights.get(severity, 1.0)
            score += weight
        
        # Normalizar a escala 0-10
        max_possible = len(vulnerabilities) * 10.0
        normalized_score = min((score / max_possible) * 10.0, 10.0) if max_possible > 0 else 0.0
        
        return normalized_score
    
    def _determine_severity(self, threat_score: float, vuln_count: int) -> str:
        """Determina la severidad basada en threat score y cantidad de vulnerabilidades"""
        if threat_score >= 8.0 or vuln_count >= 20:
            return "CRITICAL"
        elif threat_score >= 6.0 or vuln_count >= 10:
            return "HIGH"
        elif threat_score >= 4.0 or vuln_count >= 5:
            return "MEDIUM"
        elif threat_score >= 2.0 or vuln_count >= 1:
            return "LOW"
        else:
            return "INFO"
    
    def get_cached_prediction(self, cache_key: str) -> Optional[PredictionResult]:
        """Obtiene predicci칩n desde cache"""
        if not self.enable_cache or not self.redis_client:
            return None
        
        try:
            cached_data = self.redis_client.get(f"ml_pred:{cache_key}")
            if cached_data:
                self.processing_stats['cache_hits'] += 1
                return pickle.loads(cached_data.encode('latin1'))
        except Exception as e:
            logger.warning(f"Error obteniendo cache: {e}")
        
        self.processing_stats['cache_misses'] += 1
        return None
    
    def cache_prediction(self, cache_key: str, prediction: PredictionResult):
        """Guarda predicci칩n en cache"""
        if not self.enable_cache or not self.redis_client:
            return
        
        try:
            ttl = ML_CONFIG.CACHE['cache_ttl_seconds'] if ML_CONFIG else 300
            cached_data = pickle.dumps(prediction).decode('latin1')
            self.redis_client.setex(
                f"ml_pred:{cache_key}", 
                ttl, 
                cached_data
            )
        except Exception as e:
            logger.warning(f"Error guardando en cache: {e}")
    
    def enhance_scan_result(self, scan_result: Dict[str, Any], 
                          target_domain: str) -> MLEnhancedScanResult:
        """Enriquece resultado de escaneo con an치lisis ML"""
        start_time = datetime.now()
        self.processing_stats['total_scans'] += 1
        
        try:
            # Verificar si ML est치 disponible
            if not self.is_ml_available():
                logger.warning("Sistema ML no disponible, retornando resultado b치sico")
                return self._create_basic_result(scan_result, start_time)
            
            # Crear cache key
            cache_key = self._generate_cache_key(scan_result, target_domain)
            
            # Intentar obtener desde cache
            cached_prediction = self.get_cached_prediction(cache_key)
            if cached_prediction:
                logger.debug("Usando predicci칩n desde cache")
                return self._create_enhanced_result(
                    scan_result, cached_prediction, [], start_time
                )
            
            # Convertir a evento de seguridad
            security_event = self.convert_scan_to_security_event(scan_result, target_domain)
            
            # Realizar predicci칩n ML
            prediction = self.ml_analyzer.predict_threat(security_event)
            
            # Detectar patrones (usando eventos hist칩ricos si est치n disponibles)
            patterns = self._get_threat_patterns(target_domain)
            
            # Guardar en cache
            self.cache_prediction(cache_key, prediction)
            
            # Actualizar m칠tricas
            if self.metrics_collector:
                self._update_metrics(prediction, security_event)
            
            self.processing_stats['ml_enhanced_scans'] += 1
            
            return self._create_enhanced_result(scan_result, prediction, patterns, start_time)
        
        except Exception as e:
            logger.error(f"Error en an치lisis ML: {e}")
            self.processing_stats['errors'] += 1
            return self._create_basic_result(scan_result, start_time)
    
    def _generate_cache_key(self, scan_result: Dict[str, Any], target_domain: str) -> str:
        """Genera clave de cache basada en caracter칤sticas del escaneo"""
        key_components = [
            target_domain,
            str(len(scan_result.get('vulnerabilities', []))),
            str(len(scan_result.get('technologies', []))),
            str(len(scan_result.get('open_ports', []))),
            scan_result.get('scan_type', 'unknown')
        ]
        return ":".join(key_components)
    
    def _get_threat_patterns(self, target_domain: str) -> List[ThreatPattern]:
        """Obtiene patrones de amenazas para el dominio"""
        try:
            # En una implementaci칩n real, esto obtendr칤a eventos hist칩ricos
            # Por ahora retornamos lista vac칤a
            return []
        except Exception as e:
            logger.warning(f"Error obteniendo patrones: {e}")
            return []
    
    def _update_metrics(self, prediction: PredictionResult, event: SecurityEvent):
        """Actualiza m칠tricas del sistema ML"""
        try:
            metrics = {
                'ml_prediction_confidence': prediction.confidence,
                'ml_risk_score': prediction.risk_score,
                'ml_anomaly_score': prediction.anomaly_score,
                'ml_prediction_type': prediction.prediction,
                'event_vulnerability_count': event.vulnerability_count,
                'event_threat_score': event.threat_score
            }
            
            self.metrics_collector.record_ml_metrics(metrics)
        except Exception as e:
            logger.warning(f"Error actualizando m칠tricas: {e}")
    
    def _create_enhanced_result(self, scan_result: Dict[str, Any], 
                              prediction: PredictionResult,
                              patterns: List[ThreatPattern],
                              start_time: datetime) -> MLEnhancedScanResult:
        """Crea resultado enriquecido con ML"""
        processing_time = (datetime.now() - start_time).total_seconds()
        
        # Generar evaluaci칩n de riesgo
        risk_assessment = {
            'overall_risk': prediction.risk_score,
            'threat_probability': prediction.confidence if prediction.prediction == "malicious" else 1 - prediction.confidence,
            'anomaly_detected': prediction.anomaly_score > 0.5,
            'risk_level': self._get_risk_level(prediction.risk_score),
            'factors': self._analyze_risk_factors(scan_result, prediction)
        }
        
        # Combinar recomendaciones
        all_recommendations = prediction.recommendations.copy()
        all_recommendations.extend(self._generate_integration_recommendations(scan_result, prediction))
        
        return MLEnhancedScanResult(
            original_result=scan_result,
            ml_prediction=prediction,
            threat_patterns=patterns,
            risk_assessment=risk_assessment,
            recommendations=all_recommendations,
            confidence_score=prediction.confidence,
            processing_time=processing_time,
            timestamp=datetime.now()
        )
    
    def _create_basic_result(self, scan_result: Dict[str, Any], 
                           start_time: datetime) -> MLEnhancedScanResult:
        """Crea resultado b치sico sin an치lisis ML"""
        processing_time = (datetime.now() - start_time).total_seconds()
        
        # An치lisis b치sico sin ML
        vuln_count = len(scan_result.get('vulnerabilities', []))
        basic_risk = min(vuln_count * 5, 100)  # Riesgo b치sico
        
        risk_assessment = {
            'overall_risk': basic_risk,
            'threat_probability': 0.0,
            'anomaly_detected': False,
            'risk_level': self._get_risk_level(basic_risk),
            'factors': ['An치lisis ML no disponible']
        }
        
        recommendations = self._generate_basic_recommendations(scan_result)
        
        return MLEnhancedScanResult(
            original_result=scan_result,
            ml_prediction=None,
            threat_patterns=[],
            risk_assessment=risk_assessment,
            recommendations=recommendations,
            confidence_score=0.5,  # Confianza neutral
            processing_time=processing_time,
            timestamp=datetime.now()
        )
    
    def _get_risk_level(self, risk_score: float) -> str:
        """Determina nivel de riesgo basado en puntuaci칩n"""
        if risk_score >= 80:
            return "CR칈TICO"
        elif risk_score >= 60:
            return "ALTO"
        elif risk_score >= 40:
            return "MEDIO"
        elif risk_score >= 20:
            return "BAJO"
        else:
            return "M칈NIMO"
    
    def _analyze_risk_factors(self, scan_result: Dict[str, Any], 
                            prediction: PredictionResult) -> List[str]:
        """Analiza factores de riesgo"""
        factors = []
        
        vuln_count = len(scan_result.get('vulnerabilities', []))
        if vuln_count > 10:
            factors.append(f"M칰ltiples vulnerabilidades detectadas ({vuln_count})")
        
        if prediction and prediction.prediction == "malicious":
            factors.append("Actividad maliciosa predicha por ML")
        
        if prediction and prediction.anomaly_score > 0.5:
            factors.append("Comportamiento an칩malo detectado")
        
        open_ports = scan_result.get('open_ports', [])
        if len(open_ports) > 20:
            factors.append(f"Muchos puertos abiertos ({len(open_ports)})")
        
        # Verificar puertos peligrosos
        if ML_CONFIG:
            dangerous_ports = [p for p in open_ports if ML_CONFIG.is_dangerous_port(p)]
            if dangerous_ports:
                factors.append(f"Puertos peligrosos expuestos: {dangerous_ports}")
        
        return factors
    
    def _generate_integration_recommendations(self, scan_result: Dict[str, Any], 
                                            prediction: PredictionResult) -> List[str]:
        """Genera recomendaciones espec칤ficas de integraci칩n"""
        recommendations = []
        
        # Recomendaciones basadas en tecnolog칤as detectadas
        technologies = scan_result.get('technologies', [])
        for tech in technologies:
            if isinstance(tech, dict):
                tech_name = tech.get('name', '').lower()
                if 'wordpress' in tech_name:
                    recommendations.append("游댢 WordPress detectado - Verificar plugins y actualizaciones")
                elif 'apache' in tech_name:
                    recommendations.append("游댢 Apache detectado - Revisar configuraci칩n de seguridad")
                elif 'nginx' in tech_name:
                    recommendations.append("游댢 Nginx detectado - Verificar configuraci칩n SSL/TLS")
        
        # Recomendaciones basadas en vulnerabilidades
        vulnerabilities = scan_result.get('vulnerabilities', [])
        critical_vulns = [v for v in vulnerabilities if v.get('severity') == 'CRITICAL']
        if critical_vulns:
            recommendations.append(f"游뚿 {len(critical_vulns)} vulnerabilidades cr칤ticas - Parchear inmediatamente")
        
        return recommendations
    
    def _generate_basic_recommendations(self, scan_result: Dict[str, Any]) -> List[str]:
        """Genera recomendaciones b치sicas sin ML"""
        recommendations = []
        
        vuln_count = len(scan_result.get('vulnerabilities', []))
        if vuln_count > 0:
            recommendations.append(f"游댌 {vuln_count} vulnerabilidades encontradas - Revisar y remediar")
        
        open_ports = scan_result.get('open_ports', [])
        if len(open_ports) > 10:
            recommendations.append("游댏 Muchos puertos abiertos - Cerrar servicios innecesarios")
        
        recommendations.append("游뱄 Habilitar an치lisis ML para evaluaci칩n avanzada de riesgos")
        
        return recommendations
    
    def get_processing_stats(self) -> Dict[str, Any]:
        """Obtiene estad칤sticas de procesamiento"""
        stats = self.processing_stats.copy()
        stats['ml_available'] = self.is_ml_available()
        stats['cache_enabled'] = self.enable_cache
        stats['ml_enhancement_rate'] = (
            stats['ml_enhanced_scans'] / stats['total_scans'] 
            if stats['total_scans'] > 0 else 0
        )
        return stats
    
    def train_with_scan_data(self, scan_results: List[Dict[str, Any]], 
                           target_domains: List[str]):
        """Entrena modelos ML con datos de escaneos"""
        if not self.is_ml_available():
            logger.warning("Sistema ML no disponible para entrenamiento")
            return
        
        try:
            # Convertir resultados de escaneo a eventos de seguridad
            events = []
            for scan_result, domain in zip(scan_results, target_domains):
                event = self.convert_scan_to_security_event(scan_result, domain)
                events.append(event)
            
            logger.info(f"Entrenando modelos ML con {len(events)} eventos")
            
            # Entrenar modelos
            self.ml_analyzer.train_anomaly_detector(events)
            self.ml_analyzer.train_threat_classifier(events)
            
            logger.info("Entrenamiento ML completado")
        
        except Exception as e:
            logger.error(f"Error en entrenamiento ML: {e}")

# Funci칩n de utilidad para integraci칩n f치cil
def enhance_scan_with_ml(scan_result: Dict[str, Any], target_domain: str, 
                        ml_manager: Optional[MLIntegrationManager] = None) -> MLEnhancedScanResult:
    """Funci칩n de conveniencia para enriquecer escaneo con ML"""
    if ml_manager is None:
        ml_manager = MLIntegrationManager()
    
    return ml_manager.enhance_scan_result(scan_result, target_domain)

# Instancia global para uso en el pipeline
ml_integration_manager = MLIntegrationManager()