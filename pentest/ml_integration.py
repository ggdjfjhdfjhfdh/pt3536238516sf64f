#!/usr/bin/env python3
"""
Módulo de Integración ML con el Pipeline Principal
Conecta el sistema de IA/ML predictivo con el escáner de seguridad
"""

import json
import logging
import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
import redis
import pickle

try:
    from .ml_predictive_analysis import (
        MLPredictiveAnalyzer, SecurityEvent, PredictionResult, ThreatPattern
    )
    from .config.ml_config import ML_CONFIG
    from .metrics import MetricsCollector
except ImportError as e:
    logging.warning(f"Importación ML no disponible: {e}")
    MLPredictiveAnalyzer = None
    SecurityEvent = None
    PredictionResult = None
    ThreatPattern = None
    ML_CONFIG = None
    MetricsCollector = None

# Configuración de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class MLEnhancedScanResult:
    """Resultado de escaneo enriquecido con análisis ML"""
    original_result: Dict[str, Any]
    ml_prediction: Optional[PredictionResult]
    threat_patterns: List[ThreatPattern]
    risk_assessment: Dict[str, Any]
    recommendations: List[str]
    confidence_score: float
    processing_time: float
    timestamp: datetime

class MLIntegrationManager:
    """Gestor de integración entre ML y el pipeline de escaneo"""
    
    def __init__(self, redis_client=None, enable_cache=True):
        self.ml_analyzer = None
        self.redis_client = redis_client
        self.enable_cache = enable_cache
        self.metrics_collector = None
        self.processing_stats = {
            'total_scans': 0,
            'ml_enhanced_scans': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'errors': 0
        }
        
        self._initialize_components()
    
    def _initialize_components(self):
        """Inicializa los componentes ML"""
        try:
            if MLPredictiveAnalyzer:
                self.ml_analyzer = MLPredictiveAnalyzer()
                self.ml_analyzer.load_models()
                logger.info("Analizador ML inicializado")
            
            if MetricsCollector:
                self.metrics_collector = MetricsCollector()
                logger.info("Collector de métricas inicializado")
            
            # Configurar Redis si está disponible
            if not self.redis_client and self.enable_cache:
                try:
                    import redis
                    self.redis_client = redis.Redis(
                        host='localhost', port=6379, db=0, decode_responses=True
                    )
                    self.redis_client.ping()
                    logger.info("Conexión Redis establecida")
                except Exception as e:
                    logger.warning(f"Redis no disponible: {e}")
                    self.enable_cache = False
        
        except Exception as e:
            logger.error(f"Error inicializando componentes ML: {e}")
    
    def is_ml_available(self) -> bool:
        """Verifica si el sistema ML está disponible"""
        return self.ml_analyzer is not None and self.ml_analyzer.models_loaded
    
    def convert_scan_to_security_event(self, scan_result: Dict[str, Any], 
                                     target_domain: str) -> SecurityEvent:
        """Convierte resultado de escaneo a SecurityEvent para ML"""
        try:
            # Extraer información del resultado de escaneo
            vulnerabilities = scan_result.get('vulnerabilities', [])
            technologies = scan_result.get('technologies', [])
            ports = scan_result.get('open_ports', [])
            
            # Calcular threat score basado en vulnerabilidades
            threat_score = self._calculate_threat_score(vulnerabilities)
            
            # Extraer información de red
            network_info = scan_result.get('network_info', {})
            response_time = network_info.get('avg_response_time', 1.0)
            
            # Crear evento de seguridad
            event = SecurityEvent(
                timestamp=datetime.now(),
                event_type="security_scan",
                severity=self._determine_severity(threat_score, len(vulnerabilities)),
                source_ip="scanner",
                target_domain=target_domain,
                vulnerability_count=len(vulnerabilities),
                threat_score=threat_score,
                technologies=[tech.get('name', '') for tech in technologies if isinstance(tech, dict)],
                ports_open=ports if isinstance(ports, list) else [],
                response_time=response_time,
                status_code=scan_result.get('status_code', 200),
                payload_size=scan_result.get('content_length', 0),
                user_agent="PentestExpress",
                country=scan_result.get('geo_location', {}).get('country', 'Unknown'),
                is_malicious=threat_score > 7.0
            )
            
            return event
        
        except Exception as e:
            logger.error(f"Error convirtiendo scan a SecurityEvent: {e}")
            # Retornar evento básico en caso de error
            return SecurityEvent(
                timestamp=datetime.now(),
                event_type="security_scan",
                severity="UNKNOWN",
                source_ip="scanner",
                target_domain=target_domain,
                vulnerability_count=0,
                threat_score=0.0,
                technologies=[],
                ports_open=[],
                response_time=1.0,
                status_code=200,
                payload_size=0,
                user_agent="PentestExpress",
                country="Unknown",
                is_malicious=False
            )
    
    def _calculate_threat_score(self, vulnerabilities: List[Dict]) -> float:
        """Calcula puntuación de amenaza basada en vulnerabilidades"""
        if not vulnerabilities:
            return 0.0
        
        score = 0.0
        severity_weights = {
            'CRITICAL': 10.0,
            'HIGH': 7.5,
            'MEDIUM': 5.0,
            'LOW': 2.5,
            'INFO': 1.0
        }
        
        for vuln in vulnerabilities:
            severity = vuln.get('severity', 'LOW').upper()
            weight = severity_weights.get(severity, 1.0)
            score += weight
        
        # Normalizar a escala 0-10
        max_possible = len(vulnerabilities) * 10.0
        normalized_score = min((score / max_possible) * 10.0, 10.0) if max_possible > 0 else 0.0
        
        return normalized_score
    
    def _determine_severity(self, threat_score: float, vuln_count: int) -> str:
        """Determina la severidad basada en threat score y cantidad de vulnerabilidades"""
        if threat_score >= 8.0 or vuln_count >= 20:
            return "CRITICAL"
        elif threat_score >= 6.0 or vuln_count >= 10:
            return "HIGH"
        elif threat_score >= 4.0 or vuln_count >= 5:
            return "MEDIUM"
        elif threat_score >= 2.0 or vuln_count >= 1:
            return "LOW"
        else:
            return "INFO"
    
    def get_cached_prediction(self, cache_key: str) -> Optional[PredictionResult]:
        """Obtiene predicción desde cache"""
        if not self.enable_cache or not self.redis_client:
            return None
        
        try:
            cached_data = self.redis_client.get(f"ml_pred:{cache_key}")
            if cached_data:
                self.processing_stats['cache_hits'] += 1
                return pickle.loads(cached_data.encode('latin1'))
        except Exception as e:
            logger.warning(f"Error obteniendo cache: {e}")
        
        self.processing_stats['cache_misses'] += 1
        return None
    
    def cache_prediction(self, cache_key: str, prediction: PredictionResult):
        """Guarda predicción en cache"""
        if not self.enable_cache or not self.redis_client:
            return
        
        try:
            ttl = ML_CONFIG.CACHE['cache_ttl_seconds'] if ML_CONFIG else 300
            cached_data = pickle.dumps(prediction).decode('latin1')
            self.redis_client.setex(
                f"ml_pred:{cache_key}", 
                ttl, 
                cached_data
            )
        except Exception as e:
            logger.warning(f"Error guardando en cache: {e}")
    
    def enhance_scan_result(self, scan_result: Dict[str, Any], 
                          target_domain: str) -> MLEnhancedScanResult:
        """Enriquece resultado de escaneo con análisis ML"""
        start_time = datetime.now()
        self.processing_stats['total_scans'] += 1
        
        try:
            # Verificar si ML está disponible
            if not self.is_ml_available():
                logger.warning("Sistema ML no disponible, retornando resultado básico")
                return self._create_basic_result(scan_result, start_time)
            
            # Crear cache key
            cache_key = self._generate_cache_key(scan_result, target_domain)
            
            # Intentar obtener desde cache
            cached_prediction = self.get_cached_prediction(cache_key)
            if cached_prediction:
                logger.debug("Usando predicción desde cache")
                return self._create_enhanced_result(
                    scan_result, cached_prediction, [], start_time
                )
            
            # Convertir a evento de seguridad
            security_event = self.convert_scan_to_security_event(scan_result, target_domain)
            
            # Realizar predicción ML
            prediction = self.ml_analyzer.predict_threat(security_event)
            
            # Detectar patrones (usando eventos históricos si están disponibles)
            patterns = self._get_threat_patterns(target_domain)
            
            # Guardar en cache
            self.cache_prediction(cache_key, prediction)
            
            # Actualizar métricas
            if self.metrics_collector:
                self._update_metrics(prediction, security_event)
            
            self.processing_stats['ml_enhanced_scans'] += 1
            
            return self._create_enhanced_result(scan_result, prediction, patterns, start_time)
        
        except Exception as e:
            logger.error(f"Error en análisis ML: {e}")
            self.processing_stats['errors'] += 1
            return self._create_basic_result(scan_result, start_time)
    
    def _generate_cache_key(self, scan_result: Dict[str, Any], target_domain: str) -> str:
        """Genera clave de cache basada en características del escaneo"""
        key_components = [
            target_domain,
            str(len(scan_result.get('vulnerabilities', []))),
            str(len(scan_result.get('technologies', []))),
            str(len(scan_result.get('open_ports', []))),
            scan_result.get('scan_type', 'unknown')
        ]
        return ":".join(key_components)
    
    def _get_threat_patterns(self, target_domain: str) -> List[ThreatPattern]:
        """Obtiene patrones de amenazas para el dominio"""
        try:
            # En una implementación real, esto obtendría eventos históricos
            # Por ahora retornamos lista vacía
            return []
        except Exception as e:
            logger.warning(f"Error obteniendo patrones: {e}")
            return []
    
    def _update_metrics(self, prediction: PredictionResult, event: SecurityEvent):
        """Actualiza métricas del sistema ML"""
        try:
            metrics = {
                'ml_prediction_confidence': prediction.confidence,
                'ml_risk_score': prediction.risk_score,
                'ml_anomaly_score': prediction.anomaly_score,
                'ml_prediction_type': prediction.prediction,
                'event_vulnerability_count': event.vulnerability_count,
                'event_threat_score': event.threat_score
            }
            
            self.metrics_collector.record_ml_metrics(metrics)
        except Exception as e:
            logger.warning(f"Error actualizando métricas: {e}")
    
    def _create_enhanced_result(self, scan_result: Dict[str, Any], 
                              prediction: PredictionResult,
                              patterns: List[ThreatPattern],
                              start_time: datetime) -> MLEnhancedScanResult:
        """Crea resultado enriquecido con ML"""
        processing_time = (datetime.now() - start_time).total_seconds()
        
        # Generar evaluación de riesgo
        risk_assessment = {
            'overall_risk': prediction.risk_score,
            'threat_probability': prediction.confidence if prediction.prediction == "malicious" else 1 - prediction.confidence,
            'anomaly_detected': prediction.anomaly_score > 0.5,
            'risk_level': self._get_risk_level(prediction.risk_score),
            'factors': self._analyze_risk_factors(scan_result, prediction)
        }
        
        # Combinar recomendaciones
        all_recommendations = prediction.recommendations.copy()
        all_recommendations.extend(self._generate_integration_recommendations(scan_result, prediction))
        
        return MLEnhancedScanResult(
            original_result=scan_result,
            ml_prediction=prediction,
            threat_patterns=patterns,
            risk_assessment=risk_assessment,
            recommendations=all_recommendations,
            confidence_score=prediction.confidence,
            processing_time=processing_time,
            timestamp=datetime.now()
        )
    
    def _create_basic_result(self, scan_result: Dict[str, Any], 
                           start_time: datetime) -> MLEnhancedScanResult:
        """Crea resultado básico sin análisis ML"""
        processing_time = (datetime.now() - start_time).total_seconds()
        
        # Análisis básico sin ML
        vuln_count = len(scan_result.get('vulnerabilities', []))
        basic_risk = min(vuln_count * 5, 100)  # Riesgo básico
        
        risk_assessment = {
            'overall_risk': basic_risk,
            'threat_probability': 0.0,
            'anomaly_detected': False,
            'risk_level': self._get_risk_level(basic_risk),
            'factors': ['Análisis ML no disponible']
        }
        
        recommendations = self._generate_basic_recommendations(scan_result)
        
        return MLEnhancedScanResult(
            original_result=scan_result,
            ml_prediction=None,
            threat_patterns=[],
            risk_assessment=risk_assessment,
            recommendations=recommendations,
            confidence_score=0.5,  # Confianza neutral
            processing_time=processing_time,
            timestamp=datetime.now()
        )
    
    def _get_risk_level(self, risk_score: float) -> str:
        """Determina nivel de riesgo basado en puntuación"""
        if risk_score >= 80:
            return "CRÍTICO"
        elif risk_score >= 60:
            return "ALTO"
        elif risk_score >= 40:
            return "MEDIO"
        elif risk_score >= 20:
            return "BAJO"
        else:
            return "MÍNIMO"
    
    def _analyze_risk_factors(self, scan_result: Dict[str, Any], 
                            prediction: PredictionResult) -> List[str]:
        """Analiza factores de riesgo"""
        factors = []
        
        vuln_count = len(scan_result.get('vulnerabilities', []))
        if vuln_count > 10:
            factors.append(f"Múltiples vulnerabilidades detectadas ({vuln_count})")
        
        if prediction and prediction.prediction == "malicious":
            factors.append("Actividad maliciosa predicha por ML")
        
        if prediction and prediction.anomaly_score > 0.5:
            factors.append("Comportamiento anómalo detectado")
        
        open_ports = scan_result.get('open_ports', [])
        if len(open_ports) > 20:
            factors.append(f"Muchos puertos abiertos ({len(open_ports)})")
        
        # Verificar puertos peligrosos
        if ML_CONFIG:
            dangerous_ports = [p for p in open_ports if ML_CONFIG.is_dangerous_port(p)]
            if dangerous_ports:
                factors.append(f"Puertos peligrosos expuestos: {dangerous_ports}")
        
        return factors
    
    def _generate_integration_recommendations(self, scan_result: Dict[str, Any], 
                                            prediction: PredictionResult) -> List[str]:
        """Genera recomendaciones específicas de integración"""
        recommendations = []
        
        # Recomendaciones basadas en tecnologías detectadas
        technologies = scan_result.get('technologies', [])
        for tech in technologies:
            if isinstance(tech, dict):
                tech_name = tech.get('name', '').lower()
                if 'wordpress' in tech_name:
                    recommendations.append("🔧 WordPress detectado - Verificar plugins y actualizaciones")
                elif 'apache' in tech_name:
                    recommendations.append("🔧 Apache detectado - Revisar configuración de seguridad")
                elif 'nginx' in tech_name:
                    recommendations.append("🔧 Nginx detectado - Verificar configuración SSL/TLS")
        
        # Recomendaciones basadas en vulnerabilidades
        vulnerabilities = scan_result.get('vulnerabilities', [])
        critical_vulns = [v for v in vulnerabilities if v.get('severity') == 'CRITICAL']
        if critical_vulns:
            recommendations.append(f"🚨 {len(critical_vulns)} vulnerabilidades críticas - Parchear inmediatamente")
        
        return recommendations
    
    def _generate_basic_recommendations(self, scan_result: Dict[str, Any]) -> List[str]:
        """Genera recomendaciones básicas sin ML"""
        recommendations = []
        
        vuln_count = len(scan_result.get('vulnerabilities', []))
        if vuln_count > 0:
            recommendations.append(f"🔍 {vuln_count} vulnerabilidades encontradas - Revisar y remediar")
        
        open_ports = scan_result.get('open_ports', [])
        if len(open_ports) > 10:
            recommendations.append("🔐 Muchos puertos abiertos - Cerrar servicios innecesarios")
        
        recommendations.append("🤖 Habilitar análisis ML para evaluación avanzada de riesgos")
        
        return recommendations
    
    def get_processing_stats(self) -> Dict[str, Any]:
        """Obtiene estadísticas de procesamiento"""
        stats = self.processing_stats.copy()
        stats['ml_available'] = self.is_ml_available()
        stats['cache_enabled'] = self.enable_cache
        stats['ml_enhancement_rate'] = (
            stats['ml_enhanced_scans'] / stats['total_scans'] 
            if stats['total_scans'] > 0 else 0
        )
        return stats
    
    def train_with_scan_data(self, scan_results: List[Dict[str, Any]], 
                           target_domains: List[str]):
        """Entrena modelos ML con datos de escaneos"""
        if not self.is_ml_available():
            logger.warning("Sistema ML no disponible para entrenamiento")
            return
        
        try:
            # Convertir resultados de escaneo a eventos de seguridad
            events = []
            for scan_result, domain in zip(scan_results, target_domains):
                event = self.convert_scan_to_security_event(scan_result, domain)
                events.append(event)
            
            logger.info(f"Entrenando modelos ML con {len(events)} eventos")
            
            # Entrenar modelos
            self.ml_analyzer.train_anomaly_detector(events)
            self.ml_analyzer.train_threat_classifier(events)
            
            logger.info("Entrenamiento ML completado")
        
        except Exception as e:
            logger.error(f"Error en entrenamiento ML: {e}")

# Función de utilidad para integración fácil
def enhance_scan_with_ml(scan_result: Dict[str, Any], target_domain: str, 
                        ml_manager: Optional[MLIntegrationManager] = None) -> MLEnhancedScanResult:
    """Función de conveniencia para enriquecer escaneo con ML"""
    if ml_manager is None:
        ml_manager = MLIntegrationManager()
    
    return ml_manager.enhance_scan_result(scan_result, target_domain)

# Instancia global para uso en el pipeline
ml_integration_manager = MLIntegrationManager()