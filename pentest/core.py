"""Pipeline principal del esc√°ner de seguridad con notificaciones de progreso."""

from __future__ import annotations
import json, logging, os, shutil, sys, tempfile, datetime as dt
from pathlib import Path
from typing import Dict, Optional, Callable, List
from concurrent.futures import ThreadPoolExecutor, as_completed

import redis

# --- m√≥dulos de tu proyecto -----------------------------------------------
from pentest.config import REDIS_URL, SAFE_DOMAIN
from pentest.exceptions import ScanError
from pentest.recon         import recon
from pentest.fingerprint   import fingerprint
from pentest.nuclei_scan   import nuclei_scan
from pentest.tls_scan      import tls_scan
from pentest.leaks         import check_leaks
from pentest.typosquat     import check_typosquats
from pentest.cve_scan      import cve_scan
from pentest.nmap_scan     import nmap_scan
from pentest.security_config import security_config_scan # Import the new security config scan module
from pentest.report        import build_pdf, send_notification
# ---------------------------------------------------------------------------

log = logging.getLogger("pentest")
logging.basicConfig(
    stream=sys.stdout,
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s"
)

rds: redis.Redis = redis.from_url(REDIS_URL)

# Paso, porcentaje acumulado aproximado y funci√≥n que lo ejecuta ------------
Step = Dict[str, object]
STEPS: List[Step] = [
    {"key": "recon",   "pct": 10, "runner": recon},
    {"key": "finger",  "pct": 30, "runner": fingerprint},
    {"key": "nuclei",  "pct": 55, "runner": nuclei_scan},
    {"key": "tls",     "pct": 70, "runner": tls_scan},
    {"key": "leaks",   "pct": 85, "runner": check_leaks},
    {"key": "typos",   "pct": 95, "runner": check_typosquats},
    {"key": "cve",     "pct": 97, "runner": cve_scan},
    {"key": "nmap",    "pct": 98, "runner": nmap_scan},
    {"key": "security_config", "pct": 99, "runner": security_config_scan}, # Add security config scan step
]

def _publish(job_id: str, payload: Dict):
    """Env√≠a el progreso por Pub/Sub y lo guarda en Redis hash."""
    try:
        rds.publish(job_id, json.dumps(payload))
        # Guardar progreso en Redis hash
        rds.hset(f"rq:job:{job_id}", "meta", json.dumps({"progress": payload}))
    except Exception:  # conexi√≥n Redis ca√≠da ‚Üí no interrumpir el scan
        pass

def _mark(job_id: str, step_key: str, pct: int, extra: Dict | None = None):
    data = {"state": "working", "step": step_key, "pct": pct}
    if extra:
        data.update(extra)
    _publish(job_id, data)

# ---------------------------------------------------------------------------
def generate_pdf(domain: str,
                 recipient_email: str,
                 job_id: str | None = None,
                 *,
                 hibp_api_key: str | None = None,
                 debug: bool = False) -> Dict:
    """
    Ejecuta el pipeline completo y devuelve dict con estado final.
    """
    if not SAFE_DOMAIN.match(domain):
        raise ScanError(f"Dominio inv√°lido: {domain}")

    if not job_id:
        job_id = f"standalone:{dt.datetime.utcnow().isoformat()}"

    tmp_dir = Path(tempfile.mkdtemp(prefix=f"scan_{domain}_"))
    log.info("‚ûú [%s] TMP %s", domain, tmp_dir)

    files: Dict[str, Path] = {}

    def _run_scan_step(step_key, step_pct, step_fn, *args, **kwargs):
        _mark(job_id, step_key, step_pct)
        log.info("‚Üí [%s] Iniciando fase: %s (%s %%)", domain, step_key, step_pct)
        try:
            result = step_fn(*args, **kwargs)
            log.info("‚úÖ [%s] Fase %s completada.", domain, step_key)
            return step_key, result
        except Exception as e:
            log.error("‚ùå [%s] Error en la fase %s: %s", domain, step_key, e)
            raise ScanError(f"Error en {step_key}: {e}") from e

    try:
        # Run recon and finger sequentially as they have dependencies
        recon_step = next(s for s in STEPS if s["key"] == "recon")
        key, pct, fn = recon_step["key"], recon_step["pct"], recon_step["runner"]
        _, files["subdomains"] = _run_scan_step(key, pct, fn, domain, tmp_dir)
        if files["subdomains"].exists():
            with open(files["subdomains"], "r") as f:
                subdomains_content = f.read()
            log.info("[%s] Contenido de subdomains.txt despu√©s de recon:\n%s", domain, subdomains_content)
        else:
            log.warning("El archivo subdomains.txt no fue creado por la fase recon.")

        finger_step = next(s for s in STEPS if s["key"] == "finger")
        key, pct, fn = finger_step["key"], finger_step["pct"], finger_step["runner"]
        _, files["httpx"] = _run_scan_step(key, pct, fn, files["subdomains"], tmp_dir)

        # Run remaining steps in parallel
        with ThreadPoolExecutor(max_workers=5) as executor:
            future_to_step = {}
            for step in STEPS:
                if step["key"] in ["recon", "finger"]: # Skip already run steps
                    continue

                key, pct, fn = step["key"], step["pct"], step["runner"]
                if key == "leaks":
                    future = executor.submit(_run_scan_step, key, pct, fn, domain, tmp_dir, hibp_api_key)
                elif key in ["nuclei", "tls", "cve", "nmap", "security_config"]:
                    future = executor.submit(_run_scan_step, key, pct, fn, files["httpx"], tmp_dir)
                elif key == "typos":
                    future = executor.submit(_run_scan_step, key, pct, fn, domain, tmp_dir)
                else:
                    continue # Should not happen
                future_to_step[future] = key

            for future in as_completed(future_to_step):
                step_key = future_to_step[future]
                try:
                    _, result = future.result()
                    if step_key == "leaks":
                        files["leaks"] = result
                    elif step_key == "nuclei":
                        files["nuclei"] = result
                    elif step_key == "tls":
                        files["tls"] = result
                    elif step_key == "typos":
                        files["typosquats"] = result
                    elif step_key == "cve":
                        files["cves"] = result
                    elif step_key == "nmap":
                        files["nmap"] = result
                    elif step_key == "security_config":
                        files["security_config"] = result
                except ScanError as e:
                    log.error("‚ùå [%s] Error al procesar el resultado de la fase %s: %s", domain, step_key, e)
                    # Decide if you want to re-raise or just log and continue
                    raise # Re-raise to fail the entire scan if a sub-task fails



        log.info("üìÑ [%s] Iniciando generaci√≥n de informe PDF.", domain) # Log antes de generar PDF
        pdf_path = build_pdf(domain, tmp_dir,
                             httpx_file=files["httpx"],
                             nuclei_file=files["nuclei"],
                             tls_file=files["tls"],
                             leaks_file=files["leaks"],
                             typosquats_file=files["typosquats"],
                             cves_file=files["cves"],
                             nmap_file=files["nmap"],
                             security_config_file=files["security_config"] # Pass security config file
                         )

        log.info("‚úÖ [%s] Informe PDF generado en %s.", domain, pdf_path) # Log despu√©s de generar PDF

        # Notificaci√≥n email (Best-Effort)
        log.info("üìß [%s] Enviando notificaci√≥n por correo electr√≥nico.", domain) # Log antes de enviar email
        subc = _safe_count_json(files.get("httpx"))
        vulc = _safe_count_json(files.get("nuclei"))
        send_notification(job_id, "PDF generado", "success", pdf_path, recipient_email, subc, vulc)
        log.info("‚úÖ [%s] Notificaci√≥n por correo electr√≥nico enviada.", domain) # Log despu√©s de enviar email

        final = Path(f"report_{domain}_{dt.datetime.utcnow():%Y%m%d%H%M}.pdf")
        shutil.copy(pdf_path, final)

        result = {"state": "finished", "report_path": str(final)}
        _publish(job_id, result)
        log.info("‚úÖ [%s] Escaneo finalizado", domain)

    except Exception as e:
        log.exception("‚ùå [%s] Error en el escaneo", domain)
        err = {"state": "failed", "error": str(e)}
        _publish(job_id, err)
        raise

    finally:
        if not debug:
            shutil.rmtree(tmp_dir, ignore_errors=True)

# ---------------------------------------------------------------------------
def _safe_count_json(path: Path | None) -> int:
    if not path or not path.exists(): return 0
    try:
        with open(path, "r") as f:
            return len(json.load(f))
    except Exception:
        return 0
# ---------------------------------------------------------------------------
#  MODO WORKER "B√ÅSICO" (sigue utilizando tu cola BLPOP)
# ---------------------------------------------------------------------------
def start_worker():
    log.info("‚åõ Worker BLPOP escuchando en redis queue 'scan_queue'")
    while True:
        log.info("Esperando mensajes en la cola 'scan_queue'...")
        _, raw = rds.blpop("scan_queue")
        log.info(f"Mensaje recibido: {raw}")
        try:
            log.info(f"Mensaje raw recibido: {raw}")
            req = json.loads(raw)
            log.info(f"Mensaje parseado: {req}")
            job_id = f"job:{dt.datetime.utcnow().isoformat()}"
            _publish(job_id, {"state": "queued"})
            log.info(f"Iniciando generate_pdf para dominio: {req['domain']} con job_id: {job_id}")
            generate_pdf(req["domain"], req["email"], job_id)
            log.info(f"generate_pdf completado para job_id: {job_id}")
        except Exception as e:
            log.error("Error procesando job %s ‚Äì %s", raw, e)

if __name__ == "__main__":
    start_worker()