#!/usr/bin/env python3
"""
Configuración para el módulo de IA/ML Predictivo
"""

import os
from typing import Dict, List, Any

class MLConfig:
    """Configuración centralizada para Machine Learning"""
    
    # Rutas de modelos
    MODEL_BASE_PATH = os.path.join(os.path.dirname(__file__), '..', 'models')
    ANOMALY_MODEL_PATH = os.path.join(MODEL_BASE_PATH, 'anomaly_detector.pkl')
    THREAT_MODEL_PATH = os.path.join(MODEL_BASE_PATH, 'threat_classifier.pkl')
    SCALER_PATH = os.path.join(MODEL_BASE_PATH, 'scaler.pkl')
    
    # Configuración de Isolation Forest (Detección de Anomalías)
    ANOMALY_DETECTION = {
        'contamination': 0.1,  # Porcentaje esperado de anomalías
        'n_estimators': 100,   # Número de árboles
        'random_state': 42,
        'max_samples': 'auto',
        'max_features': 1.0,
        'bootstrap': False,
        'n_jobs': -1
    }
    
    # Configuración de Random Forest (Clasificación de Amenazas)
    THREAT_CLASSIFICATION = {
        'n_estimators': 100,
        'random_state': 42,
        'class_weight': 'balanced',
        'max_depth': None,
        'min_samples_split': 2,
        'min_samples_leaf': 1,
        'max_features': 'sqrt',
        'bootstrap': True,
        'n_jobs': -1
    }
    
    # Configuración de DBSCAN (Clustering de patrones)
    PATTERN_CLUSTERING = {
        'eps': 0.5,
        'min_samples': 5,
        'metric': 'euclidean',
        'algorithm': 'auto',
        'leaf_size': 30,
        'n_jobs': -1
    }
    
    # Umbrales de detección
    THRESHOLDS = {
        'threat_probability': 0.5,      # Umbral para clasificar como amenaza
        'anomaly_score': 0.5,           # Umbral para detectar anomalías
        'risk_score_critical': 80,      # Riesgo crítico
        'risk_score_high': 60,          # Riesgo alto
        'risk_score_medium': 40,        # Riesgo medio
        'confidence_minimum': 0.6,      # Confianza mínima para predicciones
        'pattern_frequency_min': 3,     # Frecuencia mínima para patrones
        'vulnerability_high': 10,       # Umbral alto de vulnerabilidades
        'vulnerability_medium': 5       # Umbral medio de vulnerabilidades
    }
    
    # Características para el modelo
    FEATURE_COLUMNS = [
        'vulnerability_count',
        'threat_score',
        'response_time',
        'payload_size',
        'ports_count',
        'tech_count',
        'hour_of_day',
        'day_of_week',
        'is_weekend'
    ]
    
    # Pesos para el cálculo de risk score
    RISK_WEIGHTS = {
        'threat_probability': 100,      # Peso base de probabilidad de amenaza
        'anomaly_bonus': 20,            # Bonus por anomalía detectada
        'vuln_high_bonus': 15,          # Bonus por muchas vulnerabilidades
        'vuln_medium_bonus': 10,        # Bonus por vulnerabilidades medias
        'threat_score_high': 15,        # Bonus por threat score alto
        'threat_score_medium': 10,      # Bonus por threat score medio
        'dangerous_ports_bonus': 10     # Bonus por puertos peligrosos
    }
    
    # Puertos considerados peligrosos
    DANGEROUS_PORTS = [
        22,    # SSH
        23,    # Telnet
        135,   # RPC
        139,   # NetBIOS
        445,   # SMB
        1433,  # SQL Server
        3389,  # RDP
        5432,  # PostgreSQL
        3306,  # MySQL
        6379,  # Redis
        27017, # MongoDB
        9200,  # Elasticsearch
        5984,  # CouchDB
        8086,  # InfluxDB
        50070  # Hadoop
    ]
    
    # Configuración de entrenamiento
    TRAINING = {
        'test_size': 0.2,               # Porcentaje para testing
        'validation_size': 0.1,         # Porcentaje para validación
        'random_state': 42,
        'stratify': True,               # Estratificar por clase
        'cross_validation_folds': 5,    # Folds para validación cruzada
        'min_samples_for_training': 100, # Mínimo de muestras para entrenar
        'retrain_threshold_days': 7,    # Días para re-entrenar modelos
        'model_performance_threshold': 0.8 # Umbral mínimo de performance
    }
    
    # Configuración de patrones de amenazas
    THREAT_PATTERNS = {
        'frequent_attacker': {
            'min_attacks': 3,
            'time_window_hours': 24,
            'severity': 'HIGH',
            'confidence': 0.9
        },
        'vulnerable_target': {
            'min_vulnerabilities': 50,
            'severity': 'MEDIUM',
            'confidence': 0.8
        },
        'temporal_peak': {
            'multiplier_threshold': 2.0,
            'severity': 'LOW',
            'confidence': 0.6
        },
        'port_scanning': {
            'min_ports': 20,
            'time_window_minutes': 10,
            'severity': 'MEDIUM',
            'confidence': 0.7
        },
        'brute_force': {
            'min_attempts': 10,
            'time_window_minutes': 5,
            'severity': 'HIGH',
            'confidence': 0.8
        }
    }
    
    # Configuración de métricas y monitoreo
    METRICS = {
        'enable_performance_tracking': True,
        'log_predictions': True,
        'save_feature_importance': True,
        'track_model_drift': True,
        'alert_on_anomaly_spike': True,
        'anomaly_spike_threshold': 0.3,  # 30% de anomalías
        'performance_check_interval': 3600,  # 1 hora en segundos
        'metrics_retention_days': 30
    }
    
    # Configuración de cache
    CACHE = {
        'enable_prediction_cache': True,
        'cache_ttl_seconds': 300,       # 5 minutos
        'max_cache_size': 1000,         # Máximo de predicciones en cache
        'cache_key_prefix': 'ml_pred:',
        'enable_model_cache': True,
        'model_cache_ttl': 3600         # 1 hora
    }
    
    # Configuración de logging específico para ML
    LOGGING = {
        'level': 'INFO',
        'format': '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        'file_path': 'logs/ml_predictions.log',
        'max_file_size': 10 * 1024 * 1024,  # 10MB
        'backup_count': 5,
        'log_predictions': True,
        'log_training': True,
        'log_performance': True
    }
    
    # Configuración de alertas
    ALERTS = {
        'enable_real_time_alerts': True,
        'critical_risk_threshold': 90,
        'anomaly_burst_threshold': 10,   # Anomalías en 5 minutos
        'anomaly_burst_window': 300,     # 5 minutos
        'alert_cooldown': 900,           # 15 minutos entre alertas similares
        'webhook_url': os.getenv('ML_ALERT_WEBHOOK'),
        'email_alerts': True,
        'slack_alerts': False
    }
    
    # Configuración de API endpoints para ML
    API_CONFIG = {
        'enable_prediction_api': True,
        'enable_training_api': False,    # Solo para admin
        'enable_metrics_api': True,
        'rate_limit_per_minute': 100,
        'require_api_key': True,
        'prediction_timeout': 30,        # segundos
        'batch_prediction_limit': 100
    }
    
    # Configuración de datos sintéticos para testing
    SYNTHETIC_DATA = {
        'enable_generation': True,
        'malicious_ratio': 0.2,          # 20% de eventos maliciosos
        'anomaly_ratio': 0.1,            # 10% de anomalías
        'time_range_days': 30,
        'events_per_day': 100,
        'ip_pool_size': 50,
        'domain_pool_size': 10
    }
    
    # Configuración de integración con otros módulos
    INTEGRATION = {
        'enable_nuclei_features': True,
        'enable_nmap_features': True,
        'enable_waf_evasion_features': True,
        'enable_threat_intel_features': True,
        'feature_extraction_timeout': 10,  # segundos
        'external_api_timeout': 5,
        'fallback_on_error': True
    }
    
    @classmethod
    def get_model_config(cls, model_type: str) -> Dict[str, Any]:
        """Obtiene configuración específica para un tipo de modelo"""
        configs = {
            'anomaly': cls.ANOMALY_DETECTION,
            'threat': cls.THREAT_CLASSIFICATION,
            'clustering': cls.PATTERN_CLUSTERING
        }
        return configs.get(model_type, {})
    
    @classmethod
    def get_threshold(cls, threshold_name: str) -> float:
        """Obtiene un umbral específico"""
        return cls.THRESHOLDS.get(threshold_name, 0.5)
    
    @classmethod
    def is_dangerous_port(cls, port: int) -> bool:
        """Verifica si un puerto es considerado peligroso"""
        return port in cls.DANGEROUS_PORTS
    
    @classmethod
    def get_risk_weight(cls, weight_name: str) -> float:
        """Obtiene un peso específico para cálculo de riesgo"""
        return cls.RISK_WEIGHTS.get(weight_name, 0)
    
    @classmethod
    def should_retrain_model(cls, last_training_date) -> bool:
        """Determina si un modelo debe ser re-entrenado"""
        from datetime import datetime, timedelta
        
        if not last_training_date:
            return True
        
        threshold_date = datetime.now() - timedelta(
            days=cls.TRAINING['retrain_threshold_days']
        )
        return last_training_date < threshold_date
    
    @classmethod
    def validate_config(cls) -> List[str]:
        """Valida la configuración y retorna errores si los hay"""
        errors = []
        
        # Validar umbrales
        for name, value in cls.THRESHOLDS.items():
            if not isinstance(value, (int, float)) or value < 0:
                errors.append(f"Umbral inválido: {name} = {value}")
        
        # Validar rutas de modelos
        if not os.path.exists(os.path.dirname(cls.MODEL_BASE_PATH)):
            try:
                os.makedirs(cls.MODEL_BASE_PATH, exist_ok=True)
            except Exception as e:
                errors.append(f"No se puede crear directorio de modelos: {e}")
        
        # Validar configuración de entrenamiento
        if cls.TRAINING['test_size'] >= 1.0 or cls.TRAINING['test_size'] <= 0:
            errors.append("test_size debe estar entre 0 y 1")
        
        if cls.TRAINING['min_samples_for_training'] < 10:
            errors.append("min_samples_for_training debe ser al menos 10")
        
        return errors

# Configuración específica por ambiente
class DevelopmentMLConfig(MLConfig):
    """Configuración para desarrollo"""
    LOGGING = {
        **MLConfig.LOGGING,
        'level': 'DEBUG'
    }
    
    TRAINING = {
        **MLConfig.TRAINING,
        'min_samples_for_training': 50  # Menos muestras en desarrollo
    }
    
    SYNTHETIC_DATA = {
        **MLConfig.SYNTHETIC_DATA,
        'events_per_day': 50  # Menos eventos sintéticos
    }

class ProductionMLConfig(MLConfig):
    """Configuración para producción"""
    LOGGING = {
        **MLConfig.LOGGING,
        'level': 'WARNING'
    }
    
    API_CONFIG = {
        **MLConfig.API_CONFIG,
        'enable_training_api': False,  # Deshabilitado en producción
        'rate_limit_per_minute': 1000
    }
    
    CACHE = {
        **MLConfig.CACHE,
        'max_cache_size': 5000,  # Más cache en producción
        'cache_ttl_seconds': 600  # 10 minutos
    }

# Función para obtener configuración según ambiente
def get_ml_config():
    """Retorna la configuración apropiada según el ambiente"""
    env = os.getenv('ENVIRONMENT', 'development').lower()
    
    if env == 'production':
        return ProductionMLConfig
    else:
        return DevelopmentMLConfig

# Configuración activa
ML_CONFIG = get_ml_config()