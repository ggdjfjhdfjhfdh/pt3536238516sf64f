import logging
import asyncio
import json
import random
from pathlib import Path
from typing import List, Dict, Any, Optional

import httpx
from urllib.parse import urljoin

from pentest.exceptions import DirBruteError
from pentest.config import WAF_EVASION_CONFIG, WAF_USER_AGENTS, WAF_COMMON_HEADERS
from pentest.waf_handler import WAFDetector, WAFEvasionTechniques, WAFType

log = logging.getLogger(__name__)

def _is_waf_blocked_async(response, waf_type: str) -> bool:
    """Determina si la respuesta indica un bloqueo por WAF (versi√≥n para httpx).
    
    Args:
        response: Respuesta HTTP de httpx
        waf_type: Tipo de WAF detectado
        
    Returns:
        True si la respuesta indica bloqueo por WAF
    """
    # C√≥digos de estado que indican bloqueo
    blocked_status_codes = [403, 406, 429, 503, 520, 521, 522, 523, 524, 525]
    
    if response.status_code in blocked_status_codes:
        # Verificar patrones espec√≠ficos en el contenido
        content = response.text.lower() if hasattr(response, 'text') else ''
        
        blocked_patterns = [
            'access denied', 'blocked', 'forbidden', 'rate limit',
            'too many requests', 'security policy', 'firewall',
            'cloudflare', 'incapsula', 'sucuri', 'akamai'
        ]
        
        for pattern in blocked_patterns:
            if pattern in content:
                return True
    
    return False


async def dir_brute_scan(
    httpx_file: Path,
    tmp_dir: Path,
    extensions: Optional[List[str]] = None,
    auto_extend: bool = False,
    max_concurrent_requests: int = 100,
    delay_between_requests: float = 0.01,
    filter_status_codes: Optional[List[int]] = None,
    filter_content_length: Optional[int] = None,
    tech_stack: Optional[str] = None,
) -> Path:
    """Realiza un escaneo de fuerza bruta de directorios en los hosts activos.

    Args:
        httpx_file: Archivo JSON con hosts activos.
        tmp_dir: Directorio temporal para almacenar resultados.
        extensions: Lista de extensiones a probar (ej. ['php', 'html', 'js']).
        auto_extend: Si es True, combina las palabras clave con las extensiones proporcionadas.
        max_concurrent_requests: N√∫mero m√°ximo de peticiones concurrentes.
        delay_between_requests: Retraso en segundos entre peticiones para evitar saturaci√≥n.
        filter_status_codes: Lista de c√≥digos de estado HTTP a ignorar.
        filter_content_length: Longitud de contenido a ignorar (para 404 uniformes).
        tech_stack: Pila tecnol√≥gica detectada (ej. 'wordpress', 'laravel').

    Returns:
        Path: Ruta al archivo JSON con los resultados del escaneo de fuerza bruta de directorios.
    """
    log.info("üïµÔ∏è‚Äç‚ôÄÔ∏è Iniciando escaneo de fuerza bruta de directorios")

    output_file = tmp_dir / "dir_brute.json"


    # Diccionario de palabras peque√±as para fuerza bruta de directorios
    wordlist_path = Path(__file__).parent / "wordlists" / "dir_brute_small.txt"
    if not wordlist_path.exists():
        raise DirBruteError(f"No se encontr√≥ el archivo de wordlist: {wordlist_path}")

    with open(wordlist_path, "r") as f:
        base_wordlist = [line.strip() for line in f if line.strip()]

    # Wordlists espec√≠ficas por tecnolog√≠a
    tech_wordlists = {
        "wordpress": [
            "wp-admin", "wp-login.php", "wp-content", "wp-includes", "xmlrpc.php",
            "wp-json", "wp-cron.php", "license.txt", "readme.html"
        ],
        "laravel": [
            "storage", "logs", "artisan", ".env", "vendor", "public",
            "bootstrap/cache", "routes", "database", "resources", "app"
        ],
        # A√±adir m√°s tecnolog√≠as seg√∫n sea necesario
    }

    # Fusionar wordlist base con wordlist espec√≠fica de tecnolog√≠a
    current_wordlist = list(base_wordlist)
    if tech_stack and tech_stack.lower() in tech_wordlists:
        log.info(f"Detectado stack tecnol√≥gico: {tech_stack}. A√±adiendo palabras clave espec√≠ficas.")
        current_wordlist.extend(tech_wordlists[tech_stack.lower()])

    wordlist = []
    if auto_extend and extensions:
        for word in current_wordlist:
            wordlist.append(word)
            for ext in extensions:
                wordlist.append(f"{word}.{ext}")
    else:
        wordlist = current_wordlist

    findings = []

    try:
        with open(httpx_file, "r") as f:
            hosts_data = json.load(f)

        # Detectar WAF para cada host
        waf_cache = {}
        
        async def detect_waf_for_host(client, target_url):
            """Detecta WAF para un host espec√≠fico."""
            if target_url in waf_cache:
                return waf_cache[target_url]
            
            try:
                response = await client.get(target_url, timeout=10)
                # Convertir httpx.Response a algo compatible con WAFDetector
                mock_response = type('MockResponse', (), {
                    'headers': dict(response.headers),
                    'text': response.text,
                    'status_code': response.status_code
                })()
                
                waf_type, details = WAFDetector.detect_waf(mock_response)
                waf_cache[target_url] = {'type': waf_type, 'details': details}
                log.info(f"WAF detectado para {target_url}: {waf_type}")
                return waf_cache[target_url]
            except Exception as e:
                log.debug(f"Error detectando WAF para {target_url}: {e}")
                waf_cache[target_url] = {'type': WAFType.UNKNOWN, 'details': {}}
                return waf_cache[target_url]
        
        async def fetch(client, target_url, word, waf_info):
            try:
                # Obtener configuraci√≥n de evasi√≥n espec√≠fica para el WAF
                evasion_config = WAFEvasionTechniques.get_evasion_config(waf_info['type'])
                
                # Aplicar delay espec√≠fico del WAF
                waf_delays = evasion_config.get('delays', {'min': 0.01, 'max': 0.05})
                waf_delay = random.uniform(waf_delays['min'], waf_delays['max'])
                await asyncio.sleep(max(delay_between_requests, waf_delay))
                
                test_url = urljoin(target_url, word)
                
                # Usar headers espec√≠ficos para el WAF detectado
                headers = WAF_COMMON_HEADERS.copy()
                headers.update(evasion_config.get('headers', {}))
                
                # Usar User-Agent espec√≠fico para el WAF
                waf_user_agents = evasion_config.get('user_agents', WAF_USER_AGENTS)
                headers['User-Agent'] = random.choice(waf_user_agents)
                
                config = WAF_EVASION_CONFIG
                response = await client.get(
                    test_url, 
                    headers=headers,
                    follow_redirects=False, 
                    timeout=config['max_time']
                )

                # Aplicar filtros
                if filter_status_codes and response.status_code in filter_status_codes:
                    return
                if filter_content_length and len(response.content) == filter_content_length:
                    return

                # Verificar si la respuesta indica bloqueo por WAF
                is_blocked = _is_waf_blocked_async(response, waf_info['type'])
                
                if is_blocked:
                    log.warning(f"üõ°Ô∏è Petici√≥n bloqueada por WAF: {test_url}")
                    return {
                        "url": test_url,
                        "status_code": response.status_code,
                        "description": f"Bloqueado por WAF: {test_url}",
                        "waf_blocked": True
                    }
                
                # Manejar redirecciones 301/302 como hallazgos potenciales
                if response.status_code in [301, 302]:
                    location = response.headers.get('location', '')
                    log.debug(f"[+] Redirecci√≥n encontrada: {test_url} -> {location} (Status: {response.status_code})")
                    return {
                        "url": test_url,
                        "status_code": response.status_code,
                        "description": f"Redirecci√≥n encontrada: {test_url} -> {location}",
                        "redirect_location": location
                    }
                
                if response.status_code == 200:
                    return {
                        "url": test_url,
                        "status_code": response.status_code,
                        "description": f"Directorio o archivo encontrado: {test_url}",
                        "content_length": len(response.content),
                        "content_type": response.headers.get('content-type', '')
                    }
                elif response.status_code == 401 or response.status_code == 403:
                    return {
                        "url": test_url,
                        "status_code": response.status_code,
                        "description": f"Acceso denegado o requiere autenticaci√≥n: {test_url}"
                    }
                else:
                    log.debug(f"[-] No encontrado: {test_url} (Status: {response.status_code})")
                    return None
            except httpx.TimeoutException as e:
                log.debug(f"Timeout al escanear {test_url}: {e}")
                return None
            except httpx.ConnectError as e:
                log.debug(f"Error de conexi√≥n al escanear {test_url}: {e}")
                return None
            except httpx.RequestError as e:
                log.debug(f"Error de petici√≥n al escanear {test_url}: {e}")
                return None
            except Exception as e:
                log.warning(f"Error inesperado al escanear {test_url}: {e}")
                return None

        # Configurar cliente httpx con evasi√≥n anti-WAF
        config = WAF_EVASION_CONFIG
        client_config = {
            'timeout': httpx.Timeout(config['max_time']),
            'verify': False,  # Ignorar certificados SSL
            'limits': httpx.Limits(
                max_keepalive_connections=20,
                max_connections=max_concurrent_requests
            )
        }
        
        async with httpx.AsyncClient(**client_config) as client:
            # Primero detectar WAF para cada host
            host_waf_info = {}
            for host_info in hosts_data:
                target_url = host_info.get("url")
                if target_url:
                    host_waf_info[target_url] = await detect_waf_for_host(client, target_url)
            
            tasks = []
            for host_info in hosts_data:
                target_url = host_info.get("url")
                if not target_url:
                    continue

                waf_info = host_waf_info.get(target_url, {'type': WAFType.UNKNOWN, 'details': {}})
                log.info(f"üîç Escaneando directorios en {target_url} (WAF: {waf_info['type']})")

                for word in wordlist:
                    tasks.append(fetch(client, target_url, word, waf_info))

            # Control de concurrencia
            results = []
            for i in range(0, len(tasks), max_concurrent_requests):
                batch = tasks[i:i + max_concurrent_requests]
                batch_results = await asyncio.gather(*batch)
                results.extend([r for r in batch_results if r is not None])

            # Agrupar resultados por host
            host_grouped_findings = {}
            for res in results:
                host_url = urljoin(res["url"], '/') # Get base URL
                if host_url not in host_grouped_findings:
                    host_grouped_findings[host_url] = []
                host_grouped_findings[host_url].append(res)
            
            for host_url, host_findings in host_grouped_findings.items():
                findings.append({"host": host_url, "found_paths": host_findings})

        with open(output_file, "w") as f:
            json.dump(findings, f, indent=2)

        log.info("‚úÖ Escaneo de fuerza bruta de directorios completado. Resultados guardados en %s", output_file)
        return output_file

    except Exception as e:
        raise DirBruteError(f"Error durante el escaneo de fuerza bruta de directorios: {str(e)}") from e