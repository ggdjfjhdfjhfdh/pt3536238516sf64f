"""Módulo para generación de informes."""

import base64
from pathlib import Path
import datetime
import logging
import os
import json
from typing import Optional, List, Dict, Any
import yaml

from jinja2 import Environment, PackageLoader, select_autoescape

from pentest.exceptions import ReportError
# from pentest.config import TEMPLATES_DIR

MITRE_MAPPING_FILE = Path(__file__).parent / "mitre_mapping.yaml"

def load_mitre_mapping():
    """Carga el mapeo de CVE a MITRE ATT&CK desde el archivo YAML."""
    if not MITRE_MAPPING_FILE.exists():
        log.warning(f"Archivo de mapeo MITRE no encontrado: {MITRE_MAPPING_FILE}")
        return {}
    try:
        with open(MITRE_MAPPING_FILE, 'r') as f:
            return yaml.safe_load(f)
    except Exception as e:
        log.error(f"Error al cargar el mapeo MITRE desde {MITRE_MAPPING_FILE}: {e}")
        return {}

log = logging.getLogger("pentest")

mitre_mapping = load_mitre_mapping()

# Inicializar entorno Jinja2 y precompilar plantilla
env = None
template_report = None

try:
    env = Environment(
        loader=PackageLoader('pentest', 'templates'),
        autoescape=select_autoescape(['html', 'xml'])
    )
    log.info("Entorno Jinja2 creado correctamente")
    
    # Intentar cargar la plantilla de forma lazy (solo cuando se necesite)
    # template_report = env.get_template("report.html")
    # log.info("Plantilla report.html precargada correctamente")
except Exception as e:
    log.error("Error al inicializar entorno Jinja2: %s", str(e))
    import traceback
    log.error("Traceback completo: %s", traceback.format_exc())
    env = None
    template_report = None

def get_template():
    """Obtiene la plantilla de forma lazy."""
    global template_report, env
    if template_report is None and env is not None:
        try:
            template_report = env.get_template("report.html")
            log.info("Plantilla report.html cargada correctamente")
        except Exception as e:
            log.error("Error al cargar plantilla report.html: %s", str(e))
            import traceback
            log.error("Traceback completo: %s", traceback.format_exc())
            raise
    return template_report



def get_recommendations(
    nuclei_data: List[Dict[str, Any]],
    leaks_data: List[Dict[str, Any]],
    typosquats_data: List[Dict[str, Any]],
    cves_data: List[Dict[str, Any]],
    nmap_data: List[Dict[str, Any]],
    security_config_data: List[Dict[str, Any]],
    dir_brute_data: List[Dict[str, Any]],
    cisa_kev_data: List[Dict[str, Any]],
    greynoise_data: List[Dict[str, Any]],
    domain: str
) -> Dict[str, Any]:
    """Genera un resumen ejecutivo y una lista de recomendaciones basadas en los hallazgos del escaneo."""
    recommendations = []
    executive_summary_text = []

    # Calcular riesgo global basado en severidad de vulnerabilidades
    risk_score = 0
    severity_weights = {
        "critical": 5,
        "high": 4,
        "medium": 3,
        "low": 2,
        "info": 1
    }

    nuclei_severity_counts = {"critical": 0, "high": 0, "medium": 0, "low": 0, "info": 0}

    for vuln in nuclei_data:
        severity = vuln.get("info", {}).get("severity", "info").lower()
        risk_score += severity_weights.get(severity, 1)
        nuclei_severity_counts[severity] += 1



    if leaks_data:
        risk_score += 4  # Consideramos las credenciales filtradas como de severidad alta

    if typosquats_data:
        risk_score += 2  # Consideramos el typosquatting como de severidad baja

    for cve in cves_data:
        risk_score += 3  # Consideramos los CVEs como de severidad media

    for config_finding in security_config_data:
        risk_score += 2  # Consideramos los hallazgos de configuración como de severidad baja

    if cisa_kev_data:
        risk_score += 4  # CISA KEV son vulnerabilidades conocidas y explotadas, alta severidad

    if greynoise_data and greynoise_data.get("classification") == "malicious":
        risk_score += 5  # IP maliciosa por GreyNoise, crítica

    for nmap_item in nmap_data:
        if nmap_item.get("threat_intel"):
            risk_score += 3  # Consideramos la inteligencia de amenazas como de severidad media

    # Determinar nivel de riesgo global
    if risk_score >= 20:
        risk_level = "Crítico"
        executive_summary_text.append(f"El nivel de riesgo global para {domain} es CRÍTICO, indicando la presencia de vulnerabilidades severas que requieren atención inmediata.")
    elif risk_score >= 15:
        risk_level = "Alto"
        executive_summary_text.append(f"El nivel de riesgo global para {domain} es ALTO, con hallazgos significativos que podrían comprometer la seguridad si no se abordan con prontitud.")
    elif risk_score >= 10:
        risk_level = "Moderado"
        executive_summary_text.append(f"El nivel de riesgo global para {domain} es MODERADO, lo que sugiere la existencia de vulnerabilidades que, aunque no críticas, deben ser corregidas para fortalecer la postura de seguridad.")
    elif risk_score >= 5:
        risk_level = "Bajo"
        executive_summary_text.append(f"El nivel de riesgo global para {domain} es BAJO, con hallazgos menores que no representan un riesgo inminente pero que se recomienda revisar.")
    else:
        risk_level = "Informacional"
        executive_summary_text.append(f"El nivel de riesgo global para {domain} es INFORMACIONAL, lo que indica que no se encontraron vulnerabilidades significativas, pero se ofrecen recomendaciones para optimizar la seguridad.")

    # Resumen de hallazgos clave para el resumen ejecutivo
    if nuclei_severity_counts["critical"] > 0:
        executive_summary_text.append(f"Se identificaron {nuclei_severity_counts['critical']} vulnerabilidades CRÍTICAS con Nuclei.")
    if nuclei_severity_counts["high"] > 0:
        executive_summary_text.append(f"Se identificaron {nuclei_severity_counts['high']} vulnerabilidades ALTAS con Nuclei.")

    if leaks_data:
        executive_summary_text.append(f"Se encontraron credenciales de correo electrónico asociadas con brechas de seguridad conocidas, lo que representa un riesgo de compromiso de cuentas.")
    if typosquats_data:
        executive_summary_text.append(f"Se identificaron dominios de typosquatting que podrían ser utilizados en ataques de phishing.")
    if cves_data:
        executive_summary_text.append(f"Se detectaron CVEs en tecnologías utilizadas, lo que indica la presencia de vulnerabilidades conocidas.")
    if any(nmap_item.get('state') == 'open' for nmap_item in nmap_data):
        executive_summary_text.append(f"Se encontraron puertos abiertos que deben ser revisados para asegurar que solo los servicios necesarios estén expuestos.")
    if security_config_data:
        executive_summary_text.append(f"Se identificaron hallazgos en la configuración de seguridad que requieren ajustes para cumplir con las mejores prácticas.")
    if dir_brute_data:
        executive_summary_text.append(f"Se encontraron {len(dir_brute_data)} directorios o archivos expuestos mediante fuerza bruta ligera.")

    if cisa_kev_data:
        executive_summary_text.append(f"Se identificaron {len(cisa_kev_data)} vulnerabilidades de CISA KEV relevantes.")

    if greynoise_data and greynoise_data.get("classification") == "malicious":
        executive_summary_text.append(f"La IP {domain} fue clasificada como MALICIOSA por GreyNoise.")

    if any(nmap_item.get("threat_intel") for nmap_item in nmap_data):
        recommendations.append({
            "title": "Inteligencia de Amenazas Detectada",
            "description": "Se ha detectado inteligencia de amenazas asociada a una o más IPs escaneadas. Esto puede indicar que las IPs han sido reportadas por actividades maliciosas.",
            "solution": "Investigar las IPs reportadas en las plataformas de inteligencia de amenazas (ej. AlienVault OTX, AbuseIPDB) para entender la naturaleza de las actividades maliciosas y tomar las acciones correctivas necesarias, como el bloqueo de IPs o la revisión de la seguridad de los sistemas asociados."
        })

    if any(nmap_item.get("threat_intel") for nmap_item in nmap_data):
        executive_summary_text.append(f"Se encontró inteligencia de amenazas asociada a las IPs escaneadas.")

    # Recomendaciones para vulnerabilidades de Nuclei
    for vuln in nuclei_data:
        severity = vuln.get("info", {}).get("severity", "").lower()
        if severity in ["critical", "high", "medium"]:
            recommendations.append({
                "title": f"Vulnerabilidad {severity.capitalize()}: {vuln.get('info', {}).get('name', 'N/A')}",
                "description": f"Se detectó una vulnerabilidad de {severity} en {vuln.get('host', 'N/A')}. Detalles: {vuln.get('info', {}).get('description', 'N/A')}",
                "solution": f"Referencia: {vuln.get('info', {}).get('reference', 'N/A')}. Aplicar parches, actualizar software o reconfigurar según la vulnerabilidad específica. Priorizar la mitigación de vulnerabilidades {severity} para reducir el riesgo."
            })



    # Recomendaciones para credenciales filtradas
    if leaks_data:
        recommendations.append({
            "title": "Gestión de Credenciales Comprometidas",
            "description": "Se encontraron direcciones de correo electrónico asociadas con brechas de seguridad conocidas en Have I Been Pwned.",
            "solution": "Cambiar inmediatamente las contraseñas de todas las cuentas afectadas, especialmente si se reutilizan. Implementar una política de contraseñas robusta que exija complejidad y rotación periódica. Habilitar la autenticación de dos factores (2FA) en todos los servicios que lo permitan para añadir una capa extra de seguridad."
        })

    # Recomendaciones para typosquatting
    if typosquats_data:
        recommendations.append({
            "title": "Mitigación de Riesgos de Typosquatting",
            "description": "Se identificaron dominios similares al dominio objetivo que podrían ser utilizados para ataques de phishing o suplantación de identidad.",
            "solution": "Considerar el registro proactivo de las variantes de dominio más críticas para proteger la marca. Educar a los empleados y usuarios sobre los riesgos de phishing y la importancia de verificar cuidadosamente las URLs antes de hacer clic o introducir credenciales."
        })

    # Recomendaciones para CVEs
    # Manejar tanto la estructura antigua como la nueva
    cve_findings = cves_data
    if isinstance(cves_data, dict) and 'findings' in cves_data:
        cve_findings = cves_data['findings']
    
    for cve in cve_findings:
        # Validar que cve sea un diccionario antes de usar .get()
        if not isinstance(cve, dict):
            continue
            
        cve_id = cve.get('id') or cve.get('cve_id', 'N/A')
        technology = cve.get('technology') or cve.get('affected_technology', 'N/A')
        recommendations.append({
            "title": f"Parchear CVE: {cve_id}",
            "description": f"Se detectó una vulnerabilidad conocida ({cve_id}) en {technology}.",
            "solution": "Consultar las bases de datos de vulnerabilidades (NVD, CVE Mitre) para obtener información detallada sobre el parche o la mitigación específica. Actualizar el software o componente afectado a la última versión estable que contenga la corrección para el CVE."
        })

    # Recomendaciones para Nmap (ejemplo: puertos abiertos inesperados)
    if nmap_data:
        open_ports = [item for item in nmap_data if item.get('state') == 'open']
        if open_ports:
            recommendations.append({
                "title": "Revisión y Cierre de Puertos Abiertos",
                "description": f"Se detectaron {len(open_ports)} puertos abiertos en los hosts escaneados. Algunos de estos puertos podrían no ser necesarios o estar mal configurados, exponiendo servicios innecesarios.",
                "solution": "Realizar una auditoría de todos los puertos abiertos para determinar su necesidad. Cerrar o filtrar mediante firewall cualquier puerto que no sea estrictamente necesario para la operación del servicio. Asegurarse de que los servicios expuestos estén correctamente configurados, parcheados y protegidos con autenticación fuerte."
            })

    # Recomendaciones para configuración de seguridad
    if security_config_data:
        recommendations.append({
            "title": "Optimización de la Configuración de Seguridad",
            "description": "Se identificaron posibles malas configuraciones de seguridad en el servidor web o las aplicaciones.",
            "solution": "Revisar y aplicar las mejores prácticas de seguridad para la configuración del servidor web (e.g., Apache, Nginx) y las aplicaciones. Esto incluye la eliminación de cabeceras informativas (Server, X-Powered-By), la configuración de políticas de seguridad de contenido (CSP), la implementación de HSTS, y la protección contra ataques comunes como XSS y CSRF."
        })

    # Recomendaciones para fuerza bruta de directorios
    if dir_brute_data:
        recommendations.append({
            "title": "Proteger Directorios y Archivos Expuestos",
            "description": f"Se detectaron {len(dir_brute_data)} directorios o archivos accesibles públicamente que podrían contener información sensible o ser puntos de entrada para ataques.",
            "solution": "Revisar los directorios y archivos expuestos para asegurar que no contengan información sensible. Implementar controles de acceso adecuados (autenticación, autorización) para proteger recursos críticos. Eliminar archivos innecesarios o de respaldo que puedan haber quedado expuestos. Considerar el uso de un WAF (Web Application Firewall) para mitigar ataques de fuerza bruta y enumeración de directorios." 
        })

    # Recomendaciones para CISA KEV
    if cisa_kev_data:
        for vul in cisa_kev_data:
            recommendations.append({
                "title": f"Vulnerabilidad CISA KEV: {vul.get('cveID', 'N/A')}",
                "description": f"Se detectó una vulnerabilidad conocida y explotada ({vul.get('cveID', 'N/A')}) en {vul.get('vendorProduct', 'N/A')}. Fecha límite para parchear: {vul.get('dueDate', 'N/A')}.",
                "solution": "Priorizar la aplicación de parches o mitigaciones para esta vulnerabilidad, ya que se sabe que está siendo explotada activamente. Consultar los avisos de CISA para obtener orientación específica sobre la remediación."
            })

    # Recomendaciones para GreyNoise
    if greynoise_data and greynoise_data.get("classification") == "malicious":
        recommendations.append({
            "title": "IP Maliciosa Detectada por GreyNoise",
            "description": f"La dirección IP {domain} ha sido clasificada como maliciosa por GreyNoise, indicando actividad de escaneo o ataque.",
            "solution": "Investigar la actividad de red asociada con esta IP. Considerar bloquear el tráfico desde esta IP en el firewall. Implementar sistemas de detección de intrusiones (IDS/IPS) para identificar y mitigar ataques de IPs maliciosas conocidas."
        })

    return {
        "recommendations": recommendations,
        "risk_level": risk_level,
        "risk_score": risk_score,
        "executive_summary": " ".join(executive_summary_text),
        "nuclei_severity_counts": nuclei_severity_counts,

}

MITRE_TACTICS = [
    "Reconnaissance", "Resource Development", "Initial Access", "Execution",
    "Persistence", "Privilege Escalation", "Defense Evasion", "Credential Access",
    "Discovery", "Lateral Movement", "Collection", "Command and Control",
    "Exfiltration", "Impact"
]

def generate_mitre_heatmap_data(
    cves_data: List[Dict[str, Any]],
    security_config_data: List[Dict[str, Any]],
    mitre_mapping: Dict[str, str]
) -> Dict[str, Dict[str, bool]]:
    """Genera los datos para el mini-heatmap de MITRE ATT&CK."""
    heatmap_data = {tactic: {tech: False for tech in mitre_mapping.values()} for tactic in MITRE_TACTICS}

    # Mapear CVEs a técnicas MITRE
    # Manejar tanto la estructura antigua como la nueva
    cve_findings = cves_data
    if isinstance(cves_data, dict) and 'findings' in cves_data:
        cve_findings = cves_data['findings']
    
    for cve in cve_findings:
        # Validar que cve sea un diccionario antes de usar .get()
        if not isinstance(cve, dict):
            continue
            
        cve_id = cve.get("id") or cve.get("cve_id")
        if cve_id and cve_id in mitre_mapping:
            technique_id = mitre_mapping[cve_id]
            # Asumimos que cada técnica pertenece a una táctica, esto es una simplificación
            # En un caso real, se necesitaría un mapeo más completo de técnicas a tácticas.
            # Por ahora, solo marcamos la técnica como presente si la táctica es genérica.
            for tactic in MITRE_TACTICS:
                # Esto es un placeholder. La lógica real debería mapear T-ID a Táctica.
                # Para este ejemplo, simplemente marcamos la técnica si existe en el mapeo.
                if technique_id in mitre_mapping.values(): # Check if the technique ID is one of the mapped ones
                    # This part needs refinement to correctly map technique to tactic
                    # For now, we'll just mark it as present in a generic way
                    # A more robust solution would involve a full MITRE ATT&CK dataset
                    pass # We'll handle the actual marking in the template or with a more complex data structure

    # Mapear hallazgos de configuración de seguridad a técnicas MITRE
    for config_finding in security_config_data:
        finding_name = config_finding.get("name")
        if finding_name and finding_name in mitre_mapping:
            technique_id = mitre_mapping[finding_name]
            for tactic in MITRE_TACTICS:
                # Similar al caso de CVEs, se necesita un mapeo más preciso
                pass

    # Para el propósito de este mini-heatmap, vamos a simplificar el mapeo
    # y solo indicaremos si una técnica mapeada está presente.
    # La estructura heatmap_data debería ser {tactic: {technique_id: bool_present}}
    # Para simplificar, vamos a crear una lista de técnicas detectadas.
    detected_techniques = set()
    # Manejar tanto la estructura antigua como la nueva para CVEs
    cve_findings = cves_data
    if isinstance(cves_data, dict) and 'findings' in cves_data:
        cve_findings = cves_data['findings']
    
    for cve in cve_findings:
        # Validar que cve sea un diccionario antes de usar .get()
        if not isinstance(cve, dict):
            continue
            
        cve_id = cve.get("id") or cve.get("cve_id")
        if cve_id and cve_id in mitre_mapping:
            detected_techniques.add(mitre_mapping[cve_id])

    for config_finding in security_config_data:
        finding_name = config_finding.get("name")
        if finding_name and finding_name in mitre_mapping:
            detected_techniques.add(mitre_mapping[finding_name])

    # Rellenar heatmap_data con las técnicas detectadas
    # Esto es una simplificación. En un caso real, cada técnica tiene una o más tácticas asociadas.
    # Para el mini-heatmap, podemos simplemente mostrar las técnicas detectadas bajo una táctica genérica
    # o si tenemos un mapeo de T-ID a Táctica, usarlo.
    # Dado que el YAML solo mapea CVE/Finding a T-ID, necesitamos un mapeo de T-ID a Táctica.
    # Por simplicidad, vamos a crear una estructura que solo muestre las técnicas detectadas.
    # La idea es que el PDF muestre una tabla con Tácticas y debajo las Técnicas.
    # Para el mini-heatmap, podemos tener una lista de técnicas y marcarlas.

    # Vamos a crear una estructura más simple para el heatmap:
    # {tactic: [list_of_techniques_under_this_tactic_that_are_detected]}
    # Esto requiere un mapeo de T-ID a Táctica, que no está en el YAML.
    # Para el propósito de este ejercicio, vamos a asumir un mapeo simple o mostrar solo las técnicas.

    # Para el mini-heatmap, vamos a crear una lista de todas las técnicas posibles
    # y marcar las que se han detectado.
    # Esto es más fácil de renderizar en una tabla simple.

    # Vamos a usar una estructura que mapee T-ID a su nombre y si está presente.
    # Esto es una simplificación extrema para el mini-heatmap.
    # La clave es que el YAML solo da T-ID, no el nombre de la técnica ni la táctica.
    # Necesitamos una fuente de datos de MITRE ATT&CK completa para eso.

    # Para el propósito de este ejercicio, vamos a generar una lista de técnicas detectadas
    # y el PDF las listará o las marcará en una tabla predefinida.

    # La estructura del heatmap_data debería ser: {tactic: {technique_id: is_detected}}
    # Para esto, necesitamos saber a qué táctica pertenece cada technique_id.
    # Como no tenemos un mapeo completo de MITRE, vamos a simularlo.

    # Mapeo simplificado de T-ID a Táctica (ejemplo, no exhaustivo)
    technique_to_tactic = {
        "T1190": "Initial Access", # Exploit Public-Facing Application
        "T1059": "Execution"       # Command and Scripting Interpreter
    }

    final_heatmap_data = {tactic: {} for tactic in MITRE_TACTICS}

    for tech_id in detected_techniques:
        tactic = technique_to_tactic.get(tech_id, "Other") # Asignar a 'Other' si no está mapeado
        if tactic not in final_heatmap_data:
            final_heatmap_data[tactic] = {}
        final_heatmap_data[tactic][tech_id] = True

    return final_heatmap_data


def build_pdf(
    domain: str,
    recipient_email: str,
    tmp_dir: Path,
    httpx_file: Path,
    nuclei_file: Path,
    leaks_file: Path,
    typosquats_file: Path,
    dir_brute_file: Path,
    
    cves_file: Path,
    nmap_file: Path,
    security_config_file: Path,
    cisa_kev_file: Path,
    greynoise_file: Path,
    premium_adaptive_file: Path = None,
    ml_file: Path = None,
) -> Path:
    """Genera un informe PDF con los resultados del escaneo.
    
    Args:
        domain: Dominio objetivo
        tmp_dir: Directorio temporal para almacenar resultados
        httpx_file: Archivo JSON con hosts activos
        nuclei_file: Archivo JSON con vulnerabilidades

        leaks_file: Archivo JSON con credenciales filtradas
        typosquats_file: Archivo JSON con dominios typosquatting
        
    Returns:
        Path al archivo PDF generado
        
    Raises:
        ReportError: Si falla la generación del informe
    """
    log.info("📊 Iniciando generación de informe para %s", domain)
    
    output_pdf = tmp_dir / f"report_{domain}.pdf"
    output_html = tmp_dir / f"report_{domain}.html"
    
    # Cargar datos
    try:
        # Helper function to load JSON data or return empty list if file is None or doesn't exist
        def load_json_or_empty(file_path) -> List[Dict[str, Any]]:
            # Handle case where file_path is already a dict (like premium_adaptive_file)
            if isinstance(file_path, dict):
                return [file_path]  # Wrap dict in list
            
            if file_path and hasattr(file_path, 'exists') and file_path.exists():
                with open(file_path, "r") as f:
                    data = json.load(f)
                    # Handle different JSON structures based on filename
                    filename = file_path.name.lower()
                    
                    if 'dir_brute' in filename or 'directories' in filename:
                        if isinstance(data, dict):
                            return data.get('directories', data.get('results', []))
                        return data if isinstance(data, list) else []
                    
                    elif 'security_config' in filename or 'security' in filename:
                        if isinstance(data, dict):
                            return data.get('results', data.get('findings', []))
                        return data if isinstance(data, list) else []
                    
                    elif 'cve' in filename:
                        if isinstance(data, dict):
                            return data.get('cves', data.get('vulnerabilities', []))
                        return data if isinstance(data, list) else []
                    
                    elif 'cisa' in filename or 'kev' in filename:
                        if isinstance(data, dict):
                            return data.get('vulnerabilities', data.get('kev_matches', []))
                        return data if isinstance(data, list) else []
                    
                    elif 'leak' in filename or 'breach' in filename:
                        if isinstance(data, dict):
                            return data.get('breaches', data.get('leaks', []))
                        return data if isinstance(data, list) else []
                    
                    elif 'typo' in filename:
                        if isinstance(data, dict):
                            return data.get('typosquats', data.get('domains', []))
                        return data if isinstance(data, list) else []
                    
                    elif 'greynoise' in filename:
                        # GreyNoise returns a dict with IP info, convert to list format
                        if isinstance(data, dict) and data:
                            return [data]  # Wrap single dict in list
                        return data if isinstance(data, list) else []
                    
                    elif 'premium_adaptive' in filename:
                        if isinstance(data, dict):
                            return data.get('findings', data.get('vulnerabilities', data.get('recommendations', [])))
                        return data if isinstance(data, list) else []
                    
                    else:
                        # Default behavior for other files (like nmap, httpx)
                        return data if isinstance(data, list) else []
            return []
        
        # Helper function specifically for nuclei data that handles new structure
        def load_nuclei_data(file_path) -> List[Dict[str, Any]]:
            # Handle case where file_path is already a dict
            if isinstance(file_path, dict):
                if 'findings' in file_path:
                    return file_path['findings']
                elif isinstance(file_path, list):
                    return file_path
                else:
                    return [file_path]
            
            if file_path and hasattr(file_path, 'exists') and file_path.exists():
                with open(file_path, "r") as f:
                    data = json.load(f)
                    # Handle new structure with 'findings' key
                    if isinstance(data, dict) and 'findings' in data:
                        return data['findings']
                    # Handle old structure (direct list)
                    elif isinstance(data, list):
                        return data
                    else:
                        return []
            return []

        httpx_data = load_json_or_empty(httpx_file)
        nuclei_data = load_nuclei_data(nuclei_file)
        leaks_data = load_json_or_empty(leaks_file)
        typosquats_data = load_json_or_empty(typosquats_file)
        cves_data = load_json_or_empty(cves_file)
        nmap_data = load_json_or_empty(nmap_file)
        security_config_data = load_json_or_empty(security_config_file)
        dir_brute_data = load_json_or_empty(dir_brute_file)
        
        cisa_kev_data = load_json_or_empty(cisa_kev_file)
        greynoise_data = load_json_or_empty(greynoise_file)
        premium_adaptive_data = load_json_or_empty(premium_adaptive_file)
        
        # Cargar datos ML
        ml_data = None
        if ml_file and ml_file.exists():
            try:
                with open(ml_file, "r") as f:
                    ml_data = json.load(f)
                log.info(f"📊 Datos ML cargados desde: {ml_file}")
            except (json.JSONDecodeError, IOError) as e:
                log.warning(f"Error al cargar datos ML desde {ml_file}: {e}")
                ml_data = None

        # Subdominios (recon)
        # The subdomains file is a simple list of subdomains, one per line.
        # We need to read it and count the lines.
        subdomains_file = tmp_dir / "subdomains.txt"
        subdomains_data = []
        if subdomains_file.exists():
            with open(subdomains_file, "r") as f:
                subdomains_data = [line.strip() for line in f if line.strip()]
    except json.JSONDecodeError as e:
        raise ReportError(f"Error al cargar datos JSON de un archivo: {str(e)}") from e
    except FileNotFoundError as e:
        raise ReportError(f"Archivo no encontrado durante la carga de datos: {str(e)}") from e
    except Exception as e:
        raise ReportError(f"Error inesperado durante la carga de datos: {str(e)}") from e
        raise ReportError(f"Error al cargar datos: {str(e)}") from e

    # Generar recomendaciones y resumen ejecutivo
    report_data = get_recommendations(
        nuclei_data,

        leaks_data,
        typosquats_data,
        cves_data,
        nmap_data,
        security_config_data,
        dir_brute_data,
        cisa_kev_data,
        greynoise_data,
        domain
    )
    recommendations = report_data["recommendations"]
    risk_level = report_data["risk_level"]
    risk_score = report_data["risk_score"]
    executive_summary_text = report_data["executive_summary"]
    nuclei_severity_counts = report_data["nuclei_severity_counts"]


    # Renderizar plantilla HTML
    try:
        template = get_template()
        if template is None:
            raise ReportError("La plantilla de informe no se pudo cargar.")
        
        html_content = template.render(
            domain=domain,
            date=datetime.date.today().strftime("%d/%m/%Y"),
            httpx_data=httpx_data,
            nuclei_data=nuclei_data,
            leaks_data=leaks_data,
            typosquats_data=typosquats_data,
            cves_data=cves_data,
            nmap_data=nmap_data,
            security_config_data=security_config_data,
            dir_brute_data=dir_brute_data,
            premium_adaptive_data=premium_adaptive_data,
            ml_data=ml_data,
            recommendations=recommendations,
            risk_level=risk_level,
            executive_summary_text=executive_summary_text,
            subdomains_count=len(subdomains_data) if subdomains_data else 0,
            httpx_count=len(httpx_data) if httpx_data else 0,
            nuclei_critical_high_count=sum(1 for v in nuclei_data if v.get("info", {}).get("severity", "").lower() in ["critical", "high"]),
            leaks_count=len(leaks_data) if leaks_data else 0,
            typosquats_count=len(typosquats_data) if typosquats_data else 0,
            cves_count=len(cves_data) if cves_data else 0,
            nmap_open_ports_count=sum(1 for nmap_item in nmap_data if nmap_item.get('state') == 'open') if nmap_data else 0,
            security_config_count=len(security_config_data) if security_config_data else 0,
            dir_brute_count=len(dir_brute_data) if dir_brute_data else 0,
            premium_adaptive_count=len(premium_adaptive_data) if premium_adaptive_data else 0,
            risk_score=risk_score,
            nuclei_severity_counts=nuclei_severity_counts,
            mitre_heatmap_data=generate_mitre_heatmap_data(cves_data, security_config_data, mitre_mapping),
            mitre_tactics=MITRE_TACTICS
        )
    except Exception as e:
        raise ReportError(f"Error al renderizar la plantilla HTML: {str(e)}") from e

    with open(output_html, "w", encoding="utf-8") as f:
        f.write(html_content)

    # Generar PDF con WeasyPrint
    try:
        from weasyprint import HTML
        HTML(string=html_content).write_pdf(str(output_pdf))
        log.info("PDF generado exitosamente con WeasyPrint en %s", output_pdf)
    except Exception as e:
        raise ReportError(f"Error al generar el PDF con WeasyPrint: {str(e)}") from e

    log.debug("build_pdf returning: %s", output_pdf)
    return output_pdf





def encode_pdf_for_email(pdf_path: Path) -> str:
    """Codifica un PDF en base64 para adjuntarlo a un email.
    
    Args:
        pdf_path: Ruta al archivo PDF
        
    Returns:
        String con el PDF codificado en base64
    """
    with open(pdf_path, "rb") as f:
        return base64.b64encode(f.read()).decode("utf-8")

def send_notification(job_id: str, status_message: str, status_type: str, pdf_path: Optional[Path], recipient_email: str, subc: int, vulc: int, domain: str, cisa_kev_vulnerabilities: int = 0, greynoise_malicious_ips: int = 0,  threat_intel_hits: int = 0):
    """Envía una notificación por email con el informe adjunto.
    
    Args:
        job_id: ID del trabajo de escaneo.
        status_message: Mensaje de estado del escaneo.
        status_type: Tipo de estado (e.g., "success", "failed").
        pdf_path: Ruta al archivo PDF.
        recipient_email: Email del destinatario.
        subc: Número de subdominios encontrados.
        vulc: Número de vulnerabilidades encontradas.
        
    Returns:
        True si se envió correctamente, False en caso contrario.
    """
    log.info("📧 Enviando notificación a %s para el dominio %s (trabajo %s)", recipient_email, domain, job_id)
    
    # Obtener clave API de MailerSend
    api_key = os.getenv("MAILERSEND_API_KEY")
    if not api_key:
        log.error("No se ha configurado la clave API de MailerSend")
        return False
    
    try:
        # Importar requests si no está disponible en el ámbito global
        import requests
        from pentest.http_utils import get_session
        from pentest.config import MAIL_SENDER_EMAIL, MAIL_SENDER_NAME
        
        # Asunto del correo
        subject = f"Pentest Express - Escaneo {status_type.capitalize()}: {job_id}"

        # Cuerpo del correo
        body = f"Hola,\n\nEl escaneo para el trabajo {job_id} ha finalizado con estado: {status_message}.\n\nDetalles:\n- Subdominios encontrados: {subc}\n- Vulnerabilidades encontradas: {vulc}\n\n- Hits de inteligencia de amenazas: {threat_intel_hits}\n\nSaludos,\nEl equipo de Pentest Express"

        # Datos para la API de MailerSend
        data = {
            "from": {"email": MAIL_SENDER_EMAIL, "name": MAIL_SENDER_NAME},
            "to": [{"email": recipient_email}],
            "subject": subject,
            "html": f"<p>{body.replace(chr(10), '<br>')}</p>"
        }

        # Adjuntar PDF si está disponible
        if pdf_path and pdf_path.exists():
            pdf_data = base64.b64encode(pdf_path.read_bytes()).decode("utf-8")
            data["attachments"] = [
                {
                    "filename": pdf_path.name,
                    "content": pdf_data
                }
            ]
            body += "\n\nAdjunto encontrarás el informe completo."

        # Enviar correo
        session = get_session()
        headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
        response = session.post("https://api.mailersend.com/v1/email", headers=headers, json=data)
        response.raise_for_status() # Lanza una excepción para códigos de estado HTTP erróneos

        log.info("✅ Notificación enviada correctamente para el dominio %s", domain)
        return True

    except requests.exceptions.RequestException as e:
        log.error("Error al enviar notificación para el dominio %s: %s", domain, e)
        return False
    except Exception as e:
        log.error("Error inesperado al enviar notificación para el dominio %s: %s", domain, e)
        return False