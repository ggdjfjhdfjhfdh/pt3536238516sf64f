"""M√≥dulo para generaci√≥n de informes."""

import base64
from pathlib import Path
import datetime
import logging
import os
import json
from typing import Optional, List, Dict, Any
import yaml

from jinja2 import Environment, PackageLoader, select_autoescape

from pentest.exceptions import ReportError
# from pentest.config import TEMPLATES_DIR

MITRE_MAPPING_FILE = Path(__file__).parent / "mitre_mapping.yaml"

def load_mitre_mapping():
    """Carga el mapeo de CVE a MITRE ATT&CK desde el archivo YAML."""
    if not MITRE_MAPPING_FILE.exists():
        log.warning(f"Archivo de mapeo MITRE no encontrado: {MITRE_MAPPING_FILE}")
        return {}
    try:
        with open(MITRE_MAPPING_FILE, 'r') as f:
            return yaml.safe_load(f)
    except Exception as e:
        log.error(f"Error al cargar el mapeo MITRE desde {MITRE_MAPPING_FILE}: {e}")
        return {}

log = logging.getLogger("pentest")

mitre_mapping = load_mitre_mapping()

# Inicializar entorno Jinja2 y precompilar plantilla
env = None
template_report = None

try:
    env = Environment(
        loader=PackageLoader('pentest', 'templates'),
        autoescape=select_autoescape(['html', 'xml'])
    )
    log.info("Entorno Jinja2 creado correctamente")
    
    # Intentar cargar la plantilla de forma lazy (solo cuando se necesite)
    # template_report = env.get_template("report.html")
    # log.info("Plantilla report.html precargada correctamente")
except Exception as e:
    log.error("Error al inicializar entorno Jinja2: %s", str(e))
    import traceback
    log.error("Traceback completo: %s", traceback.format_exc())
    env = None
    template_report = None

def get_template():
    """Obtiene la plantilla de forma lazy."""
    global template_report, env
    if template_report is None and env is not None:
        try:
            template_report = env.get_template("report.html")
            log.info("Plantilla report.html cargada correctamente")
        except Exception as e:
            log.error("Error al cargar plantilla report.html: %s", str(e))
            import traceback
            log.error("Traceback completo: %s", traceback.format_exc())
            raise
    return template_report



def get_recommendations(
    nuclei_data: List[Dict[str, Any]],
    leaks_data: List[Dict[str, Any]],
    typosquats_data: List[Dict[str, Any]],
    cves_data: List[Dict[str, Any]],
    nmap_data: List[Dict[str, Any]],
    security_config_data: List[Dict[str, Any]],
    dir_brute_data: List[Dict[str, Any]],
    cisa_kev_data: List[Dict[str, Any]],
    greynoise_data: List[Dict[str, Any]],
    domain: str
) -> Dict[str, Any]:
    """Genera un resumen ejecutivo y una lista de recomendaciones basadas en los hallazgos del escaneo."""
    recommendations = []
    executive_summary_text = []

    # Calcular riesgo global basado en severidad de vulnerabilidades
    risk_score = 0
    severity_weights = {
        "critical": 5,
        "high": 4,
        "medium": 3,
        "low": 2,
        "info": 1
    }

    nuclei_severity_counts = {"critical": 0, "high": 0, "medium": 0, "low": 0, "info": 0}

    for vuln in nuclei_data:
        severity = vuln.get("info", {}).get("severity", "info").lower()
        risk_score += severity_weights.get(severity, 1)
        nuclei_severity_counts[severity] += 1



    if leaks_data:
        risk_score += 4  # Consideramos las credenciales filtradas como de severidad alta

    if typosquats_data:
        risk_score += 2  # Consideramos el typosquatting como de severidad baja

    for cve in cves_data:
        risk_score += 3  # Consideramos los CVEs como de severidad media

    for config_finding in security_config_data:
        risk_score += 2  # Consideramos los hallazgos de configuraci√≥n como de severidad baja

    if cisa_kev_data:
        risk_score += 4  # CISA KEV son vulnerabilidades conocidas y explotadas, alta severidad

    if greynoise_data and greynoise_data.get("classification") == "malicious":
        risk_score += 5  # IP maliciosa por GreyNoise, cr√≠tica

    for nmap_item in nmap_data:
        if nmap_item.get("threat_intel"):
            risk_score += 3  # Consideramos la inteligencia de amenazas como de severidad media

    # Determinar nivel de riesgo global
    if risk_score >= 20:
        risk_level = "Cr√≠tico"
        executive_summary_text.append(f"El nivel de riesgo global para {domain} es CR√çTICO, indicando la presencia de vulnerabilidades severas que requieren atenci√≥n inmediata.")
    elif risk_score >= 15:
        risk_level = "Alto"
        executive_summary_text.append(f"El nivel de riesgo global para {domain} es ALTO, con hallazgos significativos que podr√≠an comprometer la seguridad si no se abordan con prontitud.")
    elif risk_score >= 10:
        risk_level = "Moderado"
        executive_summary_text.append(f"El nivel de riesgo global para {domain} es MODERADO, lo que sugiere la existencia de vulnerabilidades que, aunque no cr√≠ticas, deben ser corregidas para fortalecer la postura de seguridad.")
    elif risk_score >= 5:
        risk_level = "Bajo"
        executive_summary_text.append(f"El nivel de riesgo global para {domain} es BAJO, con hallazgos menores que no representan un riesgo inminente pero que se recomienda revisar.")
    else:
        risk_level = "Informacional"
        executive_summary_text.append(f"El nivel de riesgo global para {domain} es INFORMACIONAL, lo que indica que no se encontraron vulnerabilidades significativas, pero se ofrecen recomendaciones para optimizar la seguridad.")

    # Resumen de hallazgos clave para el resumen ejecutivo
    if nuclei_severity_counts["critical"] > 0:
        executive_summary_text.append(f"Se identificaron {nuclei_severity_counts['critical']} vulnerabilidades CR√çTICAS con Nuclei.")
    if nuclei_severity_counts["high"] > 0:
        executive_summary_text.append(f"Se identificaron {nuclei_severity_counts['high']} vulnerabilidades ALTAS con Nuclei.")

    if leaks_data:
        executive_summary_text.append(f"Se encontraron credenciales de correo electr√≥nico asociadas con brechas de seguridad conocidas, lo que representa un riesgo de compromiso de cuentas.")
    if typosquats_data:
        executive_summary_text.append(f"Se identificaron dominios de typosquatting que podr√≠an ser utilizados en ataques de phishing.")
    if cves_data:
        executive_summary_text.append(f"Se detectaron CVEs en tecnolog√≠as utilizadas, lo que indica la presencia de vulnerabilidades conocidas.")
    if any(nmap_item.get('state') == 'open' for nmap_item in nmap_data):
        executive_summary_text.append(f"Se encontraron puertos abiertos que deben ser revisados para asegurar que solo los servicios necesarios est√©n expuestos.")
    if security_config_data:
        executive_summary_text.append(f"Se identificaron hallazgos en la configuraci√≥n de seguridad que requieren ajustes para cumplir con las mejores pr√°cticas.")
    if dir_brute_data:
        executive_summary_text.append(f"Se encontraron {len(dir_brute_data)} directorios o archivos expuestos mediante fuerza bruta ligera.")

    if cisa_kev_data:
        executive_summary_text.append(f"Se identificaron {len(cisa_kev_data)} vulnerabilidades de CISA KEV relevantes.")

    if greynoise_data and greynoise_data.get("classification") == "malicious":
        executive_summary_text.append(f"La IP {domain} fue clasificada como MALICIOSA por GreyNoise.")

    if any(nmap_item.get("threat_intel") for nmap_item in nmap_data):
        recommendations.append({
            "title": "Inteligencia de Amenazas Detectada",
            "description": "Se ha detectado inteligencia de amenazas asociada a una o m√°s IPs escaneadas. Esto puede indicar que las IPs han sido reportadas por actividades maliciosas.",
            "solution": "Investigar las IPs reportadas en las plataformas de inteligencia de amenazas (ej. AlienVault OTX, AbuseIPDB) para entender la naturaleza de las actividades maliciosas y tomar las acciones correctivas necesarias, como el bloqueo de IPs o la revisi√≥n de la seguridad de los sistemas asociados."
        })

    if any(nmap_item.get("threat_intel") for nmap_item in nmap_data):
        executive_summary_text.append(f"Se encontr√≥ inteligencia de amenazas asociada a las IPs escaneadas.")

    # Recomendaciones para vulnerabilidades de Nuclei
    for vuln in nuclei_data:
        severity = vuln.get("info", {}).get("severity", "").lower()
        if severity in ["critical", "high", "medium"]:
            recommendations.append({
                "title": f"Vulnerabilidad {severity.capitalize()}: {vuln.get('info', {}).get('name', 'N/A')}",
                "description": f"Se detect√≥ una vulnerabilidad de {severity} en {vuln.get('host', 'N/A')}. Detalles: {vuln.get('info', {}).get('description', 'N/A')}",
                "solution": f"Referencia: {vuln.get('info', {}).get('reference', 'N/A')}. Aplicar parches, actualizar software o reconfigurar seg√∫n la vulnerabilidad espec√≠fica. Priorizar la mitigaci√≥n de vulnerabilidades {severity} para reducir el riesgo."
            })



    # Recomendaciones para credenciales filtradas
    if leaks_data:
        recommendations.append({
            "title": "Gesti√≥n de Credenciales Comprometidas",
            "description": "Se encontraron direcciones de correo electr√≥nico asociadas con brechas de seguridad conocidas en Have I Been Pwned.",
            "solution": "Cambiar inmediatamente las contrase√±as de todas las cuentas afectadas, especialmente si se reutilizan. Implementar una pol√≠tica de contrase√±as robusta que exija complejidad y rotaci√≥n peri√≥dica. Habilitar la autenticaci√≥n de dos factores (2FA) en todos los servicios que lo permitan para a√±adir una capa extra de seguridad."
        })

    # Recomendaciones para typosquatting
    if typosquats_data:
        recommendations.append({
            "title": "Mitigaci√≥n de Riesgos de Typosquatting",
            "description": "Se identificaron dominios similares al dominio objetivo que podr√≠an ser utilizados para ataques de phishing o suplantaci√≥n de identidad.",
            "solution": "Considerar el registro proactivo de las variantes de dominio m√°s cr√≠ticas para proteger la marca. Educar a los empleados y usuarios sobre los riesgos de phishing y la importancia de verificar cuidadosamente las URLs antes de hacer clic o introducir credenciales."
        })

    # Recomendaciones para CVEs
    # Manejar tanto la estructura antigua como la nueva
    cve_findings = cves_data
    if isinstance(cves_data, dict) and 'findings' in cves_data:
        cve_findings = cves_data['findings']
    
    for cve in cve_findings:
        # Validar que cve sea un diccionario antes de usar .get()
        if not isinstance(cve, dict):
            continue
            
        cve_id = cve.get('id') or cve.get('cve_id', 'N/A')
        technology = cve.get('technology') or cve.get('affected_technology', 'N/A')
        recommendations.append({
            "title": f"Parchear CVE: {cve_id}",
            "description": f"Se detect√≥ una vulnerabilidad conocida ({cve_id}) en {technology}.",
            "solution": "Consultar las bases de datos de vulnerabilidades (NVD, CVE Mitre) para obtener informaci√≥n detallada sobre el parche o la mitigaci√≥n espec√≠fica. Actualizar el software o componente afectado a la √∫ltima versi√≥n estable que contenga la correcci√≥n para el CVE."
        })

    # Recomendaciones para Nmap (ejemplo: puertos abiertos inesperados)
    if nmap_data:
        open_ports = [item for item in nmap_data if item.get('state') == 'open']
        if open_ports:
            recommendations.append({
                "title": "Revisi√≥n y Cierre de Puertos Abiertos",
                "description": f"Se detectaron {len(open_ports)} puertos abiertos en los hosts escaneados. Algunos de estos puertos podr√≠an no ser necesarios o estar mal configurados, exponiendo servicios innecesarios.",
                "solution": "Realizar una auditor√≠a de todos los puertos abiertos para determinar su necesidad. Cerrar o filtrar mediante firewall cualquier puerto que no sea estrictamente necesario para la operaci√≥n del servicio. Asegurarse de que los servicios expuestos est√©n correctamente configurados, parcheados y protegidos con autenticaci√≥n fuerte."
            })

    # Recomendaciones para configuraci√≥n de seguridad
    if security_config_data:
        recommendations.append({
            "title": "Optimizaci√≥n de la Configuraci√≥n de Seguridad",
            "description": "Se identificaron posibles malas configuraciones de seguridad en el servidor web o las aplicaciones.",
            "solution": "Revisar y aplicar las mejores pr√°cticas de seguridad para la configuraci√≥n del servidor web (e.g., Apache, Nginx) y las aplicaciones. Esto incluye la eliminaci√≥n de cabeceras informativas (Server, X-Powered-By), la configuraci√≥n de pol√≠ticas de seguridad de contenido (CSP), la implementaci√≥n de HSTS, y la protecci√≥n contra ataques comunes como XSS y CSRF."
        })

    # Recomendaciones para fuerza bruta de directorios
    if dir_brute_data:
        recommendations.append({
            "title": "Proteger Directorios y Archivos Expuestos",
            "description": f"Se detectaron {len(dir_brute_data)} directorios o archivos accesibles p√∫blicamente que podr√≠an contener informaci√≥n sensible o ser puntos de entrada para ataques.",
            "solution": "Revisar los directorios y archivos expuestos para asegurar que no contengan informaci√≥n sensible. Implementar controles de acceso adecuados (autenticaci√≥n, autorizaci√≥n) para proteger recursos cr√≠ticos. Eliminar archivos innecesarios o de respaldo que puedan haber quedado expuestos. Considerar el uso de un WAF (Web Application Firewall) para mitigar ataques de fuerza bruta y enumeraci√≥n de directorios." 
        })

    # Recomendaciones para CISA KEV
    if cisa_kev_data:
        for vul in cisa_kev_data:
            recommendations.append({
                "title": f"Vulnerabilidad CISA KEV: {vul.get('cveID', 'N/A')}",
                "description": f"Se detect√≥ una vulnerabilidad conocida y explotada ({vul.get('cveID', 'N/A')}) en {vul.get('vendorProduct', 'N/A')}. Fecha l√≠mite para parchear: {vul.get('dueDate', 'N/A')}.",
                "solution": "Priorizar la aplicaci√≥n de parches o mitigaciones para esta vulnerabilidad, ya que se sabe que est√° siendo explotada activamente. Consultar los avisos de CISA para obtener orientaci√≥n espec√≠fica sobre la remediaci√≥n."
            })

    # Recomendaciones para GreyNoise
    if greynoise_data and greynoise_data.get("classification") == "malicious":
        recommendations.append({
            "title": "IP Maliciosa Detectada por GreyNoise",
            "description": f"La direcci√≥n IP {domain} ha sido clasificada como maliciosa por GreyNoise, indicando actividad de escaneo o ataque.",
            "solution": "Investigar la actividad de red asociada con esta IP. Considerar bloquear el tr√°fico desde esta IP en el firewall. Implementar sistemas de detecci√≥n de intrusiones (IDS/IPS) para identificar y mitigar ataques de IPs maliciosas conocidas."
        })

    return {
        "recommendations": recommendations,
        "risk_level": risk_level,
        "risk_score": risk_score,
        "executive_summary": " ".join(executive_summary_text),
        "nuclei_severity_counts": nuclei_severity_counts,

}

MITRE_TACTICS = [
    "Reconnaissance", "Resource Development", "Initial Access", "Execution",
    "Persistence", "Privilege Escalation", "Defense Evasion", "Credential Access",
    "Discovery", "Lateral Movement", "Collection", "Command and Control",
    "Exfiltration", "Impact"
]

def generate_mitre_heatmap_data(
    cves_data: List[Dict[str, Any]],
    security_config_data: List[Dict[str, Any]],
    mitre_mapping: Dict[str, str]
) -> Dict[str, Dict[str, bool]]:
    """Genera los datos para el mini-heatmap de MITRE ATT&CK."""
    heatmap_data = {tactic: {tech: False for tech in mitre_mapping.values()} for tactic in MITRE_TACTICS}

    # Mapear CVEs a t√©cnicas MITRE
    # Manejar tanto la estructura antigua como la nueva
    cve_findings = cves_data
    if isinstance(cves_data, dict) and 'findings' in cves_data:
        cve_findings = cves_data['findings']
    
    for cve in cve_findings:
        # Validar que cve sea un diccionario antes de usar .get()
        if not isinstance(cve, dict):
            continue
            
        cve_id = cve.get("id") or cve.get("cve_id")
        if cve_id and cve_id in mitre_mapping:
            technique_id = mitre_mapping[cve_id]
            # Asumimos que cada t√©cnica pertenece a una t√°ctica, esto es una simplificaci√≥n
            # En un caso real, se necesitar√≠a un mapeo m√°s completo de t√©cnicas a t√°cticas.
            # Por ahora, solo marcamos la t√©cnica como presente si la t√°ctica es gen√©rica.
            for tactic in MITRE_TACTICS:
                # Esto es un placeholder. La l√≥gica real deber√≠a mapear T-ID a T√°ctica.
                # Para este ejemplo, simplemente marcamos la t√©cnica si existe en el mapeo.
                if technique_id in mitre_mapping.values(): # Check if the technique ID is one of the mapped ones
                    # This part needs refinement to correctly map technique to tactic
                    # For now, we'll just mark it as present in a generic way
                    # A more robust solution would involve a full MITRE ATT&CK dataset
                    pass # We'll handle the actual marking in the template or with a more complex data structure

    # Mapear hallazgos de configuraci√≥n de seguridad a t√©cnicas MITRE
    for config_finding in security_config_data:
        finding_name = config_finding.get("name")
        if finding_name and finding_name in mitre_mapping:
            technique_id = mitre_mapping[finding_name]
            for tactic in MITRE_TACTICS:
                # Similar al caso de CVEs, se necesita un mapeo m√°s preciso
                pass

    # Para el prop√≥sito de este mini-heatmap, vamos a simplificar el mapeo
    # y solo indicaremos si una t√©cnica mapeada est√° presente.
    # La estructura heatmap_data deber√≠a ser {tactic: {technique_id: bool_present}}
    # Para simplificar, vamos a crear una lista de t√©cnicas detectadas.
    detected_techniques = set()
    # Manejar tanto la estructura antigua como la nueva para CVEs
    cve_findings = cves_data
    if isinstance(cves_data, dict) and 'findings' in cves_data:
        cve_findings = cves_data['findings']
    
    for cve in cve_findings:
        # Validar que cve sea un diccionario antes de usar .get()
        if not isinstance(cve, dict):
            continue
            
        cve_id = cve.get("id") or cve.get("cve_id")
        if cve_id and cve_id in mitre_mapping:
            detected_techniques.add(mitre_mapping[cve_id])

    for config_finding in security_config_data:
        finding_name = config_finding.get("name")
        if finding_name and finding_name in mitre_mapping:
            detected_techniques.add(mitre_mapping[finding_name])

    # Rellenar heatmap_data con las t√©cnicas detectadas
    # Esto es una simplificaci√≥n. En un caso real, cada t√©cnica tiene una o m√°s t√°cticas asociadas.
    # Para el mini-heatmap, podemos simplemente mostrar las t√©cnicas detectadas bajo una t√°ctica gen√©rica
    # o si tenemos un mapeo de T-ID a T√°ctica, usarlo.
    # Dado que el YAML solo mapea CVE/Finding a T-ID, necesitamos un mapeo de T-ID a T√°ctica.
    # Por simplicidad, vamos a crear una estructura que solo muestre las t√©cnicas detectadas.
    # La idea es que el PDF muestre una tabla con T√°cticas y debajo las T√©cnicas.
    # Para el mini-heatmap, podemos tener una lista de t√©cnicas y marcarlas.

    # Vamos a crear una estructura m√°s simple para el heatmap:
    # {tactic: [list_of_techniques_under_this_tactic_that_are_detected]}
    # Esto requiere un mapeo de T-ID a T√°ctica, que no est√° en el YAML.
    # Para el prop√≥sito de este ejercicio, vamos a asumir un mapeo simple o mostrar solo las t√©cnicas.

    # Para el mini-heatmap, vamos a crear una lista de todas las t√©cnicas posibles
    # y marcar las que se han detectado.
    # Esto es m√°s f√°cil de renderizar en una tabla simple.

    # Vamos a usar una estructura que mapee T-ID a su nombre y si est√° presente.
    # Esto es una simplificaci√≥n extrema para el mini-heatmap.
    # La clave es que el YAML solo da T-ID, no el nombre de la t√©cnica ni la t√°ctica.
    # Necesitamos una fuente de datos de MITRE ATT&CK completa para eso.

    # Para el prop√≥sito de este ejercicio, vamos a generar una lista de t√©cnicas detectadas
    # y el PDF las listar√° o las marcar√° en una tabla predefinida.

    # La estructura del heatmap_data deber√≠a ser: {tactic: {technique_id: is_detected}}
    # Para esto, necesitamos saber a qu√© t√°ctica pertenece cada technique_id.
    # Como no tenemos un mapeo completo de MITRE, vamos a simularlo.

    # Mapeo simplificado de T-ID a T√°ctica (ejemplo, no exhaustivo)
    technique_to_tactic = {
        "T1190": "Initial Access", # Exploit Public-Facing Application
        "T1059": "Execution"       # Command and Scripting Interpreter
    }

    final_heatmap_data = {tactic: {} for tactic in MITRE_TACTICS}

    for tech_id in detected_techniques:
        tactic = technique_to_tactic.get(tech_id, "Other") # Asignar a 'Other' si no est√° mapeado
        if tactic not in final_heatmap_data:
            final_heatmap_data[tactic] = {}
        final_heatmap_data[tactic][tech_id] = True

    return final_heatmap_data


def build_pdf(
    domain: str,
    recipient_email: str,
    tmp_dir: Path,
    httpx_file: Path,
    nuclei_file: Path,
    leaks_file: Path,
    typosquats_file: Path,
    dir_brute_file: Path,
    
    cves_file: Path,
    nmap_file: Path,
    security_config_file: Path,
    cisa_kev_file: Path,
    greynoise_file: Path,
    premium_adaptive_file: Path = None,
    ml_file: Path = None,
) -> Path:
    """Genera un informe PDF con los resultados del escaneo.
    
    Args:
        domain: Dominio objetivo
        tmp_dir: Directorio temporal para almacenar resultados
        httpx_file: Archivo JSON con hosts activos
        nuclei_file: Archivo JSON con vulnerabilidades

        leaks_file: Archivo JSON con credenciales filtradas
        typosquats_file: Archivo JSON con dominios typosquatting
        
    Returns:
        Path al archivo PDF generado
        
    Raises:
        ReportError: Si falla la generaci√≥n del informe
    """
    log.info("üìä Iniciando generaci√≥n de informe para %s", domain)
    
    output_pdf = tmp_dir / f"report_{domain}.pdf"
    output_html = tmp_dir / f"report_{domain}.html"
    
    # Cargar datos
    try:
        # Helper function to load JSON data or return empty list if file is None or doesn't exist
        def load_json_or_empty(file_path) -> List[Dict[str, Any]]:
            # Handle case where file_path is already a dict (like premium_adaptive_file)
            if isinstance(file_path, dict):
                return [file_path]  # Wrap dict in list
            
            if file_path and hasattr(file_path, 'exists') and file_path.exists():
                with open(file_path, "r") as f:
                    data = json.load(f)
                    # Handle different JSON structures based on filename
                    filename = file_path.name.lower()
                    
                    if 'dir_brute' in filename or 'directories' in filename:
                        if isinstance(data, dict):
                            return data.get('directories', data.get('results', []))
                        return data if isinstance(data, list) else []
                    
                    elif 'security_config' in filename or 'security' in filename:
                        if isinstance(data, dict):
                            return data.get('results', data.get('findings', []))
                        return data if isinstance(data, list) else []
                    
                    elif 'cve' in filename:
                        if isinstance(data, dict):
                            return data.get('cves', data.get('vulnerabilities', []))
                        return data if isinstance(data, list) else []
                    
                    elif 'cisa' in filename or 'kev' in filename:
                        if isinstance(data, dict):
                            return data.get('vulnerabilities', data.get('kev_matches', []))
                        return data if isinstance(data, list) else []
                    
                    elif 'leak' in filename or 'breach' in filename:
                        if isinstance(data, dict):
                            return data.get('breaches', data.get('leaks', []))
                        return data if isinstance(data, list) else []
                    
                    elif 'typo' in filename:
                        if isinstance(data, dict):
                            return data.get('typosquats', data.get('domains', []))
                        return data if isinstance(data, list) else []
                    
                    elif 'greynoise' in filename:
                        # GreyNoise returns a dict with IP info, convert to list format
                        if isinstance(data, dict) and data:
                            return [data]  # Wrap single dict in list
                        return data if isinstance(data, list) else []
                    
                    elif 'premium_adaptive' in filename:
                        if isinstance(data, dict):
                            return data.get('findings', data.get('vulnerabilities', data.get('recommendations', [])))
                        return data if isinstance(data, list) else []
                    
                    else:
                        # Default behavior for other files (like nmap, httpx)
                        return data if isinstance(data, list) else []
            return []
        
        # Helper function specifically for nuclei data that handles new structure
        def load_nuclei_data(file_path) -> List[Dict[str, Any]]:
            # Handle case where file_path is already a dict
            if isinstance(file_path, dict):
                if 'findings' in file_path:
                    return file_path['findings']
                elif isinstance(file_path, list):
                    return file_path
                else:
                    return [file_path]
            
            if file_path and hasattr(file_path, 'exists') and file_path.exists():
                with open(file_path, "r") as f:
                    data = json.load(f)
                    # Handle new structure with 'findings' key
                    if isinstance(data, dict) and 'findings' in data:
                        return data['findings']
                    # Handle old structure (direct list)
                    elif isinstance(data, list):
                        return data
                    else:
                        return []
            return []

        httpx_data = load_json_or_empty(httpx_file)
        nuclei_data = load_nuclei_data(nuclei_file)
        leaks_data = load_json_or_empty(leaks_file)
        typosquats_data = load_json_or_empty(typosquats_file)
        cves_data = load_json_or_empty(cves_file)
        nmap_data = load_json_or_empty(nmap_file)
        security_config_data = load_json_or_empty(security_config_file)
        dir_brute_data = load_json_or_empty(dir_brute_file)
        
        cisa_kev_data = load_json_or_empty(cisa_kev_file)
        greynoise_data = load_json_or_empty(greynoise_file)
        premium_adaptive_data = load_json_or_empty(premium_adaptive_file)
        
        # Cargar datos ML
        ml_data = None
        if ml_file and ml_file.exists():
            try:
                with open(ml_file, "r") as f:
                    ml_data = json.load(f)
                log.info(f"üìä Datos ML cargados desde: {ml_file}")
            except (json.JSONDecodeError, IOError) as e:
                log.warning(f"Error al cargar datos ML desde {ml_file}: {e}")
                ml_data = None

        # Subdominios (recon)
        # The subdomains file is a simple list of subdomains, one per line.
        # We need to read it and count the lines.
        subdomains_file = tmp_dir / "subdomains.txt"
        subdomains_data = []
        if subdomains_file.exists():
            with open(subdomains_file, "r") as f:
                subdomains_data = [line.strip() for line in f if line.strip()]
    except json.JSONDecodeError as e:
        raise ReportError(f"Error al cargar datos JSON de un archivo: {str(e)}") from e
    except FileNotFoundError as e:
        raise ReportError(f"Archivo no encontrado durante la carga de datos: {str(e)}") from e
    except Exception as e:
        raise ReportError(f"Error inesperado durante la carga de datos: {str(e)}") from e
        raise ReportError(f"Error al cargar datos: {str(e)}") from e

    # Generar recomendaciones y resumen ejecutivo
    report_data = get_recommendations(
        nuclei_data,

        leaks_data,
        typosquats_data,
        cves_data,
        nmap_data,
        security_config_data,
        dir_brute_data,
        cisa_kev_data,
        greynoise_data,
        domain
    )
    recommendations = report_data["recommendations"]
    risk_level = report_data["risk_level"]
    risk_score = report_data["risk_score"]
    executive_summary_text = report_data["executive_summary"]
    nuclei_severity_counts = report_data["nuclei_severity_counts"]


    # Renderizar plantilla HTML
    try:
        template = get_template()
        if template is None:
            raise ReportError("La plantilla de informe no se pudo cargar.")
        
        html_content = template.render(
            domain=domain,
            date=datetime.date.today().strftime("%d/%m/%Y"),
            httpx_data=httpx_data,
            nuclei_data=nuclei_data,
            leaks_data=leaks_data,
            typosquats_data=typosquats_data,
            cves_data=cves_data,
            nmap_data=nmap_data,
            security_config_data=security_config_data,
            dir_brute_data=dir_brute_data,
            premium_adaptive_data=premium_adaptive_data,
            ml_data=ml_data,
            recommendations=recommendations,
            risk_level=risk_level,
            executive_summary_text=executive_summary_text,
            subdomains_count=len(subdomains_data) if subdomains_data else 0,
            httpx_count=len(httpx_data) if httpx_data else 0,
            nuclei_critical_high_count=sum(1 for v in nuclei_data if v.get("info", {}).get("severity", "").lower() in ["critical", "high"]),
            leaks_count=len(leaks_data) if leaks_data else 0,
            typosquats_count=len(typosquats_data) if typosquats_data else 0,
            cves_count=len(cves_data) if cves_data else 0,
            nmap_open_ports_count=sum(1 for nmap_item in nmap_data if nmap_item.get('state') == 'open') if nmap_data else 0,
            security_config_count=len(security_config_data) if security_config_data else 0,
            dir_brute_count=len(dir_brute_data) if dir_brute_data else 0,
            premium_adaptive_count=len(premium_adaptive_data) if premium_adaptive_data else 0,
            risk_score=risk_score,
            nuclei_severity_counts=nuclei_severity_counts,
            mitre_heatmap_data=generate_mitre_heatmap_data(cves_data, security_config_data, mitre_mapping),
            mitre_tactics=MITRE_TACTICS
        )
    except Exception as e:
        raise ReportError(f"Error al renderizar la plantilla HTML: {str(e)}") from e

    with open(output_html, "w", encoding="utf-8") as f:
        f.write(html_content)

    # Generar PDF con WeasyPrint
    try:
        from weasyprint import HTML
        HTML(string=html_content).write_pdf(str(output_pdf))
        log.info("PDF generado exitosamente con WeasyPrint en %s", output_pdf)
    except Exception as e:
        raise ReportError(f"Error al generar el PDF con WeasyPrint: {str(e)}") from e

    log.debug("build_pdf returning: %s", output_pdf)
    return output_pdf





def encode_pdf_for_email(pdf_path: Path) -> str:
    """Codifica un PDF en base64 para adjuntarlo a un email.
    
    Args:
        pdf_path: Ruta al archivo PDF
        
    Returns:
        String con el PDF codificado en base64
    """
    with open(pdf_path, "rb") as f:
        return base64.b64encode(f.read()).decode("utf-8")

def send_notification(job_id: str, status_message: str, status_type: str, pdf_path: Optional[Path], recipient_email: str, subc: int, vulc: int, domain: str, cisa_kev_vulnerabilities: int = 0, greynoise_malicious_ips: int = 0,  threat_intel_hits: int = 0):
    """Env√≠a una notificaci√≥n por email con el informe adjunto.
    
    Args:
        job_id: ID del trabajo de escaneo.
        status_message: Mensaje de estado del escaneo.
        status_type: Tipo de estado (e.g., "success", "failed").
        pdf_path: Ruta al archivo PDF.
        recipient_email: Email del destinatario.
        subc: N√∫mero de subdominios encontrados.
        vulc: N√∫mero de vulnerabilidades encontradas.
        
    Returns:
        True si se envi√≥ correctamente, False en caso contrario.
    """
    log.info("üìß Enviando notificaci√≥n a %s para el dominio %s (trabajo %s)", recipient_email, domain, job_id)
    
    # Obtener clave API de MailerSend
    api_key = os.getenv("MAILERSEND_API_KEY")
    if not api_key:
        log.error("No se ha configurado la clave API de MailerSend")
        return False
    
    try:
        # Importar requests si no est√° disponible en el √°mbito global
        import requests
        from pentest.http_utils import get_session
        from pentest.config import MAIL_SENDER_EMAIL, MAIL_SENDER_NAME
        
        # Asunto del correo
        subject = f"Pentest Express - Escaneo {status_type.capitalize()}: {job_id}"

        # Cuerpo del correo
        body = f"Hola,\n\nEl escaneo para el trabajo {job_id} ha finalizado con estado: {status_message}.\n\nDetalles:\n- Subdominios encontrados: {subc}\n- Vulnerabilidades encontradas: {vulc}\n\n- Hits de inteligencia de amenazas: {threat_intel_hits}\n\nSaludos,\nEl equipo de Pentest Express"

        # Datos para la API de MailerSend
        data = {
            "from": {"email": MAIL_SENDER_EMAIL, "name": MAIL_SENDER_NAME},
            "to": [{"email": recipient_email}],
            "subject": subject,
            "html": f"<p>{body.replace(chr(10), '<br>')}</p>"
        }

        # Adjuntar PDF si est√° disponible
        if pdf_path and pdf_path.exists():
            pdf_data = base64.b64encode(pdf_path.read_bytes()).decode("utf-8")
            data["attachments"] = [
                {
                    "filename": pdf_path.name,
                    "content": pdf_data
                }
            ]
            body += "\n\nAdjunto encontrar√°s el informe completo."

        # Enviar correo
        session = get_session()
        headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
        response = session.post("https://api.mailersend.com/v1/email", headers=headers, json=data)
        response.raise_for_status() # Lanza una excepci√≥n para c√≥digos de estado HTTP err√≥neos

        log.info("‚úÖ Notificaci√≥n enviada correctamente para el dominio %s", domain)
        return True

    except requests.exceptions.RequestException as e:
        log.error("Error al enviar notificaci√≥n para el dominio %s: %s", domain, e)
        return False
    except Exception as e:
        log.error("Error inesperado al enviar notificaci√≥n para el dominio %s: %s", domain, e)
        return False