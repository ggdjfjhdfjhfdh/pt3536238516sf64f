#!/usr/bin/env python3
"""
API Endpoints para el Sistema de IA/ML Predictivo
Proporciona endpoints REST para acceder a las funcionalidades de ML
"""

import json
import logging
import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
from dataclasses import asdict
from fastapi import APIRouter, HTTPException, Depends, BackgroundTasks, Query
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from pydantic import BaseModel, Field
import redis

try:
    from .ml_integration import MLIntegrationManager, enhance_scan_with_ml
    from .ml_predictive_analysis import SecurityEvent, PredictionResult
    from .config.ml_config import ML_CONFIG
except ImportError as e:
    logging.warning(f"Importación ML no disponible: {e}")
    MLIntegrationManager = None
    enhance_scan_with_ml = None
    SecurityEvent = None
    PredictionResult = None
    ML_CONFIG = None

# Configuración de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Configuración de seguridad
security = HTTPBearer()

# Modelos Pydantic para la API
class SecurityEventRequest(BaseModel):
    """Modelo para solicitud de evento de seguridad"""
    timestamp: Optional[datetime] = Field(default_factory=datetime.now)
    event_type: str = Field(..., description="Tipo de evento")
    severity: str = Field(..., description="Severidad del evento")
    source_ip: str = Field(..., description="IP de origen")
    target_domain: str = Field(..., description="Dominio objetivo")
    vulnerability_count: int = Field(0, description="Número de vulnerabilidades")
    threat_score: float = Field(0.0, description="Puntuación de amenaza")
    technologies: List[str] = Field(default_factory=list, description="Tecnologías detectadas")
    ports_open: List[int] = Field(default_factory=list, description="Puertos abiertos")
    response_time: float = Field(1.0, description="Tiempo de respuesta")
    status_code: int = Field(200, description="Código de estado HTTP")
    payload_size: int = Field(0, description="Tamaño del payload")
    user_agent: str = Field("Unknown", description="User Agent")
    country: str = Field("Unknown", description="País de origen")

class ScanEnhancementRequest(BaseModel):
    """Modelo para solicitud de mejora de escaneo"""
    scan_result: Dict[str, Any] = Field(..., description="Resultado del escaneo")
    target_domain: str = Field(..., description="Dominio objetivo")
    enable_caching: bool = Field(True, description="Habilitar cache")

class BatchPredictionRequest(BaseModel):
    """Modelo para predicciones en lote"""
    events: List[SecurityEventRequest] = Field(..., description="Lista de eventos")
    include_patterns: bool = Field(True, description="Incluir análisis de patrones")

class TrainingRequest(BaseModel):
    """Modelo para solicitud de entrenamiento"""
    scan_results: List[Dict[str, Any]] = Field(..., description="Resultados de escaneo")
    target_domains: List[str] = Field(..., description="Dominios objetivo")
    model_type: str = Field("both", description="Tipo de modelo a entrenar")

class PredictionResponse(BaseModel):
    """Modelo para respuesta de predicción"""
    prediction: str
    confidence: float
    risk_score: float
    anomaly_score: float
    recommendations: List[str]
    features_importance: Dict[str, float]
    processing_time: float
    timestamp: datetime

class EnhancedScanResponse(BaseModel):
    """Modelo para respuesta de escaneo mejorado"""
    original_result: Dict[str, Any]
    ml_prediction: Optional[PredictionResponse]
    threat_patterns: List[Dict[str, Any]]
    risk_assessment: Dict[str, Any]
    recommendations: List[str]
    confidence_score: float
    processing_time: float
    timestamp: datetime

class MLStatsResponse(BaseModel):
    """Modelo para estadísticas del sistema ML"""
    total_scans: int
    ml_enhanced_scans: int
    cache_hits: int
    cache_misses: int
    errors: int
    ml_available: bool
    cache_enabled: bool
    ml_enhancement_rate: float
    uptime: str

# Router para endpoints ML
ml_router = APIRouter(prefix="/api/v1/ml", tags=["Machine Learning"])

# Instancia global del gestor ML
ml_manager = None

def get_ml_manager() -> MLIntegrationManager:
    """Obtiene instancia del gestor ML"""
    global ml_manager
    if ml_manager is None and MLIntegrationManager:
        ml_manager = MLIntegrationManager()
    return ml_manager

def verify_api_key(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """Verifica la clave API"""
    # En producción, verificar contra base de datos o servicio de autenticación
    valid_keys = ["ml-api-key-2024", "admin-key"]  # Ejemplo
    
    if credentials.credentials not in valid_keys:
        raise HTTPException(
            status_code=401,
            detail="Clave API inválida"
        )
    return credentials.credentials

@ml_router.get("/health", summary="Estado del sistema ML")
async def ml_health_check():
    """Verifica el estado del sistema ML"""
    try:
        manager = get_ml_manager()
        if not manager:
            return {
                "status": "unavailable",
                "message": "Sistema ML no disponible",
                "timestamp": datetime.now().isoformat()
            }
        
        is_available = manager.is_ml_available()
        stats = manager.get_processing_stats()
        
        return {
            "status": "healthy" if is_available else "degraded",
            "ml_available": is_available,
            "cache_enabled": manager.enable_cache,
            "models_loaded": is_available,
            "stats": stats,
            "timestamp": datetime.now().isoformat()
        }
    
    except Exception as e:
        logger.error(f"Error en health check: {e}")
        return {
            "status": "error",
            "message": str(e),
            "timestamp": datetime.now().isoformat()
        }

@ml_router.post("/predict", response_model=PredictionResponse, summary="Predicción de amenaza")
async def predict_threat(
    event_request: SecurityEventRequest,
    api_key: str = Depends(verify_api_key)
):
    """Realiza predicción de amenaza para un evento de seguridad"""
    try:
        manager = get_ml_manager()
        if not manager or not manager.is_ml_available():
            raise HTTPException(
                status_code=503,
                detail="Sistema ML no disponible"
            )
        
        # Convertir request a SecurityEvent
        if SecurityEvent:
            event = SecurityEvent(
                timestamp=event_request.timestamp,
                event_type=event_request.event_type,
                severity=event_request.severity,
                source_ip=event_request.source_ip,
                target_domain=event_request.target_domain,
                vulnerability_count=event_request.vulnerability_count,
                threat_score=event_request.threat_score,
                technologies=event_request.technologies,
                ports_open=event_request.ports_open,
                response_time=event_request.response_time,
                status_code=event_request.status_code,
                payload_size=event_request.payload_size,
                user_agent=event_request.user_agent,
                country=event_request.country
            )
        else:
            raise HTTPException(
                status_code=503,
                detail="Módulo SecurityEvent no disponible"
            )
        
        # Realizar predicción
        start_time = datetime.now()
        prediction = manager.ml_analyzer.predict_threat(event)
        processing_time = (datetime.now() - start_time).total_seconds()
        
        return PredictionResponse(
            prediction=prediction.prediction,
            confidence=prediction.confidence,
            risk_score=prediction.risk_score,
            anomaly_score=prediction.anomaly_score,
            recommendations=prediction.recommendations,
            features_importance=prediction.features_importance,
            processing_time=processing_time,
            timestamp=prediction.timestamp
        )
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error en predicción: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Error interno: {str(e)}"
        )

@ml_router.post("/enhance-scan", response_model=EnhancedScanResponse, summary="Mejora de escaneo con ML")
async def enhance_scan(
    enhancement_request: ScanEnhancementRequest,
    api_key: str = Depends(verify_api_key)
):
    """Mejora resultado de escaneo con análisis ML"""
    try:
        manager = get_ml_manager()
        if not manager:
            raise HTTPException(
                status_code=503,
                detail="Sistema ML no disponible"
            )
        
        # Configurar cache si se especifica
        original_cache_setting = manager.enable_cache
        manager.enable_cache = enhancement_request.enable_caching
        
        try:
            # Realizar mejora del escaneo
            enhanced_result = manager.enhance_scan_result(
                enhancement_request.scan_result,
                enhancement_request.target_domain
            )
            
            # Convertir predicción ML a respuesta
            ml_prediction_response = None
            if enhanced_result.ml_prediction:
                ml_prediction_response = PredictionResponse(
                    prediction=enhanced_result.ml_prediction.prediction,
                    confidence=enhanced_result.ml_prediction.confidence,
                    risk_score=enhanced_result.ml_prediction.risk_score,
                    anomaly_score=enhanced_result.ml_prediction.anomaly_score,
                    recommendations=enhanced_result.ml_prediction.recommendations,
                    features_importance=enhanced_result.ml_prediction.features_importance,
                    processing_time=enhanced_result.processing_time,
                    timestamp=enhanced_result.ml_prediction.timestamp
                )
            
            return EnhancedScanResponse(
                original_result=enhanced_result.original_result,
                ml_prediction=ml_prediction_response,
                threat_patterns=[asdict(pattern) for pattern in enhanced_result.threat_patterns],
                risk_assessment=enhanced_result.risk_assessment,
                recommendations=enhanced_result.recommendations,
                confidence_score=enhanced_result.confidence_score,
                processing_time=enhanced_result.processing_time,
                timestamp=enhanced_result.timestamp
            )
        
        finally:
            # Restaurar configuración de cache
            manager.enable_cache = original_cache_setting
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error en mejora de escaneo: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Error interno: {str(e)}"
        )

@ml_router.post("/batch-predict", summary="Predicciones en lote")
async def batch_predict(
    batch_request: BatchPredictionRequest,
    background_tasks: BackgroundTasks,
    api_key: str = Depends(verify_api_key)
):
    """Realiza predicciones en lote para múltiples eventos"""
    try:
        manager = get_ml_manager()
        if not manager or not manager.is_ml_available():
            raise HTTPException(
                status_code=503,
                detail="Sistema ML no disponible"
            )
        
        # Validar límite de lote
        max_batch_size = ML_CONFIG.API_CONFIG['batch_prediction_limit'] if ML_CONFIG else 100
        if len(batch_request.events) > max_batch_size:
            raise HTTPException(
                status_code=400,
                detail=f"Lote demasiado grande. Máximo: {max_batch_size}"
            )
        
        # Procesar eventos en lote
        predictions = []
        start_time = datetime.now()
        
        for event_request in batch_request.events:
            if SecurityEvent:
                event = SecurityEvent(
                    timestamp=event_request.timestamp,
                    event_type=event_request.event_type,
                    severity=event_request.severity,
                    source_ip=event_request.source_ip,
                    target_domain=event_request.target_domain,
                    vulnerability_count=event_request.vulnerability_count,
                    threat_score=event_request.threat_score,
                    technologies=event_request.technologies,
                    ports_open=event_request.ports_open,
                    response_time=event_request.response_time,
                    status_code=event_request.status_code,
                    payload_size=event_request.payload_size,
                    user_agent=event_request.user_agent,
                    country=event_request.country
                )
                
                prediction = manager.ml_analyzer.predict_threat(event)
                predictions.append(asdict(prediction))
        
        processing_time = (datetime.now() - start_time).total_seconds()
        
        # Análisis de patrones si se solicita
        patterns = []
        if batch_request.include_patterns and SecurityEvent:
            events = []
            for event_request in batch_request.events:
                event = SecurityEvent(
                    timestamp=event_request.timestamp,
                    event_type=event_request.event_type,
                    severity=event_request.severity,
                    source_ip=event_request.source_ip,
                    target_domain=event_request.target_domain,
                    vulnerability_count=event_request.vulnerability_count,
                    threat_score=event_request.threat_score,
                    technologies=event_request.technologies,
                    ports_open=event_request.ports_open,
                    response_time=event_request.response_time,
                    status_code=event_request.status_code,
                    payload_size=event_request.payload_size,
                    user_agent=event_request.user_agent,
                    country=event_request.country
                )
                events.append(event)
            
            detected_patterns = manager.ml_analyzer.detect_threat_patterns(events)
            patterns = [asdict(pattern) for pattern in detected_patterns]
        
        return {
            "predictions": predictions,
            "threat_patterns": patterns,
            "batch_size": len(batch_request.events),
            "processing_time": processing_time,
            "timestamp": datetime.now().isoformat()
        }
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error en predicción en lote: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Error interno: {str(e)}"
        )

@ml_router.get("/stats", response_model=MLStatsResponse, summary="Estadísticas del sistema ML")
async def get_ml_stats(api_key: str = Depends(verify_api_key)):
    """Obtiene estadísticas del sistema ML"""
    try:
        manager = get_ml_manager()
        if not manager:
            raise HTTPException(
                status_code=503,
                detail="Sistema ML no disponible"
            )
        
        stats = manager.get_processing_stats()
        
        return MLStatsResponse(
            total_scans=stats['total_scans'],
            ml_enhanced_scans=stats['ml_enhanced_scans'],
            cache_hits=stats['cache_hits'],
            cache_misses=stats['cache_misses'],
            errors=stats['errors'],
            ml_available=stats['ml_available'],
            cache_enabled=stats['cache_enabled'],
            ml_enhancement_rate=stats['ml_enhancement_rate'],
            uptime="N/A"  # Implementar tracking de uptime
        )
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error obteniendo estadísticas: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Error interno: {str(e)}"
        )

@ml_router.post("/train", summary="Entrenar modelos ML")
async def train_models(
    training_request: TrainingRequest,
    background_tasks: BackgroundTasks,
    api_key: str = Depends(verify_api_key)
):
    """Entrena modelos ML con nuevos datos (solo admin)"""
    try:
        # Verificar que es una clave de admin
        if api_key != "admin-key":
            raise HTTPException(
                status_code=403,
                detail="Acceso denegado. Se requiere clave de administrador"
            )
        
        manager = get_ml_manager()
        if not manager:
            raise HTTPException(
                status_code=503,
                detail="Sistema ML no disponible"
            )
        
        # Validar datos de entrenamiento
        if len(training_request.scan_results) != len(training_request.target_domains):
            raise HTTPException(
                status_code=400,
                detail="Número de resultados y dominios debe coincidir"
            )
        
        if len(training_request.scan_results) < 10:
            raise HTTPException(
                status_code=400,
                detail="Se requieren al menos 10 muestras para entrenamiento"
            )
        
        # Ejecutar entrenamiento en background
        background_tasks.add_task(
            manager.train_with_scan_data,
            training_request.scan_results,
            training_request.target_domains
        )
        
        return {
            "message": "Entrenamiento iniciado en segundo plano",
            "samples_count": len(training_request.scan_results),
            "model_type": training_request.model_type,
            "timestamp": datetime.now().isoformat()
        }
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error iniciando entrenamiento: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Error interno: {str(e)}"
        )

@ml_router.get("/config", summary="Configuración del sistema ML")
async def get_ml_config(api_key: str = Depends(verify_api_key)):
    """Obtiene configuración del sistema ML"""
    try:
        if not ML_CONFIG:
            raise HTTPException(
                status_code=503,
                detail="Configuración ML no disponible"
            )
        
        # Retornar configuración pública (sin secretos)
        public_config = {
            "thresholds": ML_CONFIG.THRESHOLDS,
            "feature_columns": ML_CONFIG.FEATURE_COLUMNS,
            "dangerous_ports": ML_CONFIG.DANGEROUS_PORTS,
            "api_config": {
                "rate_limit_per_minute": ML_CONFIG.API_CONFIG['rate_limit_per_minute'],
                "batch_prediction_limit": ML_CONFIG.API_CONFIG['batch_prediction_limit'],
                "prediction_timeout": ML_CONFIG.API_CONFIG['prediction_timeout']
            },
            "cache_config": {
                "cache_ttl_seconds": ML_CONFIG.CACHE['cache_ttl_seconds'],
                "max_cache_size": ML_CONFIG.CACHE['max_cache_size']
            }
        }
        
        return public_config
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error obteniendo configuración: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Error interno: {str(e)}"
        )

@ml_router.delete("/cache", summary="Limpiar cache ML")
async def clear_ml_cache(api_key: str = Depends(verify_api_key)):
    """Limpia el cache del sistema ML"""
    try:
        manager = get_ml_manager()
        if not manager or not manager.redis_client:
            raise HTTPException(
                status_code=503,
                detail="Cache no disponible"
            )
        
        # Limpiar cache de predicciones ML
        cache_pattern = "ml_pred:*"
        keys = manager.redis_client.keys(cache_pattern)
        
        if keys:
            deleted_count = manager.redis_client.delete(*keys)
        else:
            deleted_count = 0
        
        return {
            "message": "Cache limpiado exitosamente",
            "deleted_keys": deleted_count,
            "timestamp": datetime.now().isoformat()
        }
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error limpiando cache: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Error interno: {str(e)}"
        )

# Función para incluir el router en la aplicación principal
def include_ml_routes(app):
    """Incluye las rutas ML en la aplicación FastAPI"""
    if MLIntegrationManager:
        app.include_router(ml_router)
        logger.info("Rutas ML incluidas en la aplicación")
    else:
        logger.warning("Sistema ML no disponible, rutas no incluidas")