#!/usr/bin/env python3
"""
API Endpoints para el Sistema de IA/ML Predictivo
Proporciona endpoints REST para acceder a las funcionalidades de ML
"""

import json
import logging
import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
from dataclasses import asdict
from pathlib import Path
from fastapi import APIRouter, HTTPException, Depends, BackgroundTasks, Query
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from pydantic import BaseModel, Field
import redis
import joblib
import uuid

try:
    from .ml_integration import MLIntegrationManager, enhance_scan_with_ml
    from .ml_predictive_analysis import SecurityEvent, PredictionResult
    from .config.ml_config import ML_CONFIG
except ImportError as e:
    logging.warning(f"Importación ML no disponible: {e}")
    MLIntegrationManager = None
    enhance_scan_with_ml = None
    SecurityEvent = None
    PredictionResult = None
    ML_CONFIG = None

# Configuración de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Configuración de seguridad
security = HTTPBearer()

# Modelos Pydantic para la API
class SecurityEventRequest(BaseModel):
    """Modelo para solicitud de evento de seguridad"""
    timestamp: Optional[datetime] = Field(default_factory=datetime.now)
    event_type: str = Field(..., description="Tipo de evento")
    severity: str = Field(..., description="Severidad del evento")
    source_ip: str = Field(..., description="IP de origen")
    target_domain: str = Field(..., description="Dominio objetivo")
    vulnerability_count: int = Field(0, description="Número de vulnerabilidades")
    threat_score: float = Field(0.0, description="Puntuación de amenaza")
    technologies: List[str] = Field(default_factory=list, description="Tecnologías detectadas")
    ports_open: List[int] = Field(default_factory=list, description="Puertos abiertos")
    response_time: float = Field(1.0, description="Tiempo de respuesta")
    status_code: int = Field(200, description="Código de estado HTTP")
    payload_size: int = Field(0, description="Tamaño del payload")
    user_agent: str = Field("Unknown", description="User Agent")
    country: str = Field("Unknown", description="País de origen")

class ScanEnhancementRequest(BaseModel):
    """Modelo para solicitud de mejora de escaneo"""
    scan_result: Dict[str, Any] = Field(..., description="Resultado del escaneo")
    target_domain: str = Field(..., description="Dominio objetivo")
    enable_caching: bool = Field(True, description="Habilitar cache")

class BatchPredictionRequest(BaseModel):
    """Modelo para predicciones en lote"""
    events: List[SecurityEventRequest] = Field(..., description="Lista de eventos")
    include_patterns: bool = Field(True, description="Incluir análisis de patrones")

class TrainingRequest(BaseModel):
    """Modelo para solicitud de entrenamiento"""
    scan_results: List[Dict[str, Any]] = Field(..., description="Resultados de escaneo")
    target_domains: List[str] = Field(..., description="Dominios objetivo")
    model_type: str = Field("both", description="Tipo de modelo a entrenar")

class OptimizedTrainingRequest(BaseModel):
    """Modelo para solicitud de entrenamiento optimizado"""
    scan_results: List[Dict[str, Any]] = Field(..., description="Resultados de escaneo")
    target_domains: List[str] = Field(..., description="Dominios objetivo")
    augmentation_factor: int = Field(2, description="Factor de augmentación de datos")
    cv_folds: int = Field(5, description="Número de folds para validación cruzada")
    optimize_hyperparams: bool = Field(True, description="Optimizar hiperparámetros")
    feature_selection: bool = Field(True, description="Realizar selección de características")
    ensemble_methods: bool = Field(True, description="Usar métodos de ensemble")
    balance_classes: bool = Field(True, description="Balancear clases automáticamente")
    temporal_validation: bool = Field(False, description="Usar validación temporal")
    min_samples_required: int = Field(100, description="Mínimo de muestras requeridas")

class DataQualityResponse(BaseModel):
    """Respuesta de evaluación de calidad de datos"""
    completeness: float = Field(..., description="Completitud de datos (0-1)")
    consistency: float = Field(..., description="Consistencia de datos (0-1)")
    diversity: float = Field(..., description="Diversidad de datos (0-1)")
    balance: float = Field(..., description="Balance de clases (0-1)")
    temporal_coverage: float = Field(..., description="Cobertura temporal (0-1)")
    overall_score: float = Field(..., description="Puntuación general (0-1)")
    sample_count: int = Field(..., description="Número de muestras")
    malicious_ratio: float = Field(..., description="Ratio de eventos maliciosos")
    recommendations: List[str] = Field(..., description="Recomendaciones de mejora")

class OptimizedTrainingResponse(BaseModel):
    """Respuesta de entrenamiento optimizado"""
    message: str = Field(..., description="Mensaje de estado")
    training_id: str = Field(..., description="ID del entrenamiento")
    samples_count: int = Field(..., description="Número de muestras")
    config_used: Dict[str, Any] = Field(..., description="Configuración utilizada")
    data_quality: DataQualityResponse = Field(..., description="Calidad de datos")
    estimated_duration_minutes: int = Field(..., description="Duración estimada en minutos")
    timestamp: str = Field(..., description="Timestamp de inicio")

class PredictionResponse(BaseModel):
    """Modelo para respuesta de predicción"""
    prediction: str
    confidence: float
    risk_score: float
    anomaly_score: float
    recommendations: List[str]
    features_importance: Dict[str, float]
    processing_time: float
    timestamp: datetime

class EnhancedScanResponse(BaseModel):
    """Modelo para respuesta de escaneo mejorado"""
    original_result: Dict[str, Any]
    ml_prediction: Optional[PredictionResponse]
    threat_patterns: List[Dict[str, Any]]
    risk_assessment: Dict[str, Any]
    recommendations: List[str]
    confidence_score: float
    processing_time: float
    timestamp: datetime

class MLStatsResponse(BaseModel):
    """Modelo para estadísticas del sistema ML"""
    total_scans: int
    ml_enhanced_scans: int
    cache_hits: int
    cache_misses: int
    errors: int
    ml_available: bool
    cache_enabled: bool
    ml_enhancement_rate: float
    uptime: str

# Router para endpoints ML
ml_router = APIRouter(prefix="/api/v1/ml", tags=["Machine Learning"])

# Instancia global del gestor ML
ml_manager = None

def get_ml_manager() -> MLIntegrationManager:
    """Obtiene instancia del gestor ML"""
    global ml_manager
    if ml_manager is None and MLIntegrationManager:
        ml_manager = MLIntegrationManager()
    return ml_manager

def verify_api_key(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """Verifica la clave API"""
    # En producción, verificar contra base de datos o servicio de autenticación
    valid_keys = ["ml-api-key-2024", "admin-key"]  # Ejemplo
    
    if credentials.credentials not in valid_keys:
        raise HTTPException(
            status_code=401,
            detail="Clave API inválida"
        )
    return credentials.credentials

@ml_router.get("/health", summary="Estado del sistema ML")
async def ml_health_check():
    """Verifica el estado del sistema ML"""
    try:
        manager = get_ml_manager()
        if not manager:
            return {
                "status": "unavailable",
                "message": "Sistema ML no disponible",
                "timestamp": datetime.now().isoformat()
            }
        
        is_available = manager.is_ml_available()
        stats = manager.get_processing_stats()
        
        return {
            "status": "healthy" if is_available else "degraded",
            "ml_available": is_available,
            "cache_enabled": manager.enable_cache,
            "models_loaded": is_available,
            "stats": stats,
            "timestamp": datetime.now().isoformat()
        }
    
    except Exception as e:
        logger.error(f"Error en health check: {e}")
        return {
            "status": "error",
            "message": str(e),
            "timestamp": datetime.now().isoformat()
        }

@ml_router.post("/predict", response_model=PredictionResponse, summary="Predicción de amenaza")
async def predict_threat(
    event_request: SecurityEventRequest,
    api_key: str = Depends(verify_api_key)
):
    """Realiza predicción de amenaza para un evento de seguridad"""
    try:
        manager = get_ml_manager()
        if not manager or not manager.is_ml_available():
            raise HTTPException(
                status_code=503,
                detail="Sistema ML no disponible"
            )
        
        # Convertir request a SecurityEvent
        if SecurityEvent:
            event = SecurityEvent(
                timestamp=event_request.timestamp,
                event_type=event_request.event_type,
                severity=event_request.severity,
                source_ip=event_request.source_ip,
                target_domain=event_request.target_domain,
                vulnerability_count=event_request.vulnerability_count,
                threat_score=event_request.threat_score,
                technologies=event_request.technologies,
                ports_open=event_request.ports_open,
                response_time=event_request.response_time,
                status_code=event_request.status_code,
                payload_size=event_request.payload_size,
                user_agent=event_request.user_agent,
                country=event_request.country
            )
        else:
            raise HTTPException(
                status_code=503,
                detail="Módulo SecurityEvent no disponible"
            )
        
        # Realizar predicción
        start_time = datetime.now()
        prediction = manager.ml_analyzer.predict_threat(event)
        processing_time = (datetime.now() - start_time).total_seconds()
        
        return PredictionResponse(
            prediction=prediction.prediction,
            confidence=prediction.confidence,
            risk_score=prediction.risk_score,
            anomaly_score=prediction.anomaly_score,
            recommendations=prediction.recommendations,
            features_importance=prediction.features_importance,
            processing_time=processing_time,
            timestamp=prediction.timestamp
        )
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error en predicción: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Error interno: {str(e)}"
        )

@ml_router.post("/enhance-scan", response_model=EnhancedScanResponse, summary="Mejora de escaneo con ML")
async def enhance_scan(
    enhancement_request: ScanEnhancementRequest,
    api_key: str = Depends(verify_api_key)
):
    """Mejora resultado de escaneo con análisis ML"""
    try:
        manager = get_ml_manager()
        if not manager:
            raise HTTPException(
                status_code=503,
                detail="Sistema ML no disponible"
            )
        
        # Configurar cache si se especifica
        original_cache_setting = manager.enable_cache
        manager.enable_cache = enhancement_request.enable_caching
        
        try:
            # Realizar mejora del escaneo
            enhanced_result = manager.enhance_scan_result(
                enhancement_request.scan_result,
                enhancement_request.target_domain
            )
            
            # Convertir predicción ML a respuesta
            ml_prediction_response = None
            if enhanced_result.ml_prediction:
                ml_prediction_response = PredictionResponse(
                    prediction=enhanced_result.ml_prediction.prediction,
                    confidence=enhanced_result.ml_prediction.confidence,
                    risk_score=enhanced_result.ml_prediction.risk_score,
                    anomaly_score=enhanced_result.ml_prediction.anomaly_score,
                    recommendations=enhanced_result.ml_prediction.recommendations,
                    features_importance=enhanced_result.ml_prediction.features_importance,
                    processing_time=enhanced_result.processing_time,
                    timestamp=enhanced_result.ml_prediction.timestamp
                )
            
            return EnhancedScanResponse(
                original_result=enhanced_result.original_result,
                ml_prediction=ml_prediction_response,
                threat_patterns=[asdict(pattern) for pattern in enhanced_result.threat_patterns],
                risk_assessment=enhanced_result.risk_assessment,
                recommendations=enhanced_result.recommendations,
                confidence_score=enhanced_result.confidence_score,
                processing_time=enhanced_result.processing_time,
                timestamp=enhanced_result.timestamp
            )
        
        finally:
            # Restaurar configuración de cache
            manager.enable_cache = original_cache_setting
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error en mejora de escaneo: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Error interno: {str(e)}"
        )

@ml_router.post("/batch-predict", summary="Predicciones en lote")
async def batch_predict(
    batch_request: BatchPredictionRequest,
    background_tasks: BackgroundTasks,
    api_key: str = Depends(verify_api_key)
):
    """Realiza predicciones en lote para múltiples eventos"""
    try:
        manager = get_ml_manager()
        if not manager or not manager.is_ml_available():
            raise HTTPException(
                status_code=503,
                detail="Sistema ML no disponible"
            )
        
        # Validar límite de lote
        max_batch_size = ML_CONFIG.API_CONFIG['batch_prediction_limit'] if ML_CONFIG else 100
        if len(batch_request.events) > max_batch_size:
            raise HTTPException(
                status_code=400,
                detail=f"Lote demasiado grande. Máximo: {max_batch_size}"
            )
        
        # Procesar eventos en lote
        predictions = []
        start_time = datetime.now()
        
        for event_request in batch_request.events:
            if SecurityEvent:
                event = SecurityEvent(
                    timestamp=event_request.timestamp,
                    event_type=event_request.event_type,
                    severity=event_request.severity,
                    source_ip=event_request.source_ip,
                    target_domain=event_request.target_domain,
                    vulnerability_count=event_request.vulnerability_count,
                    threat_score=event_request.threat_score,
                    technologies=event_request.technologies,
                    ports_open=event_request.ports_open,
                    response_time=event_request.response_time,
                    status_code=event_request.status_code,
                    payload_size=event_request.payload_size,
                    user_agent=event_request.user_agent,
                    country=event_request.country
                )
                
                prediction = manager.ml_analyzer.predict_threat(event)
                predictions.append(asdict(prediction))
        
        processing_time = (datetime.now() - start_time).total_seconds()
        
        # Análisis de patrones si se solicita
        patterns = []
        if batch_request.include_patterns and SecurityEvent:
            events = []
            for event_request in batch_request.events:
                event = SecurityEvent(
                    timestamp=event_request.timestamp,
                    event_type=event_request.event_type,
                    severity=event_request.severity,
                    source_ip=event_request.source_ip,
                    target_domain=event_request.target_domain,
                    vulnerability_count=event_request.vulnerability_count,
                    threat_score=event_request.threat_score,
                    technologies=event_request.technologies,
                    ports_open=event_request.ports_open,
                    response_time=event_request.response_time,
                    status_code=event_request.status_code,
                    payload_size=event_request.payload_size,
                    user_agent=event_request.user_agent,
                    country=event_request.country
                )
                events.append(event)
            
            detected_patterns = manager.ml_analyzer.detect_threat_patterns(events)
            patterns = [asdict(pattern) for pattern in detected_patterns]
        
        return {
            "predictions": predictions,
            "threat_patterns": patterns,
            "batch_size": len(batch_request.events),
            "processing_time": processing_time,
            "timestamp": datetime.now().isoformat()
        }
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error en predicción en lote: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Error interno: {str(e)}"
        )

@ml_router.get("/stats", response_model=MLStatsResponse, summary="Estadísticas del sistema ML")
async def get_ml_stats(api_key: str = Depends(verify_api_key)):
    """Obtiene estadísticas del sistema ML"""
    try:
        manager = get_ml_manager()
        if not manager:
            raise HTTPException(
                status_code=503,
                detail="Sistema ML no disponible"
            )
        
        stats = manager.get_processing_stats()
        
        return MLStatsResponse(
            total_scans=stats['total_scans'],
            ml_enhanced_scans=stats['ml_enhanced_scans'],
            cache_hits=stats['cache_hits'],
            cache_misses=stats['cache_misses'],
            errors=stats['errors'],
            ml_available=stats['ml_available'],
            cache_enabled=stats['cache_enabled'],
            ml_enhancement_rate=stats['ml_enhancement_rate'],
            uptime="N/A"  # Implementar tracking de uptime
        )
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error obteniendo estadísticas: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Error interno: {str(e)}"
        )

@ml_router.post("/train", summary="Entrenar modelos ML")
async def train_models(
    training_request: TrainingRequest,
    background_tasks: BackgroundTasks,
    api_key: str = Depends(verify_api_key)
):
    """Entrena modelos ML con nuevos datos (solo admin)"""
    try:
        # Verificar que es una clave de admin
        if api_key != "admin-key":
            raise HTTPException(
                status_code=403,
                detail="Acceso denegado. Se requiere clave de administrador"
            )
        
        manager = get_ml_manager()
        if not manager:
            raise HTTPException(
                status_code=503,
                detail="Sistema ML no disponible"
            )
        
        # Validar datos de entrenamiento
        if len(training_request.scan_results) != len(training_request.target_domains):
            raise HTTPException(
                status_code=400,
                detail="Número de resultados y dominios debe coincidir"
            )
        
        if len(training_request.scan_results) < 10:
            raise HTTPException(
                status_code=400,
                detail="Se requieren al menos 10 muestras para entrenamiento"
            )
        
        # Ejecutar entrenamiento en background
        background_tasks.add_task(
            manager.train_with_scan_data,
            training_request.scan_results,
            training_request.target_domains
        )
        
        return {
            "message": "Entrenamiento iniciado en segundo plano",
            "samples_count": len(training_request.scan_results),
            "model_type": training_request.model_type,
            "timestamp": datetime.now().isoformat()
        }
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error iniciando entrenamiento: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Error interno: {str(e)}"
        )

@ml_router.get("/config", summary="Configuración del sistema ML")
async def get_ml_config(api_key: str = Depends(verify_api_key)):
    """Obtiene configuración del sistema ML"""
    try:
        if not ML_CONFIG:
            raise HTTPException(
                status_code=503,
                detail="Configuración ML no disponible"
            )
        
        # Retornar configuración pública (sin secretos)
        public_config = {
            "thresholds": ML_CONFIG.THRESHOLDS,
            "feature_columns": ML_CONFIG.FEATURE_COLUMNS,
            "dangerous_ports": ML_CONFIG.DANGEROUS_PORTS,
            "api_config": {
                "rate_limit_per_minute": ML_CONFIG.API_CONFIG['rate_limit_per_minute'],
                "batch_prediction_limit": ML_CONFIG.API_CONFIG['batch_prediction_limit'],
                "prediction_timeout": ML_CONFIG.API_CONFIG['prediction_timeout']
            },
            "cache_config": {
                "cache_ttl_seconds": ML_CONFIG.CACHE['cache_ttl_seconds'],
                "max_cache_size": ML_CONFIG.CACHE['max_cache_size']
            }
        }
        
        return public_config
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error obteniendo configuración: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Error interno: {str(e)}"
        )

@ml_router.delete("/cache", summary="Limpiar cache ML")
async def clear_ml_cache(api_key: str = Depends(verify_api_key)):
    """Limpia el cache del sistema ML"""
    try:
        manager = get_ml_manager()
        if not manager or not manager.redis_client:
            raise HTTPException(
                status_code=503,
                detail="Cache no disponible"
            )
        
        # Limpiar cache de predicciones ML
        cache_pattern = "ml_pred:*"
        keys = manager.redis_client.keys(cache_pattern)
        
        if keys:
            deleted_count = manager.redis_client.delete(*keys)
        else:
            deleted_count = 0
        
        return {
            "message": "Cache limpiado exitosamente",
            "deleted_keys": deleted_count,
            "timestamp": datetime.now().isoformat()
        }
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error limpiando cache: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Error interno: {str(e)}"
        )

@ml_router.post("/data-quality", response_model=DataQualityResponse, summary="Evaluar calidad de datos")
async def evaluate_data_quality(
    training_request: TrainingRequest,
    api_key: str = Depends(verify_api_key)
):
    """Evalúa la calidad de los datos de entrenamiento"""
    try:
        from .ml_training_optimizer import assess_training_data_quality
        from .ml_integration import MLIntegrationManager
        
        # Convertir datos a eventos de seguridad
        manager = MLIntegrationManager()
        events = []
        
        for scan_result, domain in zip(training_request.scan_results, training_request.target_domains):
            event = manager.convert_scan_to_security_event(scan_result, domain)
            events.append(event)
        
        # Evaluar calidad
        quality_metrics = assess_training_data_quality(events)
        
        # Generar recomendaciones
        recommendations = []
        
        if quality_metrics.completeness < 0.8:
            recommendations.append("Mejorar completitud de datos - faltan campos importantes")
        
        if quality_metrics.consistency < 0.7:
            recommendations.append("Revisar consistencia - hay valores fuera de rango esperado")
        
        if quality_metrics.diversity < 0.6:
            recommendations.append("Aumentar diversidad - incluir más tipos de objetivos y escenarios")
        
        if quality_metrics.balance < 0.3:
            recommendations.append("Balancear clases - agregar más eventos maliciosos o benignos")
        
        if quality_metrics.temporal_coverage < 0.5:
            recommendations.append("Ampliar cobertura temporal - incluir datos de diferentes períodos")
        
        if quality_metrics.sample_count < 100:
            recommendations.append("Aumentar número de muestras - se recomiendan al menos 100 eventos")
        
        if not recommendations:
            recommendations.append("Calidad de datos es buena - proceder con entrenamiento")
        
        return DataQualityResponse(
            completeness=quality_metrics.completeness,
            consistency=quality_metrics.consistency,
            diversity=quality_metrics.diversity,
            balance=quality_metrics.balance,
            temporal_coverage=quality_metrics.temporal_coverage,
            overall_score=quality_metrics.overall_score,
            sample_count=quality_metrics.sample_count,
            malicious_ratio=quality_metrics.malicious_ratio,
            recommendations=recommendations
        )
        
    except ImportError:
        raise HTTPException(
            status_code=503,
            detail="Módulo de optimización ML no disponible"
        )
    except Exception as e:
        logger.error(f"Error evaluando calidad de datos: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Error interno: {str(e)}"
        )

@ml_router.post("/train/optimized", response_model=OptimizedTrainingResponse, summary="Entrenamiento optimizado")
async def train_optimized_models(
    training_request: OptimizedTrainingRequest,
    background_tasks: BackgroundTasks,
    api_key: str = Depends(verify_api_key)
):
    """Entrena modelos ML con técnicas optimizadas y mejores datos"""
    try:
        # Verificar permisos de admin
        if api_key != "admin-key":
            raise HTTPException(
                status_code=403,
                detail="Acceso denegado. Se requiere clave de administrador"
            )
        
        # Validaciones de datos
        if len(training_request.scan_results) != len(training_request.target_domains):
            raise HTTPException(
                status_code=400,
                detail="Número de resultados y dominios debe coincidir"
            )
        
        if len(training_request.scan_results) < training_request.min_samples_required:
            raise HTTPException(
                status_code=400,
                detail=f"Se requieren al menos {training_request.min_samples_required} muestras"
            )
        
        # Generar ID único para el entrenamiento
        import uuid
        training_id = str(uuid.uuid4())[:8]
        
        # Configurar entrenamiento optimizado
        from .ml_training_optimizer import OptimizedTrainingConfig
        
        config = OptimizedTrainingConfig(
            augmentation_factor=training_request.augmentation_factor,
            cv_folds=training_request.cv_folds,
            optimize_hyperparams=training_request.optimize_hyperparams,
            feature_selection=training_request.feature_selection,
            ensemble_methods=training_request.ensemble_methods,
            balance_classes=training_request.balance_classes,
            temporal_validation=training_request.temporal_validation,
            min_samples_required=training_request.min_samples_required
        )
        
        # Evaluar calidad de datos primero
        from .ml_training_optimizer import assess_training_data_quality
        from .ml_integration import MLIntegrationManager
        
        manager = MLIntegrationManager()
        events = []
        
        for scan_result, domain in zip(training_request.scan_results, training_request.target_domains):
            event = manager.convert_scan_to_security_event(scan_result, domain)
            events.append(event)
        
        data_quality = assess_training_data_quality(events)
        
        # Generar recomendaciones de calidad
        recommendations = []
        if data_quality.overall_score < 0.6:
            recommendations.append("Calidad de datos baja - considerar mejorar datos antes del entrenamiento")
        
        # Estimar duración del entrenamiento
        base_time = len(training_request.scan_results) * 0.1  # 0.1 min por muestra base
        if training_request.optimize_hyperparams:
            base_time *= 3  # Optimización toma más tiempo
        if training_request.augmentation_factor > 1:
            base_time *= 1.5  # Augmentación añade tiempo
        
        estimated_duration = max(5, int(base_time))  # Mínimo 5 minutos
        
        # Ejecutar entrenamiento optimizado en background
        background_tasks.add_task(
            _run_optimized_training,
            training_id,
            training_request.scan_results,
            training_request.target_domains,
            config
        )
        
        return OptimizedTrainingResponse(
            message="Entrenamiento optimizado iniciado exitosamente",
            training_id=training_id,
            samples_count=len(training_request.scan_results),
            config_used={
                "augmentation_factor": config.augmentation_factor,
                "cv_folds": config.cv_folds,
                "optimize_hyperparams": config.optimize_hyperparams,
                "feature_selection": config.feature_selection,
                "ensemble_methods": config.ensemble_methods,
                "balance_classes": config.balance_classes
            },
            data_quality=DataQualityResponse(
                completeness=data_quality.completeness,
                consistency=data_quality.consistency,
                diversity=data_quality.diversity,
                balance=data_quality.balance,
                temporal_coverage=data_quality.temporal_coverage,
                overall_score=data_quality.overall_score,
                sample_count=data_quality.sample_count,
                malicious_ratio=data_quality.malicious_ratio,
                recommendations=recommendations
            ),
            estimated_duration_minutes=estimated_duration,
            timestamp=datetime.now().isoformat()
        )
        
    except ImportError:
        raise HTTPException(
            status_code=503,
            detail="Módulo de optimización ML no disponible"
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error en entrenamiento optimizado: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Error interno: {str(e)}"
        )

async def _run_optimized_training(training_id: str, scan_results: List[Dict[str, Any]], 
                                target_domains: List[str], config: 'OptimizedTrainingConfig'):
    """Ejecuta entrenamiento optimizado en background"""
    try:
        from .ml_training_optimizer import OptimizedMLTrainer
        from .ml_integration import MLIntegrationManager
        
        logger.info(f"Iniciando entrenamiento optimizado {training_id}")
        
        # Convertir datos a eventos de seguridad
        manager = MLIntegrationManager()
        events = []
        
        for scan_result, domain in zip(scan_results, target_domains):
            event = manager.convert_scan_to_security_event(scan_result, domain)
            events.append(event)
        
        # Crear entrenador optimizado
        trainer = OptimizedMLTrainer(config)
        
        # Ejecutar entrenamiento con mejores prácticas
        results = trainer.train_with_best_practices(events)
        
        # Guardar resultados del entrenamiento
        results_path = Path("models") / "training_results" / f"{training_id}.json"
        results_path.parent.mkdir(parents=True, exist_ok=True)
        
        # Serializar resultados (sin modelos, solo métricas)
        serializable_results = {
            "training_id": training_id,
            "timestamp": results.timestamp.isoformat(),
            "training_time": results.training_time,
            "metrics": results.metrics,
            "feature_importance": results.feature_importance,
            "data_quality": {
                "completeness": results.data_quality.completeness,
                "consistency": results.data_quality.consistency,
                "diversity": results.data_quality.diversity,
                "balance": results.data_quality.balance,
                "temporal_coverage": results.data_quality.temporal_coverage,
                "overall_score": results.data_quality.overall_score,
                "sample_count": results.data_quality.sample_count,
                "malicious_ratio": results.data_quality.malicious_ratio
            },
            "config_used": {
                "augmentation_factor": config.augmentation_factor,
                "cv_folds": config.cv_folds,
                "optimize_hyperparams": config.optimize_hyperparams,
                "feature_selection": config.feature_selection,
                "ensemble_methods": config.ensemble_methods,
                "balance_classes": config.balance_classes
            }
        }
        
        with open(results_path, 'w') as f:
            json.dump(serializable_results, f, indent=2)
        
        # Guardar modelos entrenados
        models_path = Path("models") / "optimized" / training_id
        models_path.mkdir(parents=True, exist_ok=True)
        
        for model_name, model in results.models.items():
            model_file = models_path / f"{model_name}.pkl"
            joblib.dump(model, model_file)
        
        logger.info(f"Entrenamiento optimizado {training_id} completado exitosamente")
        logger.info(f"Mejores métricas: {max(results.metrics.values(), key=lambda x: x.get('f1_score', 0))}")
        
    except Exception as e:
        logger.error(f"Error en entrenamiento optimizado {training_id}: {e}")
        # Guardar error para consulta posterior
        error_path = Path("models") / "training_results" / f"{training_id}_error.json"
        error_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(error_path, 'w') as f:
            json.dump({
                "training_id": training_id,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }, f, indent=2)

@ml_router.get("/training/{training_id}/status", summary="Estado del entrenamiento")
async def get_training_status(
    training_id: str,
    api_key: str = Depends(verify_api_key)
):
    """Obtiene el estado de un entrenamiento optimizado"""
    try:
        # Buscar resultados del entrenamiento
        results_path = Path("models") / "training_results" / f"{training_id}.json"
        error_path = Path("models") / "training_results" / f"{training_id}_error.json"
        
        if results_path.exists():
            with open(results_path, 'r') as f:
                results = json.load(f)
            
            return {
                "status": "completed",
                "training_id": training_id,
                "results": results,
                "timestamp": results.get("timestamp")
            }
        
        elif error_path.exists():
            with open(error_path, 'r') as f:
                error_info = json.load(f)
            
            return {
                "status": "failed",
                "training_id": training_id,
                "error": error_info.get("error"),
                "timestamp": error_info.get("timestamp")
            }
        
        else:
            return {
                "status": "running",
                "training_id": training_id,
                "message": "Entrenamiento en progreso"
            }
    
    except Exception as e:
        logger.error(f"Error consultando estado de entrenamiento: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Error interno: {str(e)}"
        )

# Función para incluir el router en la aplicación principal
def include_ml_routes(app):
    """Incluye las rutas ML en la aplicación FastAPI"""
    if MLIntegrationManager:
        app.include_router(ml_router)
        logger.info("Rutas ML incluidas en la aplicación")
    else:
        logger.warning("Sistema ML no disponible, rutas no incluidas")