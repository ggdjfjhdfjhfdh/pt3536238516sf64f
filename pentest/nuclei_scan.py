"""Módulo para escaneo de vulnerabilidades con Nuclei."""

import json
import logging
import os
from pathlib import Path
from typing import Dict, List, Any, Optional

from pentest.runners import run_cmd
from pentest.exceptions import NucleiError
from pentest.config import DEFAULT_TIMEOUT
from pentest.http import get_session
from urllib.parse import urlparse

# Configuración de logging
log = logging.getLogger(__name__)

# Mapeo de tecnologías a plantillas de Nuclei (ejemplo)
# Estas rutas de plantillas son ejemplos y deben ser ajustadas a las rutas reales en el sistema
TEMPLATE_MAPPING = {
    "wordpress": [
        "wordpress/", # Escanea todas las plantillas de WordPress
        "cves/2022/CVE-2022-XXXX.yaml" # Ejemplo de CVE específica
    ],
    "nginx": [
        "default-logins/nginx-default-login.yaml",
        "miscellaneous/nginx-insecure-configuration.yaml"
    ],
    "apache http server": [
        "default-logins/apache-default-login.yaml",
        "miscellaneous/apache-insecure-configuration.yaml"
    ],
    "php": [
        "technologies/php-exposed-info.yaml"
    ],
    "mysql": [
        "default-logins/mysql-default-login.yaml"
    ],
    "microsoft iis": [
        "technologies/microsoft-iis-version.yaml"
    ]
}

def nuclei_scan(httpx_file: Path, tmp_dir: Path, full_scan: bool = False) -> Path:
    """Escanea vulnerabilidades utilizando Nuclei y comprueba cabeceras de seguridad.
    
    Args:
        httpx_file: Archivo JSON con hosts activos
        tmp_dir: Directorio temporal para almacenar resultados
        
    Returns:
        Path al archivo JSON con las vulnerabilidades encontradas
        
    Raises:
        NucleiError: Si falla el escaneo de vulnerabilidades
    """
    log.info("🔍 Iniciando escaneo de vulnerabilidades")
    
    output_file = tmp_dir / "nuclei.json"
    urls_file = tmp_dir / "urls.txt"
    
    # Verificar que el archivo de hosts existe
    if not httpx_file.exists():
        raise NucleiError(f"Archivo de hosts no encontrado: {httpx_file}")
    
    # Extraer URLs del archivo httpx
    try:
        with open(httpx_file, "r") as f:
            hosts_data = json.load(f)
        
        # Extraer URLs y tecnologías
        urls = []
        detected_technologies = set()
        for host in hosts_data:
            url = host.get("url")
            if url:
                urls.append(url)
            
            techs = host.get("tech", [])
            for tech in techs:
                normalized_tech = None
                if isinstance(tech, str):
                    normalized_tech = {"name": tech}
                elif isinstance(tech, dict):
                    normalized_tech = tech
                
                if normalized_tech:
                    tech_name = normalized_tech.get("name", "").lower()
                    if tech_name:
                        detected_technologies.add(tech_name)
                else:
                    log.warning(f"Elemento inesperado en la lista de tecnologías: {tech}. Se esperaba un diccionario o cadena.")

        if not urls:
            log.warning("No se encontraron URLs para escanear")
            # Crear un archivo de resultados vacío
            with open(output_file, "w") as f:
                json.dump([], f)
            return output_file
        
        # Guardar URLs en un archivo
        with open(urls_file, "w") as f:
            for url in urls:
                f.write(f"{url}\n")
                
        log.info("Preparadas %d URLs para escaneo", len(urls))
    except Exception as e:
        raise NucleiError(f"Error al procesar archivo de hosts: {str(e)}") from e
    
    # Lista para almacenar todos los resultados
    all_findings = []
    
    # Intentar escaneo con Nuclei
    try:
        log.info("Ejecutando Nuclei para detectar vulnerabilidades")
        nuclei_cmd = [
            "nuclei", 
            "-l", str(urls_file),
            "-json",
            "-severity", "critical,high,medium,low,info",
            "-silent",
            "-c", "100" # Añadir concurrencia para acelerar
        ]
        
        # Añadir plantillas específicas basadas en las tecnologías detectadas
        specific_templates = []
        for tech in detected_technologies:
            if tech in TEMPLATE_MAPPING:
                specific_templates.extend(TEMPLATE_MAPPING[tech])
        
        if specific_templates:
            log.info(f"Usando plantillas específicas para tecnologías detectadas: {', '.join(specific_templates)}")
            for template_path in specific_templates:
                nuclei_cmd.extend(["-t", template_path])
        
        if full_scan:
            log.info("Realizando escaneo completo con todas las plantillas de Nuclei.")
            nuclei_cmd.extend(["-t", "nuclei-templates/"]) # Escanea todas las plantillas disponibles
        elif not specific_templates:
            log.info("No se detectaron tecnologías específicas para plantillas. Realizando escaneo general con etiquetas por defecto.")
            nuclei_cmd.extend(["-tags", "cve,exposed-panels,default-logins,misconfiguration,vulnerabilities"])

        nuclei_output = run_cmd(nuclei_cmd, timeout=DEFAULT_TIMEOUT * 2, ignore=True, retries=3, delay=2)
        
        # Procesar la salida JSON
        for line in nuclei_output.splitlines():
            if line.strip():
                try:
                    finding = json.loads(line)
                    all_findings.append(finding)
                except json.JSONDecodeError:
                    log.warning("Error al decodificar línea JSON de Nuclei: %s", line)
        
        log.info("Nuclei encontró %d vulnerabilidades", len(all_findings))
    except Exception as e:
        log.warning("Nuclei falló: %s", str(e))
    
    # Comprobar cabeceras de seguridad manualmente
    try:
        log.info("Comprobando cabeceras de seguridad manualmente")
        session = get_session()
        
        for url in urls:
            parsed_url = urlparse(url)
            if not parsed_url.scheme or not parsed_url.netloc:
                log.warning("URL inválida encontrada, saltando comprobación de cabeceras: %s", url)
                continue

            try:
                log.info(f"Comprobando cabeceras para: {url}")
                response = session.get(url, timeout=10, verify=False, allow_redirects=True)
                headers = response.headers
                
                # Comprobar X-Frame-Options
                if "x-frame-options" not in {h.lower() for h in headers}:
                    all_findings.append({
                        "info": {
                            "name": "Missing X-Frame-Options Header",
                            "severity": "medium",
                            "description": "La cabecera X-Frame-Options no está presente, lo que podría permitir ataques de clickjacking."
                        },
                        "host": url,
                        "matched": url,
                        "type": "http"
                    })
                
                # Comprobar Content-Security-Policy
                if "content-security-policy" not in {h.lower() for h in headers}:
                    all_findings.append({
                        "info": {
                            "name": "Missing Content-Security-Policy Header",
                            "severity": "medium",
                            "description": "La cabecera Content-Security-Policy no está presente, lo que podría permitir ataques XSS."
                        },
                        "host": url,
                        "matched": url,
                        "type": "http"
                    })
                
                # Comprobar X-Content-Type-Options
                
                # Comprobar Expect-CT
                if "expect-ct" not in {h.lower() for h in headers}:
                    all_findings.append({
                        "info": {
                            "name": "Missing Expect-CT Header",
                            "severity": "medium",
                            "description": "La cabecera Expect-CT no está presente, lo que podría permitir la emisión de certificados no autorizados."
                        },
                        "host": url,
                        "matched": url,
                        "type": "http"
                    })

                # Comprobar Cross-Origin-Resource-Policy
                if "cross-origin-resource-policy" not in {h.lower() for h in headers}:
                    all_findings.append({
                        "info": {
                            "name": "Missing Cross-Origin-Resource-Policy Header",
                            "severity": "medium",
                            "description": "La cabecera Cross-Origin-Resource-Policy no está presente, lo que podría permitir ataques de inclusión de recursos de origen cruzado."
                        },
                        "host": url,
                        "matched": url,
                        "type": "http"
                    })

                # Comprobar Server header
                server_header = headers.get("Server")
                if server_header:
                    all_findings.append({
                        "info": {
                            "name": "Server Header Exposed",
                            "severity": "low",
                            "description": f"La cabecera 'Server' expone información sobre el servidor web: {server_header}. Esto podría ser utilizado por atacantes para identificar vulnerabilidades conocidas."
                        },
                        "host": url,
                        "matched": url,
                        "type": "http"
                    })
                else:
                    all_findings.append({
                        "info": {
                            "name": "Missing Server Header",
                            "severity": "info",
                            "description": "La cabecera 'Server' no está presente. Esto es una buena práctica de seguridad para evitar la exposición de información del servidor."
                        },
                        "host": url,
                        "matched": url,
                        "type": "http"
                    })

                if "x-content-type-options" not in {h.lower() for h in headers}:
                    all_findings.append({
                        "info": {
                            "name": "Missing X-Content-Type-Options Header",
                            "severity": "low",
                            "description": "La cabecera X-Content-Type-Options no está presente, lo que podría permitir MIME-sniffing."
                        },
                        "host": url,
                        "matched": url,
                        "type": "http"
                    })
                
                # Comprobar si usa HTTP (no HTTPS)
                if url.startswith("http://"):
                    all_findings.append({
                        "info": {
                            "name": "HTTP Usage (No HTTPS)",
                            "severity": "high",
                            "description": "El sitio utiliza HTTP sin cifrado, lo que expone las comunicaciones a interceptación."
                        },
                        "host": url,
                        "matched": url,
                        "type": "http"
                    })
                    
            except Exception as e:
                log.debug("Error al comprobar cabeceras para %s: %s", url, str(e))
                
        log.info("Comprobación manual de cabeceras completada")
    except Exception as e:
        log.warning("Error en comprobación manual de cabeceras: %s", str(e))
    
    # Guardar todos los resultados
    with open(output_file, "w") as f:
        json.dump(all_findings, f, indent=2)
    
    log.info("✅ Escaneo de vulnerabilidades completado: %d hallazgos", len(all_findings))
    return output_file