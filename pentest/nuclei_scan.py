"""Escaneo de vulnerabilidades con Nuclei + chequeo manual de cabeceras.

Cambios clave sobre la versi√≥n anterior
--------------------------------------
* Separaci√≥n en funciones peque√±as (_build_cmd, _run_nuclei, _manual_header_check).
* Mapeo de tecnolog√≠as case‚Äëinsensitive y sin duplicados.
* Soporte de escaneo *universal* (sin plantillas) si Nuclei no est√° disponible.
* Timeouts y reintentos configurables.
* Salida deduplicada (hash SHA‚Äë1 de host + vuln).
* Tipado estricto y testabilidad.
"""
from __future__ import annotations

import json
import logging
import os
import hashlib
import time
from pathlib import Path
from typing import Dict, List, Any, Set, Optional
from urllib.parse import urlparse
from concurrent.futures import ThreadPoolExecutor, as_completed
from functools import lru_cache

from pentest.runners import run_cmd
from pentest.exceptions import NucleiError
from pentest.config import DEFAULT_TIMEOUT
from pentest.http_utils import get_session

log = logging.getLogger(__name__)

# ---------------------------------------------------------------------------
# Configuraci√≥n
# ---------------------------------------------------------------------------

TEMPLATE_MAPPING: Dict[str, List[str]] = {
    # CMS y Frameworks Web
    "wordpress": ["wordpress/", "default-logins/wordpress-default-login.yaml"],
    "drupal": ["drupal/", "default-logins/drupal-default-login.yaml"],
    "joomla": ["joomla/", "default-logins/joomla-default-login.yaml"],
    
    # Servidores Web
    "nginx": ["default-logins/nginx-default-login.yaml", "misconfiguration/nginx-alias-traversal.yaml"],
    "apache http server": ["default-logins/apache-default-login.yaml", "misconfiguration/apache-server-info.yaml"],
    "microsoft iis": ["technologies/microsoft-iis-version.yaml", "misconfiguration/iis-shortname-disclosure.yaml"],
    
    # Lenguajes de Programaci√≥n
    "php": ["technologies/php-exposed-info.yaml", "misconfiguration/php-errors.yaml"],
    "python": ["technologies/python-version.yaml", "misconfiguration/django-debug.yaml"],
    "java": ["technologies/java-version.yaml", "misconfiguration/spring-boot-actuator.yaml"],
    "node.js": ["technologies/nodejs-version.yaml", "misconfiguration/express-stack-trace.yaml"],
    
    # Frameworks Frontend
    "react": ["technologies/react-version.yaml", "misconfiguration/react-dev-tools.yaml"],
    "vue.js": ["technologies/vue-version.yaml", "misconfiguration/vue-dev-tools.yaml"],
    "angular": ["technologies/angular-version.yaml", "misconfiguration/angular-dev-tools.yaml"],
    
    # Frameworks Backend
    "django": ["misconfiguration/django-debug.yaml", "default-logins/django-admin.yaml"],
    "laravel": ["misconfiguration/laravel-debug.yaml", "technologies/laravel-version.yaml"],
    "spring": ["misconfiguration/spring-boot-actuator.yaml", "technologies/spring-version.yaml"],
    "express": ["misconfiguration/express-stack-trace.yaml", "technologies/express-version.yaml"],
    
    # Bases de Datos
    "mysql": ["default-logins/mysql-default-login.yaml", "misconfiguration/mysql-dump.yaml"],
    "postgresql": ["default-logins/postgres-default-login.yaml", "misconfiguration/postgres-dump.yaml"],
    "mongodb": ["default-logins/mongodb-default-login.yaml", "misconfiguration/mongodb-exposure.yaml"],
    "redis": ["default-logins/redis-default-login.yaml", "misconfiguration/redis-unauth.yaml"],
    
    # Servicios Cloud
    "aws": ["cloud/aws-s3-bucket.yaml", "misconfiguration/aws-metadata.yaml"],
    "azure": ["cloud/azure-storage.yaml", "misconfiguration/azure-metadata.yaml"],
    "gcp": ["cloud/gcp-storage.yaml", "misconfiguration/gcp-metadata.yaml"],
    
    # Contenedores y Orquestaci√≥n
    "docker": ["misconfiguration/docker-api.yaml", "technologies/docker-version.yaml"],
    "kubernetes": ["misconfiguration/kubernetes-api.yaml", "technologies/kubernetes-version.yaml"],
    
    # Herramientas de Desarrollo
    "jenkins": ["default-logins/jenkins-default-login.yaml", "misconfiguration/jenkins-build-info.yaml"],
    "gitlab": ["default-logins/gitlab-default-login.yaml", "misconfiguration/gitlab-public-repos.yaml"],
    "github": ["misconfiguration/github-config.yaml", "technologies/github-version.yaml"],
    
    # APIs y Microservicios
    "swagger": ["misconfiguration/swagger-ui.yaml", "technologies/swagger-version.yaml"],
    "graphql": ["misconfiguration/graphql-introspection.yaml", "technologies/graphql-version.yaml"],
    "rest api": ["misconfiguration/api-debug.yaml", "technologies/api-version.yaml"],
}

HEADER_REQUIREMENTS = {
    # Cabeceras cr√≠ticas de seguridad
    "strict-transport-security": {
        "severity": "high",
        "desc": "Sin HSTS ‚Üí conexiones HTTP inseguras.",
        "validate": lambda v: "max-age" in v and int(v.split("max-age=")[1].split(";")[0]) >= 31536000
    },
    "content-security-policy": {
        "severity": "medium",
        "desc": "Sin CSP ‚Üí posible XSS.",
        "validate": lambda v: "unsafe-inline" not in v and "unsafe-eval" not in v
    },
    "x-frame-options": {
        "severity": "medium",
        "desc": "Sin X-Frame-Options ‚Üí riesgo de clickjacking.",
        "validate": lambda v: v.upper() in ["DENY", "SAMEORIGIN"]
    },
    "referrer-policy": {
        "severity": "medium",
        "desc": "Sin Referrer-Policy ‚Üí filtraci√≥n de informaci√≥n.",
        "validate": lambda v: v in ["no-referrer", "strict-origin-when-cross-origin", "same-origin"]
    },
    "permissions-policy": {
        "severity": "medium",
        "desc": "Sin Permissions-Policy ‚Üí acceso no controlado a APIs.",
        "validate": lambda v: len(v) > 0
    },
    "cross-origin-resource-policy": {
        "severity": "medium",
        "desc": "Sin CORP ‚Üí recursos de origen cruzado.",
        "validate": lambda v: v in ["same-site", "same-origin", "cross-origin"]
    },
    "cross-origin-opener-policy": {
        "severity": "medium",
        "desc": "Sin COOP ‚Üí ataques de timing side-channel.",
        "validate": lambda v: v in ["same-origin", "same-origin-allow-popups"]
    },
    "cross-origin-embedder-policy": {
        "severity": "medium",
        "desc": "Sin COEP ‚Üí acceso no controlado a recursos cross-origin.",
        "validate": lambda v: v in ["require-corp", "credentialless"]
    },
    "x-content-type-options": {
        "severity": "low",
        "desc": "Sin X-Content-Type-Options ‚Üí MIME sniffing.",
        "validate": lambda v: v.lower() == "nosniff"
    },
    "x-xss-protection": {
        "severity": "low",
        "desc": "Sin X-XSS-Protection ‚Üí XSS en navegadores legacy.",
        "validate": lambda v: v == "1; mode=block"
    },
    "expect-ct": {
        "severity": "low",
        "desc": "Sin Expect-CT ‚Üí certificados no autorizados.",
        "validate": lambda v: "max-age" in v
    },
}

NUCLEI_DEFAULT_TAGS = "cve,exposed-panels,default-logins,misconfiguration,vulnerabilities"
MAX_RETRIES = 3

# Configuraci√≥n de rendimiento
MAX_WORKERS = 10  # N√∫mero m√°ximo de hilos para chequeo de cabeceras
REQUEST_TIMEOUT = 10  # Timeout para requests HTTP
RATE_LIMIT_DELAY = 0.1  # Delay entre requests para rate limiting
CACHE_SIZE = 128  # Tama√±o del cache LRU

# ---------------------------------------------------------------------------
# Utilidades internas
# ---------------------------------------------------------------------------

def _build_cmd(urls_file: Path, templates: Set[str], full_scan: bool) -> List[str]:
    """Compone el comando nuclei seg√∫n la configuraci√≥n."""
    cmd = [
        "nuclei", "-l", str(urls_file), "-json", "-silent", "-severity",
        "critical,high,medium,low,info", "-c", "100",
    ]

    if full_scan:
        cmd += ["-t", os.environ.get("NUCLEI_TEMPLATE_DIR", "nuclei-templates/")]
    elif templates:
        for t in templates:
            cmd += ["-t", t]
    else:
        cmd += ["-tags", NUCLEI_DEFAULT_TAGS]
    return cmd


def _dedup_findings(findings: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """Elimina duplicados usando hash(host+template+matched)."""
    seen: Set[str] = set()
    deduped: List[Dict[str, Any]] = []
    for f in findings:
        key_raw = f.get("host", "") + f.get("template", "") + f.get("matched", "")
        key = hashlib.sha1(key_raw.encode()).hexdigest()
        if key not in seen:
            seen.add(key)
            deduped.append(f)
    return deduped


def _run_nuclei(cmd: List[str]) -> str:
    return run_cmd(cmd, timeout=DEFAULT_TIMEOUT * 2, ignore=True,
                   retries=MAX_RETRIES, delay=2)


@lru_cache(maxsize=CACHE_SIZE)
def _cached_header_check(url: str) -> Dict[str, Any]:
    """Chequeo de cabeceras con cache para evitar requests duplicados."""
    session = get_session()
    try:
        resp = session.get(url, timeout=REQUEST_TIMEOUT, verify=False, allow_redirects=True)
        return {
            "headers": dict(resp.headers),
            "status_code": resp.status_code,
            "url": resp.url
        }
    except Exception as exc:
        log.debug("Error en request a %s: %s", url, exc)
        return {"error": str(exc)}


def _validate_header_value(header_name: str, header_value: str) -> Dict[str, Any]:
    """Valida el valor de una cabecera espec√≠fica."""
    header_config = HEADER_REQUIREMENTS.get(header_name.lower())
    if not header_config:
        return {"valid": True, "message": "No validation configured"}
    
    validate_func = header_config.get("validate")
    if not validate_func:
        return {"valid": True, "message": "Header present"}
    
    try:
        is_valid = validate_func(header_value)
        return {
            "valid": is_valid,
            "message": "Valid configuration" if is_valid else "Invalid configuration"
        }
    except Exception as exc:
        return {"valid": False, "message": f"Validation error: {exc}"}


def _check_single_url_headers(url: str) -> List[Dict[str, Any]]:
    """Chequea las cabeceras de seguridad para una URL espec√≠fica."""
    findings = []
    p = urlparse(url)
    if not p.scheme or not p.netloc:
        return findings
    
    # Rate limiting
    time.sleep(RATE_LIMIT_DELAY)
    
    response_data = _cached_header_check(url)
    if "error" in response_data:
        return findings
    
    headers = response_data["headers"]
    hdrs_l = {k.lower(): v for k, v in headers.items()}
    
    # Chequear cabeceras requeridas
    for header_name, meta in HEADER_REQUIREMENTS.items():
        header_value = hdrs_l.get(header_name)
        
        if not header_value:
            # Cabecera faltante
            findings.append({
                "host": url,
                "matched": url,
                "type": "http",
                "info": {
                    "name": f"Missing {header_name.title()} Header",
                    "severity": meta["severity"],
                    "description": meta["desc"],
                },
            })
        else:
            # Validar valor de cabecera
            validation = _validate_header_value(header_name, header_value)
            if not validation["valid"]:
                findings.append({
                    "host": url,
                    "matched": url,
                    "type": "http",
                    "info": {
                        "name": f"Invalid {header_name.title()} Header",
                        "severity": meta["severity"],
                        "description": f"{meta['desc']} Value: '{header_value}'. {validation['message']}",
                    },
                })
    
    # Chequear cabecera Server
    srv = headers.get("Server")
    findings.append({
        "host": url,
        "matched": url,
        "type": "http",
        "info": {
            "name": "Server Header " + ("Exposed" if srv else "Not Present"),
            "severity": "low" if srv else "info",
            "description": f"'Server' header value: {srv or 'none'}.",
        },
    })
    
    # Chequear protocolo HTTP no cifrado
    if url.startswith("http://"):
        findings.append({
            "host": url,
            "matched": url,
            "type": "http",
            "info": {
                "name": "HTTP (unencrypted)",
                "severity": "high",
                "description": "El sitio usa HTTP sin cifrado.",
            },
        })
    
    return findings


def _parallel_header_check(urls: List[str]) -> List[Dict[str, Any]]:
    """Ejecuta el chequeo de cabeceras en paralelo para m√∫ltiples URLs."""
    findings = []
    
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        # Enviar todas las tareas
        future_to_url = {executor.submit(_check_single_url_headers, url): url for url in urls}
        
        # Recoger resultados conforme se completan
        for future in as_completed(future_to_url):
            url = future_to_url[future]
            try:
                url_findings = future.result()
                findings.extend(url_findings)
            except Exception as exc:
                log.debug("Error procesando %s: %s", url, exc)
    
    return findings

# ---------------------------------------------------------------------------
# API p√∫blica
# ---------------------------------------------------------------------------

def nuclei_scan(httpx_file: Optional[Path], tmp_dir: Path, full_scan: bool = False) -> Path:
    log.info("üîç [NUCLEI] Nuclei: escaneo de vulnerabilidades")
    log.info("üîç [NUCLEI] Archivo httpx: %s", httpx_file)
    log.info("üîç [NUCLEI] Directorio temporal: %s", tmp_dir)
    
    out_json = tmp_dir / "nuclei.json"
    urls_file = tmp_dir / "urls.txt"
    log.info("üîç [NUCLEI] Archivo de salida: %s", out_json)

    if not httpx_file or not httpx_file.exists():
        log.warning(f"üîç [NUCLEI] ‚ùå Archivo de hosts no encontrado o es None: {httpx_file}. Nuclei scan will return empty results.")
        out_json.write_text("[]")
        return out_json

    # Verificar el tama√±o del archivo httpx
    file_size = httpx_file.stat().st_size
    log.info("üîç [NUCLEI] Tama√±o del archivo httpx: %d bytes", file_size)

    # ---------------------------------------------------------------------
    # Preparar URLs + tecnolog√≠as
    # ---------------------------------------------------------------------
    try:
        content = httpx_file.read_text()
        log.info("üîç [NUCLEI] Contenido crudo del archivo httpx (primeros 500 chars): %s", content[:500])
        hosts_data = json.loads(content)
        log.info("üîç [NUCLEI] Datos JSON parseados: %d entradas", len(hosts_data))
        if hosts_data:
            log.info("üîç [NUCLEI] Primera entrada: %s", hosts_data[0])
    except Exception as exc:
        log.warning(f"üîç [NUCLEI] ‚ùå Error leyendo {httpx_file}: {exc}. Nuclei scan will return empty results.")
        log.warning(f"üîç [NUCLEI] ‚ùå Contenido problem√°tico: %s", content[:200] if 'content' in locals() else 'No se pudo leer')
        out_json.write_text("[]")
        return out_json

    urls: List[str] = []
    techs: Set[str] = set()
    
    log.info("üîç [NUCLEI] Procesando %d entradas de httpx", len(hosts_data))
    for i, h in enumerate(hosts_data):
        log.debug("üîç [NUCLEI] Procesando entrada %d: %s", i, h)
        if url := h.get("url"):
            urls.append(url)
            log.debug("üîç [NUCLEI] URL a√±adida: %s", url)
        else:
            log.warning("üîç [NUCLEI] ‚ö†Ô∏è Entrada %d sin campo 'url': %s", i, h)
        
        for t in h.get("tech", []):
            name = t if isinstance(t, str) else t.get("name", "")
            if name:
                techs.add(name.lower())
                log.debug("üîç [NUCLEI] Tecnolog√≠a a√±adida: %s", name.lower())

    log.info("üîç [NUCLEI] URLs extra√≠das: %d", len(urls))
    log.info("üîç [NUCLEI] Lista de URLs: %s", urls)
    log.info("üîç [NUCLEI] Tecnolog√≠as detectadas: %s", list(techs))

    if not urls:
        log.warning("üîç [NUCLEI] ‚ö†Ô∏è Sin URLs para escanear ‚Äì devolviendo JSON vac√≠o")
        log.warning("üîç [NUCLEI] ‚ö†Ô∏è Datos httpx recibidos: %s", hosts_data)
        out_json.write_text("[]")
        return out_json

    urls_file.write_text("\n".join(urls))
    log.info("%d URLs preparadas", len(urls))

    # Plantillas espec√≠ficas
    tmpl: Set[str] = {tp for tech in techs for tp in TEMPLATE_MAPPING.get(tech, [])}

    # ---------------------------------------------------------------------
    # Ejecuci√≥n de Nuclei
    # ---------------------------------------------------------------------
    findings: List[Dict[str, Any]] = []
    try:
        cmd = _build_cmd(urls_file, tmpl, full_scan)
        log.debug("Cmd nuclei: %s", " ".join(cmd))
        raw = _run_nuclei(cmd)
        for line in raw.splitlines():
            line = line.strip()
            if not line:
                continue
            try:
                findings.append(json.loads(line))
            except json.JSONDecodeError:
                log.debug("JSON inv√°lido de nuclei: %s", line[:120])
        log.info("Nuclei devolvi√≥ %d hallazgos", len(findings))
    except Exception as exc:
        log.warning("Nuclei fall√≥: %s", exc)

    # ---------------------------------------------------------------------
    # Chequeo paralelo de cabeceras
    # ---------------------------------------------------------------------
    log.info("üîç [NUCLEI] Iniciando chequeo paralelo de cabeceras para %d URLs", len(urls))
    start_time = time.time()
    header_findings = _parallel_header_check(urls)
    header_check_time = time.time() - start_time
    log.info("üîç [NUCLEI] Chequeo de cabeceras completado en %.2f segundos", header_check_time)
    
    findings.extend(header_findings)

    # ---------------------------------------------------------------------
    # Procesar y estructurar resultados
    # ---------------------------------------------------------------------
    final_findings = _dedup_findings(findings)
    
    # Generar estad√≠sticas
    severity_counts = {"critical": 0, "high": 0, "medium": 0, "low": 0, "info": 0}
    host_counts = {}
    
    for finding in final_findings:
        severity = finding.get("info", {}).get("severity", "info")
        severity_counts[severity] = severity_counts.get(severity, 0) + 1
        
        host = finding.get("host", "unknown")
        host_counts[host] = host_counts.get(host, 0) + 1
    
    # Estructura de salida mejorada
    output_data = {
        "summary": {
            "total_findings": len(final_findings),
            "severity_breakdown": severity_counts,
            "hosts_analyzed": len(urls),
            "technologies_detected": list(techs),
            "scan_timestamp": time.strftime("%Y-%m-%d %H:%M:%S UTC", time.gmtime()),
            "execution_time": {
                "nuclei_scan": "N/A",  # Se podr√≠a medir si es necesario
                "header_check": f"{header_check_time:.2f}s",
                "total": f"{time.time() - start_time:.2f}s"
            },
            "templates_used": list(tmpl) if tmpl else ["default-tags"],
            "full_scan_mode": full_scan
        },
        "findings": final_findings,
        "host_summary": {
            host: {
                "finding_count": count,
                "url": host
            } for host, count in host_counts.items()
        }
    }
    
    # Salvar resultados
    out_json.write_text(json.dumps(output_data, indent=2))
    log.info("‚úÖ Nuclei terminado: %d hallazgos √∫nicos en %d hosts", len(final_findings), len(urls))
    log.info("üìä Resumen por severidad: %s", severity_counts)
    return out_json
