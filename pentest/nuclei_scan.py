"""Escaneo de vulnerabilidades con Nuclei + chequeo manual de cabeceras.

Cambios clave sobre la versión anterior
--------------------------------------
* Separación en funciones pequeñas (_build_cmd, _run_nuclei, _manual_header_check).
* Mapeo de tecnologías case‑insensitive y sin duplicados.
* Soporte de escaneo *universal* (sin plantillas) si Nuclei no está disponible.
* Timeouts y reintentos configurables.
* Salida deduplicada (hash SHA‑1 de host + vuln).
* Tipado estricto y testabilidad.
"""
from __future__ import annotations

import json
import logging
import os
import hashlib
import time
from pathlib import Path
from typing import Dict, List, Any, Set, Optional
from urllib.parse import urlparse
from concurrent.futures import ThreadPoolExecutor, as_completed
from functools import lru_cache

from pentest.runners import run_cmd
from pentest.exceptions import NucleiError
from pentest.config import DEFAULT_TIMEOUT
from pentest.http_utils import get_session

log = logging.getLogger(__name__)

# ---------------------------------------------------------------------------
# Configuración
# ---------------------------------------------------------------------------

TEMPLATE_MAPPING: Dict[str, List[str]] = {
    # CMS y Frameworks Web
    "wordpress": ["wordpress/", "default-logins/wordpress-default-login.yaml"],
    "drupal": ["drupal/", "default-logins/drupal-default-login.yaml"],
    "joomla": ["joomla/", "default-logins/joomla-default-login.yaml"],
    
    # Servidores Web
    "nginx": ["default-logins/nginx-default-login.yaml", "misconfiguration/nginx-alias-traversal.yaml"],
    "apache http server": ["default-logins/apache-default-login.yaml", "misconfiguration/apache-server-info.yaml"],
    "microsoft iis": ["technologies/microsoft-iis-version.yaml", "misconfiguration/iis-shortname-disclosure.yaml"],
    
    # Lenguajes de Programación
    "php": ["technologies/php-exposed-info.yaml", "misconfiguration/php-errors.yaml"],
    "python": ["technologies/python-version.yaml", "misconfiguration/django-debug.yaml"],
    "java": ["technologies/java-version.yaml", "misconfiguration/spring-boot-actuator.yaml"],
    "node.js": ["technologies/nodejs-version.yaml", "misconfiguration/express-stack-trace.yaml"],
    
    # Frameworks Frontend
    "react": ["technologies/react-version.yaml", "misconfiguration/react-dev-tools.yaml"],
    "vue.js": ["technologies/vue-version.yaml", "misconfiguration/vue-dev-tools.yaml"],
    "angular": ["technologies/angular-version.yaml", "misconfiguration/angular-dev-tools.yaml"],
    
    # Frameworks Backend
    "django": ["misconfiguration/django-debug.yaml", "default-logins/django-admin.yaml"],
    "laravel": ["misconfiguration/laravel-debug.yaml", "technologies/laravel-version.yaml"],
    "spring": ["misconfiguration/spring-boot-actuator.yaml", "technologies/spring-version.yaml"],
    "express": ["misconfiguration/express-stack-trace.yaml", "technologies/express-version.yaml"],
    
    # Bases de Datos
    "mysql": ["default-logins/mysql-default-login.yaml", "misconfiguration/mysql-dump.yaml"],
    "postgresql": ["default-logins/postgres-default-login.yaml", "misconfiguration/postgres-dump.yaml"],
    "mongodb": ["default-logins/mongodb-default-login.yaml", "misconfiguration/mongodb-exposure.yaml"],
    "redis": ["default-logins/redis-default-login.yaml", "misconfiguration/redis-unauth.yaml"],
    
    # Servicios Cloud
    "aws": ["cloud/aws-s3-bucket.yaml", "misconfiguration/aws-metadata.yaml"],
    "azure": ["cloud/azure-storage.yaml", "misconfiguration/azure-metadata.yaml"],
    "gcp": ["cloud/gcp-storage.yaml", "misconfiguration/gcp-metadata.yaml"],
    
    # Contenedores y Orquestación
    "docker": ["misconfiguration/docker-api.yaml", "technologies/docker-version.yaml"],
    "kubernetes": ["misconfiguration/kubernetes-api.yaml", "technologies/kubernetes-version.yaml"],
    
    # Herramientas de Desarrollo
    "jenkins": ["default-logins/jenkins-default-login.yaml", "misconfiguration/jenkins-build-info.yaml"],
    "gitlab": ["default-logins/gitlab-default-login.yaml", "misconfiguration/gitlab-public-repos.yaml"],
    "github": ["misconfiguration/github-config.yaml", "technologies/github-version.yaml"],
    
    # APIs y Microservicios
    "swagger": ["misconfiguration/swagger-ui.yaml", "technologies/swagger-version.yaml"],
    "graphql": ["misconfiguration/graphql-introspection.yaml", "technologies/graphql-version.yaml"],
    "rest api": ["misconfiguration/api-debug.yaml", "technologies/api-version.yaml"],
}

HEADER_REQUIREMENTS = {
    # Cabeceras críticas de seguridad
    "strict-transport-security": {
        "severity": "high",
        "desc": "Sin HSTS → conexiones HTTP inseguras.",
        "validate": lambda v: "max-age" in v and int(v.split("max-age=")[1].split(";")[0]) >= 31536000
    },
    "content-security-policy": {
        "severity": "medium",
        "desc": "Sin CSP → posible XSS.",
        "validate": lambda v: "unsafe-inline" not in v and "unsafe-eval" not in v
    },
    "x-frame-options": {
        "severity": "medium",
        "desc": "Sin X-Frame-Options → riesgo de clickjacking.",
        "validate": lambda v: v.upper() in ["DENY", "SAMEORIGIN"]
    },
    "referrer-policy": {
        "severity": "medium",
        "desc": "Sin Referrer-Policy → filtración de información.",
        "validate": lambda v: v in ["no-referrer", "strict-origin-when-cross-origin", "same-origin"]
    },
    "permissions-policy": {
        "severity": "medium",
        "desc": "Sin Permissions-Policy → acceso no controlado a APIs.",
        "validate": lambda v: len(v) > 0
    },
    "cross-origin-resource-policy": {
        "severity": "medium",
        "desc": "Sin CORP → recursos de origen cruzado.",
        "validate": lambda v: v in ["same-site", "same-origin", "cross-origin"]
    },
    "cross-origin-opener-policy": {
        "severity": "medium",
        "desc": "Sin COOP → ataques de timing side-channel.",
        "validate": lambda v: v in ["same-origin", "same-origin-allow-popups"]
    },
    "cross-origin-embedder-policy": {
        "severity": "medium",
        "desc": "Sin COEP → acceso no controlado a recursos cross-origin.",
        "validate": lambda v: v in ["require-corp", "credentialless"]
    },
    "x-content-type-options": {
        "severity": "low",
        "desc": "Sin X-Content-Type-Options → MIME sniffing.",
        "validate": lambda v: v.lower() == "nosniff"
    },
    "x-xss-protection": {
        "severity": "low",
        "desc": "Sin X-XSS-Protection → XSS en navegadores legacy.",
        "validate": lambda v: v == "1; mode=block"
    },
    "expect-ct": {
        "severity": "low",
        "desc": "Sin Expect-CT → certificados no autorizados.",
        "validate": lambda v: "max-age" in v
    },
}

NUCLEI_DEFAULT_TAGS = "cve,exposed-panels,default-logins,misconfiguration,vulnerabilities"
MAX_RETRIES = 3

# Configuración de rendimiento
MAX_WORKERS = 10  # Número máximo de hilos para chequeo de cabeceras
REQUEST_TIMEOUT = 10  # Timeout para requests HTTP
RATE_LIMIT_DELAY = 0.1  # Delay entre requests para rate limiting
CACHE_SIZE = 128  # Tamaño del cache LRU

# ---------------------------------------------------------------------------
# Utilidades internas
# ---------------------------------------------------------------------------

def _build_cmd(urls_file: Path, templates: Set[str], full_scan: bool) -> List[str]:
    """Compone el comando nuclei según la configuración."""
    cmd = [
        "nuclei", "-l", str(urls_file), "-json", "-silent", "-severity",
        "critical,high,medium,low,info", "-c", "100",
    ]

    if full_scan:
        cmd += ["-t", os.environ.get("NUCLEI_TEMPLATE_DIR", "nuclei-templates/")]
    elif templates:
        for t in templates:
            cmd += ["-t", t]
    else:
        cmd += ["-tags", NUCLEI_DEFAULT_TAGS]
    return cmd


def _dedup_findings(findings: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """Elimina duplicados usando hash(host+template+matched)."""
    seen: Set[str] = set()
    deduped: List[Dict[str, Any]] = []
    for f in findings:
        key_raw = f.get("host", "") + f.get("template", "") + f.get("matched", "")
        key = hashlib.sha1(key_raw.encode()).hexdigest()
        if key not in seen:
            seen.add(key)
            deduped.append(f)
    return deduped


def _run_nuclei(cmd: List[str]) -> str:
    return run_cmd(cmd, timeout=DEFAULT_TIMEOUT * 2, ignore=True,
                   retries=MAX_RETRIES, delay=2)


@lru_cache(maxsize=CACHE_SIZE)
def _cached_header_check(url: str) -> Dict[str, Any]:
    """Chequeo de cabeceras con cache para evitar requests duplicados."""
    session = get_session()
    try:
        resp = session.get(url, timeout=REQUEST_TIMEOUT, verify=False, allow_redirects=True)
        return {
            "headers": dict(resp.headers),
            "status_code": resp.status_code,
            "url": resp.url
        }
    except Exception as exc:
        log.debug("Error en request a %s: %s", url, exc)
        return {"error": str(exc)}


def _validate_header_value(header_name: str, header_value: str) -> Dict[str, Any]:
    """Valida el valor de una cabecera específica."""
    header_config = HEADER_REQUIREMENTS.get(header_name.lower())
    if not header_config:
        return {"valid": True, "message": "No validation configured"}
    
    validate_func = header_config.get("validate")
    if not validate_func:
        return {"valid": True, "message": "Header present"}
    
    try:
        is_valid = validate_func(header_value)
        return {
            "valid": is_valid,
            "message": "Valid configuration" if is_valid else "Invalid configuration"
        }
    except Exception as exc:
        return {"valid": False, "message": f"Validation error: {exc}"}


def _check_single_url_headers(url: str) -> List[Dict[str, Any]]:
    """Chequea las cabeceras de seguridad para una URL específica."""
    findings = []
    p = urlparse(url)
    if not p.scheme or not p.netloc:
        return findings
    
    # Rate limiting
    time.sleep(RATE_LIMIT_DELAY)
    
    response_data = _cached_header_check(url)
    if "error" in response_data:
        return findings
    
    headers = response_data["headers"]
    hdrs_l = {k.lower(): v for k, v in headers.items()}
    
    # Chequear cabeceras requeridas
    for header_name, meta in HEADER_REQUIREMENTS.items():
        header_value = hdrs_l.get(header_name)
        
        if not header_value:
            # Cabecera faltante
            findings.append({
                "host": url,
                "matched": url,
                "type": "http",
                "info": {
                    "name": f"Missing {header_name.title()} Header",
                    "severity": meta["severity"],
                    "description": meta["desc"],
                },
            })
        else:
            # Validar valor de cabecera
            validation = _validate_header_value(header_name, header_value)
            if not validation["valid"]:
                findings.append({
                    "host": url,
                    "matched": url,
                    "type": "http",
                    "info": {
                        "name": f"Invalid {header_name.title()} Header",
                        "severity": meta["severity"],
                        "description": f"{meta['desc']} Value: '{header_value}'. {validation['message']}",
                    },
                })
    
    # Chequear cabecera Server
    srv = headers.get("Server")
    findings.append({
        "host": url,
        "matched": url,
        "type": "http",
        "info": {
            "name": "Server Header " + ("Exposed" if srv else "Not Present"),
            "severity": "low" if srv else "info",
            "description": f"'Server' header value: {srv or 'none'}.",
        },
    })
    
    # Chequear protocolo HTTP no cifrado
    if url.startswith("http://"):
        findings.append({
            "host": url,
            "matched": url,
            "type": "http",
            "info": {
                "name": "HTTP (unencrypted)",
                "severity": "high",
                "description": "El sitio usa HTTP sin cifrado.",
            },
        })
    
    return findings


def _parallel_header_check(urls: List[str]) -> List[Dict[str, Any]]:
    """Ejecuta el chequeo de cabeceras en paralelo para múltiples URLs."""
    findings = []
    
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        # Enviar todas las tareas
        future_to_url = {executor.submit(_check_single_url_headers, url): url for url in urls}
        
        # Recoger resultados conforme se completan
        for future in as_completed(future_to_url):
            url = future_to_url[future]
            try:
                url_findings = future.result()
                findings.extend(url_findings)
            except Exception as exc:
                log.debug("Error procesando %s: %s", url, exc)
    
    return findings

# ---------------------------------------------------------------------------
# API pública
# ---------------------------------------------------------------------------

def nuclei_scan(httpx_file: Optional[Path], tmp_dir: Path, full_scan: bool = False) -> Path:
    log.info("🔍 [NUCLEI] Nuclei: escaneo de vulnerabilidades")
    log.info("🔍 [NUCLEI] Archivo httpx: %s", httpx_file)
    log.info("🔍 [NUCLEI] Directorio temporal: %s", tmp_dir)
    
    out_json = tmp_dir / "nuclei.json"
    urls_file = tmp_dir / "urls.txt"
    log.info("🔍 [NUCLEI] Archivo de salida: %s", out_json)

    if not httpx_file or not httpx_file.exists():
        log.warning(f"🔍 [NUCLEI] ❌ Archivo de hosts no encontrado o es None: {httpx_file}. Nuclei scan will return empty results.")
        out_json.write_text("[]")
        return out_json

    # Verificar el tamaño del archivo httpx
    file_size = httpx_file.stat().st_size
    log.info("🔍 [NUCLEI] Tamaño del archivo httpx: %d bytes", file_size)

    # ---------------------------------------------------------------------
    # Preparar URLs + tecnologías
    # ---------------------------------------------------------------------
    try:
        content = httpx_file.read_text()
        log.info("🔍 [NUCLEI] Contenido crudo del archivo httpx (primeros 500 chars): %s", content[:500])
        hosts_data = json.loads(content)
        log.info("🔍 [NUCLEI] Datos JSON parseados: %d entradas", len(hosts_data))
        if hosts_data:
            log.info("🔍 [NUCLEI] Primera entrada: %s", hosts_data[0])
    except Exception as exc:
        log.warning(f"🔍 [NUCLEI] ❌ Error leyendo {httpx_file}: {exc}. Nuclei scan will return empty results.")
        log.warning(f"🔍 [NUCLEI] ❌ Contenido problemático: %s", content[:200] if 'content' in locals() else 'No se pudo leer')
        out_json.write_text("[]")
        return out_json

    urls: List[str] = []
    techs: Set[str] = set()
    
    log.info("🔍 [NUCLEI] Procesando %d entradas de httpx", len(hosts_data))
    for i, h in enumerate(hosts_data):
        log.debug("🔍 [NUCLEI] Procesando entrada %d: %s", i, h)
        if url := h.get("url"):
            urls.append(url)
            log.debug("🔍 [NUCLEI] URL añadida: %s", url)
        else:
            log.warning("🔍 [NUCLEI] ⚠️ Entrada %d sin campo 'url': %s", i, h)
        
        for t in h.get("tech", []):
            name = t if isinstance(t, str) else t.get("name", "")
            if name:
                techs.add(name.lower())
                log.debug("🔍 [NUCLEI] Tecnología añadida: %s", name.lower())

    log.info("🔍 [NUCLEI] URLs extraídas: %d", len(urls))
    log.info("🔍 [NUCLEI] Lista de URLs: %s", urls)
    log.info("🔍 [NUCLEI] Tecnologías detectadas: %s", list(techs))

    if not urls:
        log.warning("🔍 [NUCLEI] ⚠️ Sin URLs para escanear – devolviendo JSON vacío")
        log.warning("🔍 [NUCLEI] ⚠️ Datos httpx recibidos: %s", hosts_data)
        out_json.write_text("[]")
        return out_json

    urls_file.write_text("\n".join(urls))
    log.info("%d URLs preparadas", len(urls))

    # Plantillas específicas
    tmpl: Set[str] = {tp for tech in techs for tp in TEMPLATE_MAPPING.get(tech, [])}

    # ---------------------------------------------------------------------
    # Ejecución de Nuclei
    # ---------------------------------------------------------------------
    findings: List[Dict[str, Any]] = []
    try:
        cmd = _build_cmd(urls_file, tmpl, full_scan)
        log.debug("Cmd nuclei: %s", " ".join(cmd))
        raw = _run_nuclei(cmd)
        for line in raw.splitlines():
            line = line.strip()
            if not line:
                continue
            try:
                findings.append(json.loads(line))
            except json.JSONDecodeError:
                log.debug("JSON inválido de nuclei: %s", line[:120])
        log.info("Nuclei devolvió %d hallazgos", len(findings))
    except Exception as exc:
        log.warning("Nuclei falló: %s", exc)

    # ---------------------------------------------------------------------
    # Chequeo paralelo de cabeceras
    # ---------------------------------------------------------------------
    log.info("🔍 [NUCLEI] Iniciando chequeo paralelo de cabeceras para %d URLs", len(urls))
    start_time = time.time()
    header_findings = _parallel_header_check(urls)
    header_check_time = time.time() - start_time
    log.info("🔍 [NUCLEI] Chequeo de cabeceras completado en %.2f segundos", header_check_time)
    
    findings.extend(header_findings)

    # ---------------------------------------------------------------------
    # Procesar y estructurar resultados
    # ---------------------------------------------------------------------
    final_findings = _dedup_findings(findings)
    
    # Generar estadísticas
    severity_counts = {"critical": 0, "high": 0, "medium": 0, "low": 0, "info": 0}
    host_counts = {}
    
    for finding in final_findings:
        severity = finding.get("info", {}).get("severity", "info")
        severity_counts[severity] = severity_counts.get(severity, 0) + 1
        
        host = finding.get("host", "unknown")
        host_counts[host] = host_counts.get(host, 0) + 1
    
    # Estructura de salida mejorada
    output_data = {
        "summary": {
            "total_findings": len(final_findings),
            "severity_breakdown": severity_counts,
            "hosts_analyzed": len(urls),
            "technologies_detected": list(techs),
            "scan_timestamp": time.strftime("%Y-%m-%d %H:%M:%S UTC", time.gmtime()),
            "execution_time": {
                "nuclei_scan": "N/A",  # Se podría medir si es necesario
                "header_check": f"{header_check_time:.2f}s",
                "total": f"{time.time() - start_time:.2f}s"
            },
            "templates_used": list(tmpl) if tmpl else ["default-tags"],
            "full_scan_mode": full_scan
        },
        "findings": final_findings,
        "host_summary": {
            host: {
                "finding_count": count,
                "url": host
            } for host, count in host_counts.items()
        }
    }
    
    # Salvar resultados
    out_json.write_text(json.dumps(output_data, indent=2))
    log.info("✅ Nuclei terminado: %d hallazgos únicos en %d hosts", len(final_findings), len(urls))
    log.info("📊 Resumen por severidad: %s", severity_counts)
    return out_json
