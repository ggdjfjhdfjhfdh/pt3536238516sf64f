"""Escaneo de vulnerabilidades con Nuclei + chequeo manual de cabeceras.

Cambios clave sobre la versi√≥n anterior
--------------------------------------
* Separaci√≥n en funciones peque√±as (_build_cmd, _run_nuclei, _manual_header_check).
* Mapeo de tecnolog√≠as case‚Äëinsensitive y sin duplicados.
* Soporte de escaneo *universal* (sin plantillas) si Nuclei no est√° disponible.
* Timeouts y reintentos configurables.
* Salida deduplicada (hash SHA‚Äë1 de host + vuln).
* Tipado estricto y testabilidad.
"""
from __future__ import annotations

import json
import logging
import os
import hashlib
from pathlib import Path
from typing import Dict, List, Any, Set
from urllib.parse import urlparse

from pentest.runners import run_cmd
from pentest.exceptions import NucleiError
from pentest.config import DEFAULT_TIMEOUT
from pentest.http import get_session

log = logging.getLogger(__name__)

# ---------------------------------------------------------------------------
# Configuraci√≥n
# ---------------------------------------------------------------------------

TEMPLATE_MAPPING: Dict[str, List[str]] = {
    "wordpress": ["wordpress/"],
    "nginx": ["default-logins/nginx-default-login.yaml"],
    "apache http server": ["default-logins/apache-default-login.yaml"],
    "php": ["technologies/php-exposed-info.yaml"],
    "mysql": ["default-logins/mysql-default-login.yaml"],
    "microsoft iis": ["technologies/microsoft-iis-version.yaml"],
}

HEADER_REQUIREMENTS = {
    "x-frame-options": {
        "severity": "medium",
        "desc": "Sin X-Frame-Options ‚Üí riesgo de clickjacking."
    },
    "content-security-policy": {
        "severity": "medium",
        "desc": "Sin CSP ‚Üí posible XSS."
    },
    "expect-ct": {
        "severity": "medium",
        "desc": "Sin Expect-CT ‚Üí certificados no autorizados."
    },
    "cross-origin-resource-policy": {
        "severity": "medium",
        "desc": "Sin CORP ‚Üí recursos de origen cruzado."
    },
    "x-content-type-options": {
        "severity": "low",
        "desc": "Sin X-Content-Type-Options ‚Üí MIME sniffing."
    },
}

NUCLEI_DEFAULT_TAGS = "cve,exposed-panels,default-logins,misconfiguration,vulnerabilities"
MAX_RETRIES = 3

# ---------------------------------------------------------------------------
# Utilidades internas
# ---------------------------------------------------------------------------

def _build_cmd(urls_file: Path, templates: Set[str], full_scan: bool) -> List[str]:
    """Compone el comando nuclei seg√∫n la configuraci√≥n."""
    cmd = [
        "nuclei", "-l", str(urls_file), "-json", "-silent", "-severity",
        "critical,high,medium,low,info", "-c", "100",
    ]

    if full_scan:
        cmd += ["-t", os.environ.get("NUCLEI_TEMPLATE_DIR", "nuclei-templates/")]
    elif templates:
        for t in templates:
            cmd += ["-t", t]
    else:
        cmd += ["-tags", NUCLEI_DEFAULT_TAGS]
    return cmd


def _dedup_findings(findings: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """Elimina duplicados usando hash(host+template+matched)."""
    seen: Set[str] = set()
    deduped: List[Dict[str, Any]] = []
    for f in findings:
        key_raw = f.get("host", "") + f.get("template", "") + f.get("matched", "")
        key = hashlib.sha1(key_raw.encode()).hexdigest()
        if key not in seen:
            seen.add(key)
            deduped.append(f)
    return deduped


def _run_nuclei(cmd: List[str]) -> str:
    return run_cmd(cmd, timeout=DEFAULT_TIMEOUT * 2, ignore=True,
                   retries=MAX_RETRIES, delay=2)

# ---------------------------------------------------------------------------
# API p√∫blica
# ---------------------------------------------------------------------------

def nuclei_scan(httpx_file: Optional[Path], tmp_dir: Path, full_scan: bool = False) -> Path:
    log.info("üîç [NUCLEI] Nuclei: escaneo de vulnerabilidades")
    log.info("üîç [NUCLEI] Archivo httpx: %s", httpx_file)
    log.info("üîç [NUCLEI] Directorio temporal: %s", tmp_dir)
    
    out_json = tmp_dir / "nuclei.json"
    urls_file = tmp_dir / "urls.txt"
    log.info("üîç [NUCLEI] Archivo de salida: %s", out_json)

    if not httpx_file or not httpx_file.exists():
        log.warning(f"üîç [NUCLEI] ‚ùå Archivo de hosts no encontrado o es None: {httpx_file}. Nuclei scan will return empty results.")
        out_json.write_text("[]")
        return out_json

    # Verificar el tama√±o del archivo httpx
    file_size = httpx_file.stat().st_size
    log.info("üîç [NUCLEI] Tama√±o del archivo httpx: %d bytes", file_size)

    # ---------------------------------------------------------------------
    # Preparar URLs + tecnolog√≠as
    # ---------------------------------------------------------------------
    try:
        content = httpx_file.read_text()
        log.info("üîç [NUCLEI] Contenido crudo del archivo httpx (primeros 500 chars): %s", content[:500])
        hosts_data = json.loads(content)
        log.info("üîç [NUCLEI] Datos JSON parseados: %d entradas", len(hosts_data))
        if hosts_data:
            log.info("üîç [NUCLEI] Primera entrada: %s", hosts_data[0])
    except Exception as exc:
        log.warning(f"üîç [NUCLEI] ‚ùå Error leyendo {httpx_file}: {exc}. Nuclei scan will return empty results.")
        log.warning(f"üîç [NUCLEI] ‚ùå Contenido problem√°tico: %s", content[:200] if 'content' in locals() else 'No se pudo leer')
        out_json.write_text("[]")
        return out_json

    urls: List[str] = []
    techs: Set[str] = set()
    
    log.info("üîç [NUCLEI] Procesando %d entradas de httpx", len(hosts_data))
    for i, h in enumerate(hosts_data):
        log.debug("üîç [NUCLEI] Procesando entrada %d: %s", i, h)
        if url := h.get("url"):
            urls.append(url)
            log.debug("üîç [NUCLEI] URL a√±adida: %s", url)
        else:
            log.warning("üîç [NUCLEI] ‚ö†Ô∏è Entrada %d sin campo 'url': %s", i, h)
        
        for t in h.get("tech", []):
            name = t if isinstance(t, str) else t.get("name", "")
            if name:
                techs.add(name.lower())
                log.debug("üîç [NUCLEI] Tecnolog√≠a a√±adida: %s", name.lower())

    log.info("üîç [NUCLEI] URLs extra√≠das: %d", len(urls))
    log.info("üîç [NUCLEI] Lista de URLs: %s", urls)
    log.info("üîç [NUCLEI] Tecnolog√≠as detectadas: %s", list(techs))

    if not urls:
        log.warning("üîç [NUCLEI] ‚ö†Ô∏è Sin URLs para escanear ‚Äì devolviendo JSON vac√≠o")
        log.warning("üîç [NUCLEI] ‚ö†Ô∏è Datos httpx recibidos: %s", hosts_data)
        out_json.write_text("[]")
        return out_json

    urls_file.write_text("\n".join(urls))
    log.info("%d URLs preparadas", len(urls))

    # Plantillas espec√≠ficas
    tmpl: Set[str] = {tp for tech in techs for tp in TEMPLATE_MAPPING.get(tech, [])}

    # ---------------------------------------------------------------------
    # Ejecuci√≥n de Nuclei
    # ---------------------------------------------------------------------
    findings: List[Dict[str, Any]] = []
    try:
        cmd = _build_cmd(urls_file, tmpl, full_scan)
        log.debug("Cmd nuclei: %s", " ".join(cmd))
        raw = _run_nuclei(cmd)
        for line in raw.splitlines():
            line = line.strip()
            if not line:
                continue
            try:
                findings.append(json.loads(line))
            except json.JSONDecodeError:
                log.debug("JSON inv√°lido de nuclei: %s", line[:120])
        log.info("Nuclei devolvi√≥ %d hallazgos", len(findings))
    except Exception as exc:
        log.warning("Nuclei fall√≥: %s", exc)

    # ---------------------------------------------------------------------
    # Chequeo manual de cabeceras
    # ---------------------------------------------------------------------
    session = get_session()
    for url in urls:
        p = urlparse(url)
        if not p.scheme or not p.netloc:
            continue
        try:
            resp = session.get(url, timeout=10, verify=False, allow_redirects=True)
            hdrs_l = {k.lower() for k in resp.headers}
            for h, meta in HEADER_REQUIREMENTS.items():
                if h not in hdrs_l:
                    findings.append({
                        "host": url,
                        "matched": url,
                        "type": "http",
                        "info": {
                            "name": f"Missing {h.title()} Header",
                            "severity": meta["severity"],
                            "description": meta["desc"],
                        },
                    })
            # Server header
            srv = resp.headers.get("Server")
            findings.append({
                "host": url,
                "matched": url,
                "type": "http",
                "info": {
                    "name": "Server Header " + ("Exposed" if srv else "Not Present"),
                    "severity": "low" if srv else "info",
                    "description": f"'Server' header value: {srv or 'none'}.",
                },
            })
            if url.startswith("http://"):
                findings.append({
                    "host": url,
                    "matched": url,
                    "type": "http",
                    "info": {
                        "name": "HTTP (unencrypted)",
                        "severity": "high",
                        "description": "El sitio usa HTTP sin cifrado.",
                    },
                })
        except Exception as exc:
            log.debug("Header check error %s: %s", url, exc)

    # ---------------------------------------------------------------------
    # Salvar resultados
    # ---------------------------------------------------------------------
    final = _dedup_findings(findings)
    out_json.write_text(json.dumps(final, indent=2))
    log.info("‚úÖ Nuclei terminado: %d hallazgos √∫nicos", len(final))
    return out_json
